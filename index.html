<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Common Media Application Format for Presentation of Segmented Media</title>
  <script src='https://www.w3.org/Tools/respec/respec-w3c-common' async class='remove'></script>
  <style type="text/css">code{white-space: pre;}</style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1>Common Media Application Format for Presentation of Segmented Media</h1>
<section id="abstract" style="display: none;"></section>
<section class="introductory">
<h2>Introduction</h2>
<p>The Common Media Application Format (CMAF) is a Media Application Format that specifies how to use the ISO Base Media File Format and other MPEG standards to package media for segmented delivery. It is optimized for efficient adaptive playback of a single presentation containing encoded and encrypted Tracks by a wide range of devices over the Internet, using a variety of delivery methods.</p>
<p>The Common Media Application Format is intended to improve the efficiency of large-scale video distribution over the Internet and improve device compatibility for all delivery methods. It seeks to address the current situation where the same video has to be encoded in several different formats that multiply the network storage and bandwidth consumed, and complicate device compatibility by requiring support for multiple media formats that are intended to produce the same video presentation.</p>
<p>The Common Media Application Format describes how to construct a multimedia presentation in a series of small media objects called Segments. These objects, even when produced during live presentation, can be transferred using common file-based delivery protocols – as well as more specialized methods such as multicast and peer-to-peer – and then reassembled and played back by a player.</p>
<p>Segments contain movie fragments that can be copied directly from one or a set of CMAF conformant ISO Base Media files without modification. CMAF specifies the encoding constraints of movie fragments called <a>CMAF Fragment</a>s, and the packaging of one or more <a>CMAF Fragment</a>s in an addressable resource called a <a>CMAF Segment</a>. <a>CMAF Segment</a>s are organized into a Presentation by a <a>Manifest</a>.</p>
<p><a>Manifest</a>s can identify each <a>CMAF Segment</a> by a URI. The <a>CMAF Segment</a> data structure is independent of intermediate transport protocol or other delivery method, allowing CMAF <a>Player</a>s to render the same <a>CMAF Segment</a>s and <a>Manifest</a> regardless of delivery method. <a>CMAF Fragment</a>s may be automatically formatted as <a>CMAF Segment</a>s by HTTP(S) servers that encapsulate one or more <a>CMAF Fragment</a>s in an HTTP(S) response matching that URL in a <a>Manifest</a>.</p>
<p>A <a>CMAF Track</a> is a <a>CMAF Header</a> followed by a continuous sequence of CMAF Fragments ordered by decode time, nearly equivalent to a single track ISO Base Media File Format fragmented movie file. A <a>CMAF Track</a> may only contain a partial time range of a valid ISOBMFF track, whereas files are defined to start at media time zero. Each <a>CMAF Track</a> contains only one media type, such as audio, video, or subtitles. Discontinuous timespans of the same source stream are considered separate <a>CMAF Track</a>s. Each Track must be synchronized in its own Presentation and must be initialized with a <a>CMAF Header</a>.</p>
<p>Conceptually, multiple Presentations may be combined in a <a>Composition</a> in which each Presentation is played in sequence, or in parallel. The specification of <a>Composition</a>s and the implementation of a specific <a>Manifest</a> format are outside the scope of this specification. Any <a>Manifest</a> or <a>Composition</a> format that accurately describes <a>CMAF Segment</a>s and Track Sets .and their synchronization may be used to assemble and render a Presentation.</p>
<p>The CMAF specification adds constraints to the ISO Base Media File Format so that it meets the requirements of widely adopted streaming protocols such as MPEG DASH and Apple’s HTTP Live Streaming. <a>CMAF Segment</a>, Track, and Track Set constraints enable a sequence of <a>CMAF Fragment</a>s resulting from adaptive streaming to be decoded seamlessly within a single ISOBMFF parser/decoder primarily designed for file playback, possibly isolated by an HTML web browser.</p>
<p>To support interoperability, CMAF defines a file brand and Media Profiles for encoded media, including video (AVC &amp; HEVC), audio (AAC) and subtitles (WebVTT &amp; Closed Captions). These brands and Media Profiles indicate when a Track conforms to CMAF packaging and encoding constraints, and the maximum decoder requirements necessary to decode that Media Profile. The CMAF container brand can also be used in combination with CMAF Compatible Media Profiles, which are not specified in CMAF, but conform to CMAF container, Track, and functional constraints. CMAF specifies Presentation Profiles that define the minimum necessary Tracks and Media Profiles that must be included in a conforming Presentation. Wide support for these <a>CMAF Presentation</a> and Media Profiles by players will eliminate the need to store multiple variations of content, which will increase encoding, storage, and edge caching efficiency for distributors.</p>
<p>CMAF uses MPEG Common Encryption for media sample encryption. This allows different DRM systems on different devices to play the same encrypted media files.</p>
<p>CMAF specifies how to encode Switching Sets of Tracks from the same source content at different bitrates, resolutions, and frame rates so that a player can seamlessly switch between Tracks in a Switching Set during playback to adapt to current network and playback conditions. CMAF also specifies how to group Switching Sets containing alternative audio, video, and subtitle versions into Selection Sets. A player or user can make a selection from each Selection Set for synchronized multimedia playback. Selection Sets also allow each player to customize the Presentation to match device capabilities and user preferences, e.g. selecting the preferred audio language from several in a Selection Set.</p>
</section>
<section>
<h2>Scope</h2>
<section>
<h2>Application Model</h2>
<p>The Common Media Application Format is designed to support segmented media delivery and presentation. In typical use, a client referred to as a <a>Player</a> receives short (e.g. 2-10s) periods of media (Segments). A succession of media Segments with continuous content forms a Track. Each Track contains a single media type, i.e. audio, video, or subtitles. Multiple Tracks (e.g. audio and video) may be individually selected from alternatives, received, and played simultaneously; a process called “late binding”. The <a>Player</a> synchronizes decoding and presentation of parallel Tracks, and renders Fragments within each track in a continuous sequence of media samples to produce multimedia Presentations. See <a href="#cmaf-architecture"></a> for more detail.</p>
<p>The set of Segments to be played in each Presentation, their identity, order, type, grouping, and other information is conveyed by a presentation description called a <a>Manifest</a>. Presentations may be sequenced and otherwise combined in a <a>Composition</a> that describes multiple Presentations and when they are to be played.</p>
</section>
<section>
<h2>Scope within the Application Model</h2>
<p>In order to apply to the widest range of playback systems, the Common Media Application Format only defines how <a>CMAF Fragment</a>s are to be encoded and packaged using the ISO Base Media File Format so that they are suitable for segmented media delivery and playback. It does not define the form or the content of the <a>Manifest</a>. It does not define how multiple Presentations are combined in a <a>Composition</a>. It does not define how the Segments are to be transported to the <a>Player</a>.</p>
<p>This specification does not define <a>Player</a> responsibilities or behavior, although requirements for synchronization and seamless decoding of adaptively selected <a>CMAF Segment</a>s may be inferred from the specified <a>CMAF Fragment</a> encoding constraints. (Note however that <a href="#fundamental-concepts"></a> lists several affordances of <a>CMAF Segment</a>s that are available to <a>Player</a> implementations.)</p>
<p>CMAF defines Track and Fragment encryption, but it does not define key delivery or encrypted content playback policy.</p>
<p>These constraints are intended to define standard interoperability points between encoders and decoders, and content packagers and players; and to enable the same Tracks to be used for a wide range of adaptive streaming, broadcast/multicast, and file playback applications.</p>
</section>
</section>
<section>
<h2>Normative references</h2>
<p>The following documents, in whole or in part, are normatively referenced in this document and are indispensable for its application. For dated references, only the edition cited applies. For undated references, the latest edition of the referenced document (including any amendments) applies.</p>
<p>These normative references are intended to include corrigenda and amendments available at the time of use.</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">[<span id="AAC" class="anchor"></span>AAC]</td>
<td style="text-align: left;">ISO/IEC 14496-3, Information technology — Coding of audio-visual objects — Part 3: Advanced Audio Coding, including Amendment 4</td>
</tr>
<tr class="even">
<td style="text-align: left;">[<span id="H264REF" class="anchor"><span id="AVC" class="anchor"></span></span>AVC]</td>
<td style="text-align: left;">ISO/IEC 14496-10, Information technology — Coding of audio-visual objects — Part 10: Advanced Video Coding</td>
</tr>
<tr class="odd">
<td style="text-align: left;">[<span id="CENCREF" class="anchor"></span>CENC]</td>
<td style="text-align: left;">ISO/IEC 23001-7: 2016, Third Edition, “Information technology – MPEG systems technologies – Part 7: Common encryption in ISO base media file format files”.</td>
</tr>
<tr class="even">
<td style="text-align: left;">[<span id="DASHREF" class="anchor"></span>DASH]</td>
<td style="text-align: left;">ISO/IEC 23009-1, Information technology — Dynamic adaptive streaming over HTTP (DASH) — Part 1: Media presentation description and segment formats</td>
</tr>
<tr class="odd">
<td style="text-align: left;">[<span id="H265REF" class="anchor"><span id="HEVC" class="anchor"></span></span>HEVC]</td>
<td style="text-align: left;">ISO/IEC 23008-2, Information technology — High efficiency coding and media delivery in heterogeneous environments — Part 2: High efficiency video coding</td>
</tr>
<tr class="even">
<td style="text-align: left;">[<span id="ISOM" class="anchor"><span id="ISOMREF" class="anchor"></span></span>ISOM]</td>
<td style="text-align: left;">ISO/IEC 14496-12:2015 “Information technology – Coding of audio-visual objects – Part 12: ISO Base Media File Format</td>
</tr>
<tr class="odd">
<td style="text-align: left;">[<span id="ISOTXTREF" class="anchor"></span>ISOTXT]</td>
<td style="text-align: left;">ISO/IEC 14496-30, &quot;Timed Text and Other Visual Overlays in ISO Base Media File Format&quot;</td>
</tr>
<tr class="even">
<td style="text-align: left;">[<span id="ISOVIDEOREF" class="anchor"></span>ISOVIDEO]</td>
<td style="text-align: left;">ISO/IEC 14496-15, Third Edition, “Information technology -- Coding of audio-visual objects -- Carriage of NAL unit structured video in the ISO Base Media File Format”</td>
</tr>
<tr class="odd">
<td style="text-align: left;">[<span id="R1886REF" class="anchor"></span>R1886]</td>
<td style="text-align: left;">ITU-R Recommendation BT.1886, Reference electro-optical transfer function for flat panel displays used in HDTV studio production, March 2011.</td>
</tr>
<tr class="even">
<td style="text-align: left;">[<span id="R2035REF" class="anchor"></span>R2035]</td>
<td style="text-align: left;">ITU-R Recommendation BT.2035, A reference viewing environment for evaluation of HDTV program material or completed programmes, July 2013.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">[<span id="R709REF" class="anchor"><span id="BT709" class="anchor"></span></span>BT709]</td>
<td style="text-align: left;">ITU-R Recommendation BT.709, Parameter values for the HDTV standards for production and international programme exchange, June 2015.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span id="X667" class="anchor"></span>[<span id="RFC4122REF" class="anchor"></span>X667]</td>
<td style="text-align: left;">ITU-T Recommendation X.667, Information technology - Open Systems Interconnection - Procedures for the operation of OSI Registration Authorities: Generation and registration of Universally Unique Identifiers (UUIDs) and their use as ASN.1 Object Identifier components. <a href="http://www.itu.int/rec/T-REC-X.667-200409-S/en"><em>http://www.itu.int/rec/T-REC-X.667-200409-S/en</em></a></td>
</tr>
<tr class="odd">
<td style="text-align: left;">[<span id="RFC6381REF" class="anchor"></span>RFC6381]</td>
<td style="text-align: left;">IETF RFC 6381, The 'Codecs' and 'Profiles' Parameters for &quot;Bucket&quot; Media Types, August 2011.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span id="RFC7230" class="anchor"></span>[RFC7230]</td>
<td style="text-align: left;">IETF RFC 7230, Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span id="RFC7231" class="anchor"></span>[RFC7231]</td>
<td style="text-align: left;">IETF RFC 7231, Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span id="SCTE128" class="anchor"></span>[SCTE128]</td>
<td style="text-align: left;">ANSI/SCTE 128-1 2013: AVC Video Constraints for Cable Television, Part 1 - Coding, <a href="http://www.scte.org/documents/pdf/Standards/ANSI_SCTE%20128-1%202013.pdf"><em>http://www.scte.org/documents/pdf/Standards/ANSI_SCTE%20128-1%202013.pdf</em></a></td>
</tr>
<tr class="odd">
<td style="text-align: left;">[<span id="ST2020" class="anchor"><span id="BT2020" class="anchor"></span></span>BT2020]</td>
<td style="text-align: left;">ITU-R Recommendation BT.2020, Parameter values for ultra-high definition television systems for production and international programme exchange, October 2015, <a href="http://www.itu.int/rec/R-REC-BT.2020/en"><em>http://www.itu.int/rec/R-REC-BT.2020/en</em></a></td>
</tr>
<tr class="even">
<td style="text-align: left;">[<span id="ST2084" class="anchor"></span>ST2084]</td>
<td style="text-align: left;">SMPTE ST 2084:2014, Dynamic Range Electro-Optical Transfer Function of Mastering Reference Displays, August 16, 2014.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">[<span id="ST2086" class="anchor"></span>ST2086]</td>
<td style="text-align: left;">SMPTE ST 2086:2014, Mastering Display Color Volume Metadata Supporting High Luminance and Wide Color Gamut Images, October 13, 2014.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span id="CEA608REF" class="anchor"></span>[CEA608]</td>
<td style="text-align: left;">CTA-608-E R-2014, Line 21 Data Services, April 1, 2008, <a href="http://www.ce.org/Standards/Standard-Listings/R4-3-Television-Data-Systems-Subcommittee/Line-21-Data-Service.aspx"><em>http://www.ce.org/Standards/</em></a><a href="http://www.ce.org/Standards/Standard-Listings/R4-3-Television-Data-Systems-Subcommittee/Line-21-Data-Service.aspx"><em>Standard-Listings/R4-3-Television-Data-Systems-</em></a><a href="http://www.ce.org/Standards/Standard-Listings/R4-3-Television-Data-Systems-Subcommittee/Line-21-Data-Service.aspx"><em>Subcommittee/Line-21-Data-Service.aspx</em></a></td>
</tr>
<tr class="odd">
<td style="text-align: left;">[<span id="CEA708REF" class="anchor"></span>CEA708]</td>
<td style="text-align: left;">CTA-708-E, Digital Television (DTV) Closed Captioning, August 23, 2013, <a href="http://www.ce.org/Standards/Standard-Listings/R4-3-Television-Data-Systems-Subcommittee/CEA-708-D.aspx"><em>http://www.ce.org/Standards/Standard-Listings/</em></a><a href="http://www.ce.org/Standards/Standard-Listings/R4-3-Television-Data-Systems-Subcommittee/CEA-708-D.aspx"><em>R4-3-Television-Data-Systems-Subcommittee/CEA-708-D.aspx</em></a></td>
</tr>
<tr class="even">
<td style="text-align: left;">[<span id="MP4SYS" class="anchor"></span>MP4SYS]</td>
<td style="text-align: left;">ISO/IEC 14496-1:2010, Information technology -- Coding of audio-visual objects -- Part 1: Systems,</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span id="IMSC" class="anchor"></span>[IMSC]</td>
<td style="text-align: left;">W3C, TTML Profiles for Internet Media Subtitles and Captions 1.0 (IMSC1), http://www.w3.org/TR/ttml-imsc1/</td>
</tr>
<tr class="even">
<td style="text-align: left;">[<span id="VTT" class="anchor"></span>VTT]</td>
<td style="text-align: left;">W3C, WebVTT: The Web Video Text Tracks Format, Draft Community Group Report, 8 December 2015, http://www.w3.org/TR/webvtt1/</td>
</tr>
</tbody>
</table>
</section>
<section>
<h2>Terms, definitions, and abbreviated terms</h2>
<section>
<h2>Terms and definitions</h2>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><dfn>CMAF Header</dfn></td>
<td style="text-align: left;">sequence of ISO Base Media File Format boxes starting with a file type box and including a movie box that includes initialization information common to a set of Segments. (<a href="#cmaf-header-initialization-segment"></a>).</td>
</tr>
<tr class="even">
<td style="text-align: left;"><dfn>Composition</dfn></td>
<td style="text-align: left;">combination of multiple <a>CMAF Presentation</a>s in a relationship such as a sequence.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><dfn>CMAF Presentation</dfn></td>
<td style="text-align: left;">set of one or more synchronized <a>CMAF Selection Set</a>s, each containing Segments of one media type that can be sequentially decoded to produce a presentation, potentially including synchronized audio, video, and subtitles (<a href="#cmaf-presentation-and-timing-model"></a>)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><dfn>CMAF Fragment</dfn></td>
<td style="text-align: left;">ISO Base Media File Format segment, as defined by ISO/IEC 14496-12 section 8.16, constrained to a single movie fragment box, a single track fragment box, and conforming to CMAF encoding and packaging constraints.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><dfn>CMAF Segment</dfn></td>
<td style="text-align: left;">resource consisting of one or more consecutive <a>CMAF Fragment</a>s from a <a>CMAF Track</a> (<a href="#cmaf-fragments-segments-and-chunks"></a>)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><dfn>CMAF Segment Duration</dfn></td>
<td style="text-align: left;">sum of the media sample durations in a <a>CMAF Segment</a>.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><dfn>Low Latency Decodable Chunk</dfn></td>
<td style="text-align: left;">resource that contains a single Movie Fragment Box and Media Data Box that contains a sequential and contiguous subset of the samples of a <a>CMAF Fragment</a> to allow faster packaging and delivery of video samples during live encoding. (<a href="#cmaf-low-latency-delivery-chunks"></a>).</td>
</tr>
<tr class="even">
<td style="text-align: left;"><dfn>CMAF Selection Set</dfn></td>
<td style="text-align: left;">set of <a>CMAF Switching Set</a>s, where each Switching Set encodes an alternative aspect of the same program over the same time period, only one of which is intended to be played at a time, e.g. a different language or codec (<a href="#cmaf-track-selection-sets-and-late-binding"></a>).</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><dfn>CMAF Switching Set</dfn></td>
<td style="text-align: left;">set of <a>CMAF Track</a>s, each of which is an alternative encoding of the same source content constrained to enable seamless Track switching and decoding (<a href="#cmaf-track-switching-sets-and-adaptive-switching"></a>).</td>
</tr>
<tr class="even">
<td style="text-align: left;"><dfn>CMAF Track</dfn></td>
<td style="text-align: left;">sequence of <a>CMAF Segment</a>s of the same media type ordered by presentation time, as well as the <a>CMAF Header</a> necessary to initialize that sequence of Segments. (<a href="#cmaf-tracks"></a>)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><dfn>CMAF Track File</dfn></td>
<td style="text-align: left;"><a>CMAF Track</a> stored in a single ISO BMFF file containing a <a>CMAF Header</a> and all <a>CMAF Segment</a>s in sequence, starting from decode time zero.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><dfn>CMAF Track Duration</dfn></td>
<td style="text-align: left;">sum of the <a>CMAF Segment Duration</a>s of all <a>CMAF Segment</a>s in a <a>CMAF Track</a></td>
</tr>
<tr class="odd">
<td style="text-align: left;">I-Picture</td>
<td style="text-align: left;">independently decodable picture</td>
</tr>
<tr class="even">
<td style="text-align: left;"><dfn>Manifest</dfn></td>
<td style="text-align: left;">document that describes one or more <a>CMAF Presentation</a>s (<a href="#manifest"></a>)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><dfn>Player</dfn></td>
<td style="text-align: left;">component of the CMAF application model responsible for interpreting a <a>Manifest</a>, requesting <a>CMAF Segment</a>s, and rendering a <a>CMAF Presentation</a></td>
</tr>
<tr class="even">
<td style="text-align: left;">Required</td>
<td style="text-align: left;"><a>CMAF Track</a> and Media Profile required by a Presentation Profile to be included in each <a>CMAF Presentation</a> conforming to that Presentation Profile.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Sample</td>
<td style="text-align: left;"><p>all of the media data in a <a>CMAF Segment</a> associated with a single timestamp</p>
<p>Note: The term “sample” is also used in the context of video to refer to the spatial samples of an image, and in the context of audio to refer to higher frequency temporal waveform samples. Unless qualified, the term “Sample” refers a file format media sample.</p></td>
</tr>
<tr class="even">
<td style="text-align: left;">Sub-sampling</td>
<td style="text-align: left;">video encoding using an exact fraction of the number of spatial samples in the source video, i.e. the fraction yields a spatial sample count that is an integer or even integer, as specified in <a href="#audio-tracks"></a>.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Sync Sample</td>
<td style="text-align: left;">media sample that starts an independent sequence of samples; if decoding starts at the sync sample, it and succeeding samples in decoding order can all be correctly decoded, and the resulting set of decoded samples forms the correct presentation of the media starting at the decoded sample that has the earliest composition time.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Video Profile</td>
<td style="text-align: left;">encoding constraints on a Track that may be signaled with a profile identifier and relied on by <a>Player</a>s for selection of compatible Tracks.</td>
</tr>
</tbody>
</table>
</section>
<section>
<h2>Abbreviations and Acronyms</h2>
<p>For the purposes of this Media Application Format, the following abbreviations apply.</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">AU</td>
<td style="text-align: left;">Audio decoding Access Unit</td>
</tr>
<tr class="even">
<td style="text-align: left;"><abbr title="Coded Video Sequence starting with SAP type 1 or 2 picture, and including all samples prior to the next SAP type 1 or 2 picture">CVS</acronym></td>
<td style="text-align: left;">Coded Video Sequence starting with SAP type 1 or 2 picture, and including all samples prior to the next SAP type 1 or 2 picture</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><abbr title="MPEG Dynamic Adaptive Streaming over HTTP">DASH</abbr></td>
<td style="text-align: left;">MPEG Dynamic Adaptive Streaming over HTTP (ISO/IEC 23009-1)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><abbr title="Instantaneous Decoder Refresh">IDR</abbr></td>
<td style="text-align: left;">Instantaneous Decoder Refresh (picture)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><abbr title="MPEG Common Encryption Key Identifier">KID</abbr></td>
<td style="text-align: left;">MPEG Common Encryption Key Identifier</td>
</tr>
<tr class="even">
<td style="text-align: left;"><abbr title="Network Adaptation Layer">NAL</abbr></td>
<td style="text-align: left;">Network Adaptation Layer</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><abbr title="Picture Parameter Set">PPS</abbr></td>
<td style="text-align: left;">Picture Parameter Set</td>
</tr>
<tr class="even">
<td style="text-align: left;"><abbr title="Supplemental Enhancement Information">SEI</abbr></td>
<td style="text-align: left;">Supplemental Enhancement Information</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><abbr title="Sequence Parameter Set">SPS</abbr></td>
<td style="text-align: left;">Sequence Parameter Set</td>
</tr>
<tr class="even">
<td style="text-align: left;"><abbr title="Video Coding Layer">VCL</abbr></td>
<td style="text-align: left;">Video Coding Layer</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><abbr title="Video Parameter Set">VPS</abbr></td>
<td style="text-align: left;">Video Parameter Set</td>
</tr>
</tbody>
</table>
</section>
</section>
<section>
<h2>Document Organization</h2>
<p>Document sections are ordered from general to specific, starting with the scope of CMAF and basic definitions, then the media container specification, Common Encryption for all Track types, then specific Track formats.</p>
<p><a href="#cmaf-architecture"></a> describes the segmented media playback model and the associated objects defined by the CMAF.</p>
<p><a href="#the-common-media-application-format-container"></a> describes the ISO container format associated with the Common Media Format brand.</p>
<p><a href="#common-encryption-of-tracks"></a> details how digital rights management encryption is applied to the Common Media Format.</p>
<p><a href="#video tracks"></a> describes the video track in relation to the CMAF container and the constraints on each video format.</p>
<p><a href="#audio-tracks"></a> describes audio tracks, their container constraints, elementary stream sample format, encoding constraints of required and optional audio formats</p>
<p><a href="#subtitles-and-captions"></a> CMAF supports CEA-608, CEA-708 and WebVTT for carrying timed text information.</p>
<p><a href="#cmaf-presentations-and-media-profiles"></a> specifies encoding constraints and brands intended to signal core interoperability points.</p>
<p><a href="#cmaf-compatible-tracks-and-media-profiles"></a> Specification and Registration of CMAF Compatible Media Profiles and Track bindings.</em></p>
<p><a href="#subsampling-of-tracks-in-track-switching-sets"></a>video encoding guidelines for spatial and temporal subsampling for adaptive streaming.</p>
<p><a href="#example-encoding-parameters-for-conformant-cmaf-switching-sets"></a></p>
</section>
<section>
<h2>Document Notation and Conventions</h2>
<p>The following terms are used to specify conformance elements of this specification. These are adopted from the ISO/IEC Directives, Part 2, Annex H [ISO-P2H ISO-P2H]. For more information, please refer to those directives.</p>
<ul>
<li><p>SHALL and SHALL NOT indicate requirements strictly to be followed in order to conform to the document and from which no deviation is permitted.</p></li>
<li><p>SHOULD and SHOULD NOT indicate that among several possibilities one is recommended as particularly suitable, without mentioning or excluding others, or that a certain course of action is preferred but not necessarily required, or that (in the negative form) a certain possibility or course of action is deprecated but not prohibited.</p></li>
<li><p>MAY and NEED NOT indicate a course of action permissible within the limits of the document.</p></li>
</ul>
<p>Terms defined to have a specific meaning within this specification will be capitalized, e.g. “Track”, and should be interpreted with their general meaning if not capitalized.</p>
</section>
<section>
<h2>CMAF Architecture</h2>
<section>
<h2>Fundamental Concepts</h2>
<section>
<h2>Interoperability, Profiles, and Brands</h2>
<p><a>CMAF Presentation</a>s are intended to provide reliable encoding, decoding, and playback by:</p>
<ol type="1">
<li><p>Defining standard Presentation Profiles that include Required audio, video, and subtitle Tracks and Track Sets that can be decoded by all <a>Player</a>s that support that Presentation Profile. Other <a>CMAF Track</a>s and CMAF Compatible Tracks can be additionally included in the manifest for additional features that may not be supported by all players.</p></li>
<li><p>Defining Media Profiles and ISOM compatibility brands for CMAF interoperability using widely deployed MPEG codecs and encoding parameters. An extension method is also defined to specify and register other Media Profile brands for CMAF compatible media profiles.</p></li>
<li><p>Defining the CMAF Container ISOM brand (‘cmfc’), that indicates a Track containing that brand conforms to the constraints of a CMAF container, Track, Fragments, and optionally, Common Encryption.</p></li>
</ol>
<p>A Presentation that meets the constraints of a Presentation Profile in ‎A.1 is said to be <a>CMAF Presentation</a>-compliant.</p>
<p>A Track that meets the constraints of either a Media Profile in ‎A.2, ‎A.3, or ‎A.4 is said to be <a>CMAF Track</a>-compliant.</p>
<p>A Track that meets the constraints of ‎Annex B. is said to be CMAF Container-compliant.</p>
</section>
<section>
<h2 id="media-object-model">Media Object Model</h2>
<p>The CMAF media objects delivered for playback are Segments, which contain one or more Fragments containing the media data itself, and <a>CMAF Header</a>s, which carry initialization information common to a group of Segments. CMAF also defines logical media objects: Tracks, Switching Sets, Selection Sets, and Presentations. See Figure 1.</p>
<p>A <a>Manifest</a> is included in the application model to describe media objects as Presentations and enable playback (see Figure 1) , but the specific implementation of the <a>Manifest</a> is beyond the scope of this specification. The same media objects may be described by multiple manifest formats, and may be combined with different media objects in different Presentations using different <a>Manifest</a>s. Reuse of the same media objects in different Presentations and <a>Manifest</a>s greatly improves encoding, storage and delivery efficiency.</p>
<p>It is possible to organize Presentations in sequences and other relationships referred to in this specification as a <a>Composition</a>. Composition examples include a sequence of programs and advertisements in a channel, an ad presentation that overlays a program presentation, a programmatic selection of a sequence of <a>Manifest</a>s, manual selection of Presentations from a menu, etc. CMAF defines the encoding and organization of Segments and Tracks within each Presentation, but does not define or constrain the <a>Composition</a> of multiple Presentations.</p>
<p>Subsections of <a href="#cmaf-architecture"></a> describe the important constraints on these media objects. Subsequent Sections of CMAF specify the container and track formats in detail.</p>
<p><img src="media/cmaf-media-object-model.png" width="620" height="400" alt="CMAF media object model" /></p>
<p><span id="_Ref432004518" class="anchor"><span id="_Toc447628025" class="anchor"></span></span>Figure 1 - CMAF Media Object Model</p>
</section>
<section>
<h2><a>CMAF Fragment</a>s, Segments, and Chunks</h2>
<section>
<h2>Introduction</h2>
<p><a>CMAF Track</a>s are encoded as a <a>CMAF Header</a> followed by time-sequential Fragments containing media samples and their metadata. Independently decodable Fragments improve interoperability by allowing media decoding systems to render continuous media streams regardless of the delivery method or adaptive switching between Tracks in a Switching Set.</p>
<p>One or more complete Fragments in sequence are contained in a Segment. A Segment is usually identified by a URL that can be used to reference it by servers, CDNs, and <a>Manifest</a>s. The ability of many Presentations, <a>Manifest</a>s, and CDN edge caches to refer to the same <a>CMAF Segment</a> by the same URI greatly improves Internet streaming efficiency.</p>
<p>For low latency delivery of Fragments, the samples of a Fragment can be delivered as they are encoded, in short duration <a>Low Latency Decodable Chunk</a>s, each with a metadata header to enable parsing and decoding. Chunk support is optional for servers and players. The same samples are available later as a Segment, after the Segment is fully encoded.</p>
</section>
<section>
<h2>Fragments</h2>
<p><a>CMAF Fragment</a>s are ISO Base Media movie fragments conforming to the CMAF specification, and are the primary media objects encoded and decoded. <a>CMAF Fragment</a>s enable live encoding, adaptive streaming, and late binding by segmenting the media by time and type. Fragments are logically or physically combined into <a>CMAF Track</a>s that start with a <a>CMAF Header</a>. Each Fragment contains a Track Fragment Decode Time Box (‘tfdt’) that determines its sequence within a <a>CMAF Track</a>.</p>
<p><a>CMAF Fragment</a> constraints and relationships are specified in CMAF as Tracks. Tracks can conform to Switching Sets and Selection Sets that are synchronized in a Presentation. A Presentation can be described by one or more <a>Manifest</a>s. A <a>CMAF Segment</a> is a resource consisting of one or more consecutive and complete <a>CMAF Fragment</a>s. See section 2 of [<a href="#RFC7231"><em>RFC7231</em></a>] for the definition and identification of a resource.</p>
<p>Each <a>CMAF Segment</a> is normally identified with a URI in <a>Manifest</a>s, in some cases including a byte range.</p>
<p><a>CMAF Fragment</a>s and the Segments that contain them are additionally constrained in order to conform to a Track, Switching Set, Selection Set, and Presentation; as specified in those sections below.</p>
</section>
<section>
<h2><a>CMAF Segment</a>s</h2>
<p>One or more <a>CMAF Fragment</a>s is contained in a <a>CMAF Segment</a>, which is then typically identified by URI used by servers and <a>Manifest</a>s to describe a <a>CMAF Presentation</a>.</p>
<p>CMAF video Fragment durations are typically 2-6 seconds for coding efficiency, and <a>CMAF Segment</a> durations are typically not greater than 10-12 seconds to reduce delivery latency and bitrate rate adaptation response time. Subtitle Segment durations are usually similar to video Segment durations in live Presentations to avoid increasing video delay. A single Subtitle <a>CMAF Segment</a> in a prerecorded Presentation can have a duration up to the duration of the Track that contains it.</p>
<p>See Sections ‎7 through ‎11 for additional details on the construction of <a>CMAF Fragment</a>s and <a>CMAF Track</a>s of different media types.</p>
</section>
<section>
<h2><a>Low Latency Decodable Chunk</a>s</h2>
<p><a>Low Latency Decodable Chunk</a>s are resources used to deliver media samples before they can be packaged in <a>CMAF Segment</a>s during live encoding and streaming.</p>
<p><a>Low Latency Decodable Chunk</a>s are typically only available until a <a>CMAF Segment</a> containing all of the same samples becomes available, whereas <a>CMAF Segment</a>s are typically available for longer periods.</p>
<p>Origin servers that package Low Latency Delivery Packages are expected to assign them a short time-to-live for efficient use of content delivery network caches.</p>
<p>Example of Low Latency Delivery Package use:</p>
<blockquote>
<p>A four second Coded Video Sequence in a <a>CMAF Segment</a> requires at least four seconds after encoder output of the first video sample before the <a>CMAF Segment</a> can be packaged for streaming. The same samples could be packaged for streaming in a half-second when sequentially packaged as eight Low Latency Delivery Packages of half-second duration.</p>
<p>Streaming protocols that enable server “push”, such as HTTP/2, broadcast, multicast, etc. can deliver multiple Low Latency Delivery Packages in response to a single request as soon as they are available; thus reducing streaming delay to roughly one second, plus any additional buffering that may be required for bitrate adaptation, network jitter, etc.</p>
</blockquote>
</section>
</section>
<section>
<h2 id="cmaf-tracks"><a>CMAF Track</a>s</h2>
<p>A <a>CMAF Track</a> is a continuous sequence of <a>CMAF Segment</a>s in presentation time order preceded by a <a>CMAF Header</a>. The <a>CMAF Header</a> contains a Movie Box (‘moov’) sufficient to process and present all <a>CMAF Segment</a>s in the <a>CMAF Track</a>.</p>
</section>
<section>
<h2 id="cmaf-track-files"><a>CMAF Track File</a>s</h2>
<p>A <a>CMAF Track File</a> is a complete <a>CMAF Track</a> stored in a single ISOM BMFF file. The <a>CMAF Track File</a> starts with a <a>CMAF Header</a> followed by a continuous sequence of <a>CMAF Fragment</a>s in decode order, and the first <a>CMAF Fragment</a> has a BaseMediaDecodeTime of zero.</p>
<p><a>CMAF Segment</a>s may be identified by the file URI and a byte range. <a>CMAF Segment</a> byte ranges may be listed in a manifest for determined from a delivery format defined method, such as download of a Segment Index Box (‘sidx’), that is out of scope of CMAF.</p>
</section>
<section>
<h2 id="cmaf-track-switching-sets-and-adaptive-switching"><a>CMAF Track</a> Switching Sets and Adaptive Switching</h2>
<section>
<h2 id="introduction-2">Introduction</h2>
<p>A <a>CMAF Switching Set</a> is a collection of <a>CMAF Track</a>s, where each Track is a different encoding of the same source content. Switching Sets are constrained to simplify switching between Tracks by simply sequencing their <a>CMAF Segment</a>s during playback to adapt to network and other environmental conditions. Switching Set constraints also minimize visible discontinuities when <a>CMAF Track</a>s are switched.</p>
<p>The description of <a>CMAF Switching Set</a>s and the <a>CMAF Track</a>s they contain in a <a>Manifest</a> is out of scope of the CMAF specification, but <a>Manifest</a>s are expected to contain enough <a>CMAF Track</a> and Segment information to enable automatic adaptive selection by <a>Player</a>s.</p>
</section>
<section>
<h4 id="decoding-adaptively-switched-segments">Decoding Adaptively Switched Segments</h4>
<p>Adaptively delivered <a>CMAF Track</a> is a timed sequence of <a>CMAF Header</a>s and Fragments selected from multiple <a>CMAF Track</a>s in a Switching Set. Typical ISOBMFF file parsers and decoders can decode the concatenated sequence of <a>CMAF Fragment</a>s the same as a fragmented movie file, with the possible exception of needing to re-initialize the decoder at switch points, as though switching unrelated tracks in a multitrack file ISO Media file.</p>
<p>An adaptive streaming <a>Player</a> typically “switches Tracks”, i.e. selects the next <a>CMAF Segment</a> from a different <a>CMAF Track</a> in the Switching Set, to adapt to the current throughput of the network and maintain a safe level in the <a>Player</a>’s buffers that will prevent an interruption in the presentation.</p>
<p>The encoding constraints of the <a>CMAF Track</a>s in a Switching Set determine if the Adaptively Switched Track requires re-initialization at adaptive switch points.</p>
<ul>
<li><p>If a Switching Set is encoded with bitstream switching constraints, a continuous sequence of <a>CMAF Fragment</a>s may be delivered and decoded.</p></li>
<li><p>If a Switching Set is not encoded with bitstream switching constraints, a <a>CMAF Header</a> must be processed prior to each sequence of <a>CMAF Fragment</a>s from that <a>CMAF Track</a>.</p></li>
</ul>
<p>Processing the <a>CMAF Header</a> causes re-initialization of the parsing, decoding, decryption, and display parameters contained in the <a>CMAF Header</a>. This can be similar to switching files if all parameters are reset, in which case it might not be seamless. <a>Player</a>s can minimize the impact by comparing parameters and only changing configurations that need to be changed, e.g. the video decoder need not be reconfigured for a lower profile or level. Decoding and video scaling parameters in the <a>CMAF Header</a> must be set before decoding and rendering the CMAF video Fragments from that non-bitstream switchable Switching Set. See section [‎7.3.8] for details on <a>CMAF Switching Set</a>s.</p>
<p>The normative behavior of video decoders is well-specified, but display processing is considered out of scope, i.e. conversion of YCbCr 4:2:0 subsamples from the decoder to some number of pixels in a colorspace appropriate for a particular display. Adaptive display processors require unspecified but typical behavior to scale different video spatial sampling used to encode different <a>CMAF Fragment</a>s to the same display size and position. <a>CMAF Track</a>s in a Switching Set are constrained to subsample, frame, and crop the source video so it can be rescaled with precise registration to make switching as seamless as possible. The constraints specified for <a>CMAF Track</a>s and Switching Sets determine the behavior required by display processors, but display processing and other <a>Player</a> requirements are not directly specified by CMAF.</p>
<p>CMAF video Tracks require re-initialization if they store any video decoding parameter sets only in the <a>CMAF Header</a> (e.g. ‘avc1’ and ‘hvc1’ sample entries and video sample formats).</p>
<p>Video <a>CMAF Fragment</a>s from the same Switching Set, encoded with parameter sets in each <a>CMAF Fragment</a> (e.g. ‘avc3’ and ‘hev1’ sample entries and video sample formats) can be decoded without re-initialization, the same as a <a>CMAF Track</a> that is not switched.</p>
</section>
</section>
<section>
<h3 id="cmaf-track-selection-sets-and-late-binding"><a>CMAF Track</a> Selection Sets and Late Binding</h3>
<p>A <a>CMAF Selection Set</a> is a set of <a>CMAF Switching Set</a>s, where each Switching Set encodes an alternative aspect of the same program over the same time period – for example, different audio languages, video camera angles, video formats, or codecs.</p>
<p>CMAF <a>Player</a>s are expected to automatically select one Switching Set from each Selection Set at the start of playback based on <a>Player</a> compatibility and user preferences. Users or playback applications may switch between Switching Sets in a Selection Set during playback, but seamless presentation is not expected, either because the content differs (e.g. language or camera), or because <a>CMAF Segment</a> time alignment and decoding are not constrained to decode seamlessly. The process of selecting independently stored <a>CMAF Track</a>s for synchronized presentation is called “late binding”. Late binding allows <a>CMAF Track</a>s to be encoded once and used in many different combinations. Late binding is much more efficient than “early binding” each combination of audio, video, subtitles, advertising, etc. packaged in a multiplexed track has to be separately identified and stored, duplicating much of the same information in different combinations, resulting in higher storage costs and less efficient CDN caching.</p>
<p>Typically, only one Track from each Selection Set is presented at a time. Multiple audio and video Selection Sets can be combined in a <a>CMAF Presentation</a>, using multiple decoders, for instance to mix a separate audio dialog Tracks with a Track containing music and effects, or present one video Selection Set on top of another as “picture in picture”.</p>
<p>The description of Selection Sets in a <a>Manifest</a> is not specified by the CMAF specification, however each <a>Manifest</a> format is expected to provide sufficient information to enable <a>Player</a>s to automatically select optimal <a>CMAF Track</a> Switching Sets from <a>CMAF Selection Set</a>s.</p>
</section>
<section>
<h3 id="cmaf-presentation-and-timing-model"><a>CMAF Presentation</a> and Timing Model</h3>
<p>A <a>CMAF Presentation</a> is a group of one or more synchronized Selection Sets that are intended for simultaneous presentation. There is typically one Selection Set for each media type (audio, video, or subtitles), which may contain only one Switching Set if no alternative content is available.</p>
<p><img src="media/cmaf-timeline-synchronization-model.png" width="624" height="350" alt="CMAF timeline synchronization model" />A <a>CMAF Presentation</a> may contain more than one Selection Set of a particular media type to indicate that one <a>CMAF Track</a> from each Selection Set SHOULD be presented at the same time. For instance, separate Selection Sets for audio background sound and audio dialog would indicated one of each type are intended to be decoded and mixed for in a Presentation. Similarly, separate video Selection Sets could be used to indicate two video Tracks that are intended to be decoded and presented simultaneously as picture in picture, or picture on picture, etc.</p>
<p>Note that ISO Base Media video tracks have both a decode timeline and a composition timeline.</p>
<p>There are multiple timelines involved in synchronizing a <a>CMAF Presentation</a>. Each timeline has a timescale in units per second, and an origin where the measure equals zero.</p>
<ol type="1">
<li><p>Track decode time</p></li>
<li><p>Track composition time</p></li>
<li><p>Movie or Presentation time</p></li>
<li><p>UTC time, either at the time of encoding, or at the time of playback (this timeline may not be relevant for VOD Presentations)</p></li>
</ol>
<p>CMAF abstracts the timing model of ISO Media files to apply to late binding, live presentations, and the reuse of <a>CMAF Segment</a>s in multiple <a>CMAF Presentation</a>s.</p>
<p>The ISO Media decode timeline is defined by the decode time and duration of each sample in a track. The accumulated decode time is the sum of all previous sample durations in that track in their stored order. The first sample in each track in an ISO Media file has a decode time of zero.</p>
<p>In the case of <a>CMAF Track</a>s, the first Fragment may have a non-zero baseMediaDecodeTime in the Track Fragment Decode Time Box (‘tfdt’), but baseMediaDecodeTime values equals the sum of prior samples’ decode durations added to the Track’s first Fragment baseMediaDecodeTime value for the duration of the <a>CMAF Track</a>. Decode time is considered continuous in each track in order to maintain synchronization between tracks on a common timeline.</p>
<p>In the case of an ISO Media file, multiple tracks are synchronized to a movie timeline that starts at time zero by definition, and the first sample of each track is also defined to start at decode time zero. An edit list in each track can offset the decode time relative to the movie time in the event that presentation should not start with the first recorded sample, or that sample is not synchronized with the start time of the other tracks aligned to movie time zero.</p>
<p>Video tracks in ISO Media also have a composition timeline created by sample reordering in the video codec that changes the composition sequence and can add a composition delay to the track relative to the decode timeline (typically a few sample durations, depending on picture removal delay from the video decoder).</p>
<p>In the case of CMAF, video tracks use negative composition offsets where necessary to remove composition delay, so that the presentation time of <a>CMAF Fragment</a>s is equal to their decode time; thus removing that distinction and allowing the baseMediaDecodeTime in the Track Fragment Decode Time Box (‘tfdt’) to be used as <a>CMAF Track</a> and Fragment presentation time. Because <a>CMAF Fragment</a>s contain complete coded video sequences (usually one), sample reordering happens within the <a>CMAF Fragment</a> duration and does not change the first or last sample presentation time. If alternative <a>CMAF Track</a>s in a <a>CMAF Switching Set</a> have different picture removal delays due to different encoded picture size and number of reference frames used, it will not result in different composition delays between <a>CMAF Track</a>s.</p>
<p>A <a>CMAF Presentation</a> has a presentation timeline similar to the movie timeline of a file. It will typically need to specify the non-zero decode time of each Switching Set at zero on the <a>Manifest</a>’s presentation timeline. The <a>Manifest</a> can also link presentation time zero to a specified UTC time to indicate the earliest availability of <a>CMAF Segment</a>s that are being encoded or made available in realtime.</p>
<p>During random access and “trick play” (fast forward, reverse, slow motion, etc.), the Track Fragment Decode Time Box can be used to calculate the CMAF presentation time from the <a>CMAF Track</a> time by applying the presentation time offset in reverse. Discontinuities in <a>CMAF Track</a> timelines are considered a new <a>CMAF Track</a> in a new <a>CMAF Presentation</a> that must specify the <a>CMAF Track</a>’s decode time at the start of the <a>CMAF Presentation</a> (similar to a DASH Period).</p>
</section>
<section>
<h3 id="manifest"><a>Manifest</a></h3>
<p>Although CMAF does not define the form or the content of the <a>Manifest</a>, it does define its role. A <a>Manifest</a> is a document that describes one or more <a>CMAF Presentation</a>s; e.g. the MPEG DASH MPD.</p>
<p>A <a>Manifest</a> provides the <a>Player</a> with enough information to select, initialize, and synchronize the <a>CMAF Track</a>(s) to be played, and identify <a>CMAF Header</a>s and Segments, and possibly download them synchronously. <a>CMAF Track</a>s and Fragments contain sufficient information to enable decryption, decoding, synchronization, and rendering once <a>CMAF Fragment</a>s are located in <a>CMAF Segment</a>s. A <a>Manifest</a> can also provide information on delivery protocol, network management, authorization, license acquisition, etc. in addition to Segment identification and Presentation description, but those are optional for the hypothetical presentation model.</p>
<p>A CMAF <a>Manifest</a> is responsible for describing the combination and synchronization of independently encoded <a>CMAF Switching Set</a>s grouped in Selection Set to form a synchronized multimedia presentation. A common presentation timeline, similar to an ISO Media movie timeline, can be used to synchronize the timestamps of each <a>CMAF Track</a> so that a CMAF <a>Player</a> can “late bind” selected audio, video, and subtitles. In cases where there are multiple <a>CMAF Track</a>s in a Switching Set, a CMAF <a>Player</a> can seamlessly switch between <a>CMAF Track</a>s to optimize for the network bandwidth and device capability.</p>
<p>Presentation <a>Manifest</a>s are expected to include any recorded audio offset edit list duration in <a>Manifest</a> synchronization information so that audio Switching Set synchronization is precisely described relative to video to the accuracy of the media timescales. A <a>Manifest</a> may specify a presentation start time referencing wall clock time, e.g. UTC time; typically for a live Presentation.</p>
<p>A <a>Manifest</a> may specify a growing Presentation duration for each Selection Set and its contained Switching Sets and Tracks during live encoding and playback.</p>
<p>A <a>Manifest</a> may remove earlier Segments from a Presentation. A <a>Manifest</a> may specify an availability start and end time (in wall clock time) for an entire Presentation.</p>
<p><a>Manifest</a>s and Compositions of <a>Manifest</a>s may include additional information to indicate different start and end times within the <a>CMAF Presentation</a> to begin and end media playback.</p>
</section>
</section>
<section>
<h2 id="hypothetical-player-model">Hypothetical <a>Player</a> Model</h2>
<section>
<h3 id="overview">Overview</h3>
<p><a>Player</a> implementers should note that CMAF provides the following affordances:</p>
<ul>
<li><blockquote>
<p>A <a>CMAF Segment</a> is well-suited to network transfer because it is a compact, self-contained set of media samples that covers a single, short period of time, and can be sequenced with other <a>CMAF Segment</a>s in a single track parser/decoder and browser media source buffer without additional bitstream splicing and editing.</p>
</blockquote></li>
<li><blockquote>
<p>Each <a>CMAF Segment</a> contains a media timestamp in the form of BaseMediaDecodeTime in the Track Fragment Decode Time Box (‘tfdt’), which allows individual <a>CMAF Segment</a>s and <a>CMAF Track</a>s that start with arbitrary timestamps to be synchronized to a presentation timeline</p>
</blockquote></li>
<li><blockquote>
<p>The movie fragment box (‘moof') and the sample data contain everything necessary to render the samples at the correct place on the playback timeline after a Track has been initialized with a <a>CMAF Header</a>.</p>
</blockquote></li>
<li><blockquote>
<p><a>CMAF Track</a>s can be separately selected and delivered by a player, then synchronized at presentation time, thus allowing each player to customize the presentation for the device, network, and user.</p>
</blockquote></li>
<li><blockquote>
<p>The IDR picture at the start of each video <a>CMAF Segment</a> can be obtained with minimal transfer activity for fast forward or fast reverse streaming.</p>
</blockquote></li>
<li><blockquote>
<p>Selection Sets and single track <a>CMAF Segment</a>s allow alternative content to be offered for playback without requiring the <a>Player</a> to transfer content that it does not intend to play.</p>
</blockquote></li>
<li><blockquote>
<p>Switching Sets allows alternative bitrate and resolution encodings of the same content to be seamlessly presented through a single video decoder.</p>
</blockquote></li>
<li><blockquote>
<p>The use of Common Encryption supports access to the same content by multiple decryption key delivery systems.</p>
</blockquote></li>
<li><blockquote>
<p>The 'emsg' box allows Segments to signal application-defined Track events with low latency during live presentations without requiring frequent <a>Manifest</a> downloads.</p>
</blockquote></li>
</ul>
</section>
<section>
<h3 id="adaptive-streaming-playback-informative">Adaptive Streaming Playback (Informative)</h3>
<p>In order to play an adaptive streaming Presentation, a <a>Player</a> typically:</p>
<ul>
<li><p>parses the <a>Manifest</a> and selects Selection Sets of media types it can present on that device (e.g. audio only, or audio/video/subtitles/Picture in Picture, etc.).</p></li>
<li><p>compares Switching Set information to <a>Player</a>, decoder, display, DRM, etc. capabilities to determine the compatible Switching Sets in those Selection Sets it can play.</p></li>
<li><p>selects the most preferred and compatible Switching Set in each Selection Set, sometimes based on stored user preferences (language, accessibility, rating, stereo or multichannel audio, etc.).</p></li>
<li><p>selects an initial Track from each selected Switching Set, usually based on estimated network bandwidth, rapid start heuristics, display size, etc.</p></li>
<li><p>initializes, decodes, synchronizes, and presents the selected Tracks, and automatically requests each <a>CMAF Segment</a> in sequence from that Switching Set, adapting requested bitrates to maintain continuous playback within the limitations of network throughput.</p></li>
</ul>
<p>Live Presentation playback is typically optimized for low latency, so a player only buffers a few seconds of each selected <a>CMAF Track</a> in the player to minimize presentation delay. A different bitrate could be selected for each <a>CMAF Segment</a> requested from a Switching Set in order to prevent buffer underflow in the player while maximizing media quality. Once a live presentation delay and buffer duration is selected, the delay can’t be changed without halting playback and rebuffering, or decoding at a speed faster or slower than normal, which is usually not acceptable. Measurements of network latency, jitter, throughput rate, throughput variation, Segment duration variation, and server/client clock synchronization can help a player select an optimal presentation delay and next Segment bitrates to request. To minimize visible changes between <a>CMAF Segment</a>s encoded at different bitrates, live <a>CMAF Switching Set</a>s may include more Tracks with smaller bitrate differences, for instance an increase of 30% to the next highest bitrate Track.</p>
<p>Recorded (video on demand) Presentation playback is typically optimized for infrequent switching and infrequent rebuffering. <a>Player</a>s can accumulate several minutes of buffer time during playback by selecting lower bitrate Segments that can be downloaded faster than they are decoded. Once sufficient buffer time has accumulated; an optimum bitrate can be selected. Tracks may be rarely switched because the long player buffer duration averages short term changes in network throughput. Because bitrate changes are less frequent and therefore less noticeable, fewer Tracks with larger bitrate differences may be considered acceptable in order to reduce encoding and storage, for instance an increase of 50% to the next highest bitrate Track.</p>
<p>When <a>Player</a>s adaptively switch CMAF video Tracks, they typically rescale the decoded and cropped image to the <a>Player</a> selected display aperture. Alternative Tracks in a Switching Set are typically encoded at lower resolutions (subsampled) in proportion to their bitrate. If video samples are stored in ‘avc1’ or ‘hvc1’ format, a <a>CMAF Header</a> must be processed before the first <a>CMAF Segment</a> from a new Track to reinitialize the decoder with the correct decoding parameters for that Track. If video samples are stored in ‘avc3’ or ‘hev1’ format, reinitialization is not required because each <a>CMAF Fragment</a> contains the necessary decoding parameters in the first video sample.</p>
<p>See Appendix B for recommendations on encoding adaptive Switching Sets.</p>
</section>
</section>
</section>
<section>
<h2 id="the-common-media-application-format-container">The Common Media Application Format Container</h2>
<section>
<h2 id="introduction-3">Introduction</h2>
<p>The Common Media Application Format Container is derived from the ISO Base Media File Format, and is primarily a profile of that format.</p>
</section>
<section>
<h2 id="cmaf-brands">CMAF Brands</h2>
<p>The CMAF container file type brand is ‘cmfc’. The requirements of this brand include the requirements of the brand ‘iso9’ [<a href="#ISOMREF"><em>ISOM</em></a>]. It also includes boxes specified in Common Encryption [<a href="#CENCREF"><em>CENC</em></a>], [DASH], MPEG-4 Part 15 for storage of NAL Structure video [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>], and those boxes defined by referenced audio specifications, as defined in <a href="#audio-tracks"></a>.</p>
<p>The brand ‘cmfc’ SHALL be listed in compatible_brands. The brand ‘iso9’ SHALL be listed in compatible_brands. If ‘cmfc’ is the major_brand, the minor_version SHALL be 0.</p>
<p>Note: File readers should read possible future versions of CMAF that increment the minor_version number.</p>
<p>A <a>CMAF Track</a> SHALL also contain a CMAF Media Profile brand specified in ‎Annex A.</p>
<p>A CMAF Compatible Track MAY also include the ‘cmfc’ container brand if it contains an externally specified Media Profile brand that conforms to container, Track, and media requirements as specified in ‎Annex B.</p>
<p>If ‘cmfc’ is the major_brand, file names SHOULD use the file extension “*.cmff”, and use the Internet Media Type (MIME type) registered for that extension. If ‘iso9’ or another brand is the major_brand, then file names SHOULD use the file extension and Internet Media Type specified for that brand, e.g. *.mp4, *.3gp, *.uvu, etc.</p>
<p><a>CMAF Segment</a>s MAY be identified by the ISO Media segment-type brand ‘cmfs’ with the minor_version 0.</p>
<p>The primary constraints of the ‘cmfc’ file type brand are described in Sections ‎7.3.4 and ‎7.3.5.</p>
<p>The media samples contained in <a>CMAF Segment</a>s can also be packaged and delivered in smaller <a>Low Latency Decodable Chunk</a>s. See Section ‎7.3.7.</p>
<p>Additional container constraints are specified in this Section and in Sections ‎7 through ‎11 and ‎Annex A. that define audio, video, and subtitle Track formats and Track Profiles, and encryption of audio and video media data. Additional container and Track constraints are specified for Tracks included in Track Selection Sets (see ‎6.1.7) and Track Switching Sets (see ‎6.1.6).</p>
<p>Each Track has a <a>CMAF Header</a> associated with it, although the <a>CMAF Header</a> and <a>CMAF Segment</a>s might not be stored as an ISO Media file, if they are stored at all.</p>
</section>
<section><h2 id="cmaf-container-syntax">CMAF Container Syntax</h2>
<section>
<h3 id="cmaf-boxes">CMAF Boxes</h3>
<p>The Common Media Application Format Container brand ‘cmfc’ SHALL include the following boxes with nesting, optionality, and cardinality specified in the following table. Other boxes MAY be included. Boxes not specified here directly or by reference MAY be ignored.</p>
<p>Table 1 - Common Media Application Format brand ‘cmfc’ boxes</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">NL 0</th>
<th style="text-align: left;">NL 1</th>
<th style="text-align: left;">NL 2</th>
<th style="text-align: left;">NL 3</th>
<th style="text-align: left;">NL 4</th>
<th style="text-align: left;">NL 5</th>
<th style="text-align: left;">Format Req.</th>
<th style="text-align: left;">Specification</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">ftyp</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎7.5.1</td>
<td style="text-align: left;">File Type and Compatibility</td>
</tr>
<tr class="even">
<td style="text-align: left;">moov</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="#ISOMREF"><em>ISOM</em></a>] 8.2.1</td>
<td style="text-align: left;">Container for functional metadata</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">mvhd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="#ISOMREF"><em>ISOM</em></a>] 8.2.2</td>
<td style="text-align: left;">Movie header</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">trak</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">+</td>
<td style="text-align: left;">[<a href="#ISOMREF"><em>ISOM</em></a>] 8.3.1</td>
<td style="text-align: left;">Container for each track</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">tkhd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.3.2</td>
<td style="text-align: left;">Track header</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">edts</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">0/1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.6.5</td>
<td style="text-align: left;">Edit Box</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">elst</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">0/1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.6.6</td>
<td style="text-align: left;">Edit List Box</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">mdia</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.4</td>
<td style="text-align: left;">Track Media Information</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">mdhd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎7.5.7</td>
<td style="text-align: left;">Media Header</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">hdlr</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.4.3</td>
<td style="text-align: left;">Declares the media handler type</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">minf</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.4.4</td>
<td style="text-align: left;">Media Information container</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">vmhd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">0/1</td>
<td style="text-align: left;">Section ‎7.5.8</td>
<td style="text-align: left;">Video Media Header</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">smhd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">0/1</td>
<td style="text-align: left;">Section ‎7.5.9</td>
<td style="text-align: left;">Sound Media Header</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">sthd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">0/1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 12.6.2</td>
<td style="text-align: left;">Subtitle Media Header</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">dinf</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.7.1</td>
<td style="text-align: left;">Data Information Box</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">dref</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎7.5.10</td>
<td style="text-align: left;">Data Reference Box, declares source of media data in track</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">stbl</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.5</td>
<td style="text-align: left;">Sample Table Box, container for the time/space map</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">stsd</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎7.5.11</td>
<td style="text-align: left;">Sample Descriptions<br />
(See Table 2‑2 for additional detail.)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">stts</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎7.5.13</td>
<td style="text-align: left;">Decoding, Time to Sample</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">stsc</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎7.5.13</td>
<td style="text-align: left;">Sample-to-Chunk</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">stsz /<br />
stz2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎7.5.13</td>
<td style="text-align: left;">Sample Size Box</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">stco</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎7.5.13</td>
<td style="text-align: left;">Chunk Offset</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">elng</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">0/1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.4.6</td>
<td style="text-align: left;">Extended Language Tag</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">sgpd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">‎7.5.19</td>
<td style="text-align: left;">Sample Group Description Box</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">udta</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">0/1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.10.1</td>
<td style="text-align: left;">User Data Box</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">cprt</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">+</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.10.2</td>
<td style="text-align: left;">Copyright Box</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">kind</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">+</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8..10.4</td>
<td style="text-align: left;">Track Kind Box</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">mvex</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.8.1</td>
<td style="text-align: left;">Movie Extends Box</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">mehd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">0/1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.8.2</td>
<td style="text-align: left;">Movie Extends Header</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">trex</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">+<br />
(1 per track)</td>
<td style="text-align: left;">Section ‎7.5.15</td>
<td style="text-align: left;">Track Extends Box</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">pssh</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">[<a href="#CENCREF"><em>CENC</em></a>] 8.1</td>
<td style="text-align: left;">Protection System Specific Header Box</td>
</tr>
<tr class="even">
<td style="text-align: left;">styp</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.16.2</td>
<td style="text-align: left;">Segment Type</td>
</tr>
<tr class="odd">
<td style="text-align: left;">prft</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.16.5</td>
<td style="text-align: left;">Producer Reference Time</td>
</tr>
<tr class="even">
<td style="text-align: left;">emsg</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">Section ‎7.4.2</td>
<td style="text-align: left;">Event Message</td>
</tr>
<tr class="odd">
<td style="text-align: left;">moof</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">+</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.8.4</td>
<td style="text-align: left;">Movie Fragment</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">mfhd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎0</td>
<td style="text-align: left;">Movie Fragment Header</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">traf</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.8.6</td>
<td style="text-align: left;">Track Fragment</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">tfhd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎-</td>
<td style="text-align: left;">Track Fragment Header</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">tfdt</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.8.12</td>
<td style="text-align: left;">Track Fragment Base Media Decode Time</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">trun</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎7.5.18</td>
<td style="text-align: left;">Track Fragment Run Box</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">senc</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">0/1</td>
<td style="text-align: left;">[<a href="#CENCREF"><em>CENC</em></a>]</td>
<td style="text-align: left;">Sample Encryption Box</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">saio</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">* see note 1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.7.13</td>
<td style="text-align: left;">Sample Auxiliary Information Offsets Box</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">saiz</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">* see note 1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.7.12</td>
<td style="text-align: left;">Sample Auxiliary Information Sizes Box</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">sbgp</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.9.2</td>
<td style="text-align: left;">Sample to Group Box</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">sgpd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.9.3</td>
<td style="text-align: left;">Sample Group Description Box</td>
</tr>
<tr class="even">
<td style="text-align: left;">mdat</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">+</td>
<td style="text-align: left;">Section ‎7.5.19</td>
<td style="text-align: left;">Media Data container for media samples</td>
</tr>
</tbody>
</table>
<p><strong>Format Req.:</strong> indicates the number of boxes required to be present in the container, where ‘*’ means “zero or more” and ‘+’ means “one or more”. A value of &quot;0/1&quot; indicates only that a box may be present, but it may also be conditionally required as specified in the CMAF format or a specific Profile.</p>
<p>Note 1: The Sample Auxiliary Information Box (‘saio’) and Sample Auxiliary Size Box (‘saiz’) are conditionally required for encrypted content as specified in section 8.7.12 of [<a href="#CENCREF"><em>CENC</em></a>].</p>
<blockquote>
<p>Table 2 is a continuation of Table 1 showing nesting levels 5 to 8 separately to reduce table width.</p>
</blockquote>
<p>Table 2 – CMAF Protected Sample Entry Box structure</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">NL 5</th>
<th style="text-align: left;">NL 6</th>
<th style="text-align: left;">NL 7</th>
<th style="text-align: left;">NL 8</th>
<th style="text-align: left;">Format Req.</th>
<th style="text-align: left;">Source</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">stsd</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Section ‎7.5.11</td>
<td style="text-align: left;">Sample Description Box</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">sinf</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.12.1</td>
<td style="text-align: left;">Protection Scheme Information Box</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">frma</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.12.2</td>
<td style="text-align: left;">Original Format Box</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">schm</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.12.5</td>
<td style="text-align: left;">Scheme Type Box</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">schi</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] 8.12.6</td>
<td style="text-align: left;">Scheme Information Box</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">tenc</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">[<a href="#CENCREF"><em>CENC</em></a>] 8.2</td>
<td style="text-align: left;">Track Encryption Box</td>
</tr>
</tbody>
</table>
</section>
<section>
<h3 id="cmaf-container-structure">CMAF Container Structure</h3>
<p>The structure of a CMAF container is specified as a file, although it may only exist as a stream of Segments that never persist as a complete file. The following structure applies to a file that may represent the accumulation of a stream that is encoded over time, a file that is progressively downloaded over time, or a stored file. Additional constraints may be required to conform to a particular Media Profile and Application Profile defined in this specification.</p>
</section>
<section>
<h3 id="cmaf-header-initialization-segment"><a>CMAF Header</a> / Initialization Segment</h3>
<p>Figure 2 illustrates a <a>CMAF Header</a>, consisting of a sequence of required or optional boxes (optional boxes indicated by dotted lines).</p>
<p>The <a>CMAF Header</a> defines the set of boxes that appear at the beginning of a CMAF Container and their sequence, as shown in Figure 2. The <a>CMAF Header</a> is defined to extend from the first byte of the container up to but not including the first byte of the first <a>CMAF Segment</a>. These boxes are defined in compliance with [<a href="#ISOMREF"><em>ISOM</em></a>] with the following additional constraints and requirements:</p>
<ul>
<li><blockquote>
<p>The <a>CMAF Header</a> SHALL start with a File Type Box (‘ftyp’), as defined in Section‎7.5.1.</p>
</blockquote></li>
<li><blockquote>
<p>The <a>CMAF Header</a> shall include one Movie Box (‘moov’).</p>
</blockquote></li>
<li><blockquote>
<p>The Movie Box shall start with a Movie Header Box (‘mvhd’), as defined in Section ‎7.5.2.</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>The Movie Box shall contain one or more media tracks as specified in Section‎7.3.4, which defines the Track Box (‘trak’) requirements for the Common Media Format.</p>
</blockquote></li>
<li><blockquote>
<p>Media Samples SHALL NOT be referenced by the Track Box (‘trak’) in a <a>CMAF Header</a>. Therefore, the duration field value in the Movie and Track Header Boxes is zero, since it stores the duration of the Track Box, not the Movie Fragments Boxes.</p>
</blockquote></li>
<li><blockquote>
<p>The Movie Box shall contain a Movie Extends Box (‘mvex’), as defined in Section 8.8.1 of [<a href="#ISOMREF"><em>ISOM</em></a>], to indicate that the container contains Movie Fragment Boxes.</p>
</blockquote></li>
</ul>
<p><img src="media/cmaf-header-box-sequence-structure.png" width="475" height="301" alt="<a>CMAF Header</a> Box Sequence and Structure" /></p>
<p>Figure 2 – (Informational) <a>CMAF Header</a> box sequence and structure</p>
<ul>
<li><blockquote>
<p>The Movie Extends Box (‘mvex’) MAY contain a Movie Extends Header Box (‘mehd’), as defined in [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.8.2, and if so SHALL provide the overall duration of a fragmented movie. If the duration is unknown, this box SHALL be omitted.</p>
</blockquote></li>
<li><blockquote>
<p>The Movie Box (‘moov’) MAY contain a Free Space Box (‘free’), for example to reserve space to later overwrite metadata or DRM-specific boxes, without changing file size or byte offsets. If present in the CMAF file, the Free Space Box (‘free’) SHALL be the last box in the Movie Box (‘moov’).</p>
</blockquote></li>
</ul>
<p>In streaming applications, including live encoding, just-in-time packaging of pre-encoded elementary streams, and streaming of pre-encoded files, the CMAF File Header corresponds to the Initialization Segment specified in DASH streaming profiles defined for ISO Media.</p>
</section>
<section>
<h3 id="cmaf-tracks-1"><a>CMAF Track</a>s</h3>
<p>A <a>CMAF Track</a> is a <a>CMAF Header</a> followed by a timed sequence of <a>CMAF Fragment</a>s that form a byte sequence equivalent to a single track ISO Media File, or a portion of a hypothetical file, i.e. the first movie fragment MAY begin with a non-zero baseMediaDecodeTime. The first <a>CMAF Fragment</a> in a <a>CMAF Track</a> MAY be non-zero because only a subset of a file’s movie fragments are included in the <a>CMAF Track</a>, or because Track Fragment Decode Time Box (‘tfdt’) baseMediaDecodeTime used a timeline origin such as UTC (1/1/1900) or Unix Epoch (1/1/1970) when it was encoded.</p>
<p>A <a>CMAF Track</a> SHALL consist of a continuous sequence of <a>CMAF Fragment</a>s encoded from the same media source stream and media type ordered by presentation time, as well as a <a>CMAF Header</a> sufficient to initialize and process those <a>CMAF Fragment</a>s.</p>
<p>A CMAF Compatible Track MAY contain timed metadata, but SHALL be contained in a separate metadata Selection Set, not a second track in CMAF audio or video Fragments.</p>
<p>Media samples in successive Fragments of a Track SHALL be continuous in decoding time.</p>
<p>The first <a>CMAF Fragment</a> in a <a>CMAF Track</a> MAY start at a non-zero baseMediaDecodeTime.</p>
<p>Subsequent <a>CMAF Fragment</a>s in a <a>CMAF Track</a> SHALL have baseMediaDecodeTime equal to the sum of all prior <a>CMAF Fragment</a> durations added to the first Fragment’s BaseMediaDecodeTime.</p>
<p>Sequence_number in ‘mfhd’ is ignored, and is not required to be unique within <a>CMAF Track</a> or increase with decode time.</p>
<p>Each <a>CMAF Fragment</a> in a <a>CMAF Track</a> SHOULD have a duration of at least one second, with the possible exception of the first and last Fragments of the Track, to avoid the need for very short <a>CMAF Segment</a>s and request scheduling.</p>
<p>Note: Valid <a>CMAF Track</a>s do not have media time discontinuities resulting from missing samples or Fragments. Gaps in decode time would result in audio video synchronization errors because the ISO Base Media File Format calculates decode and presentation times as the sum of prior sample durations in a track. If audio or video frames are unavailable during recording, recorded samples may be extended in duration or filled with media data such as silent audio or repeated pictures. Long gaps and gaps synchronized across all media streams can be recorded as two sequential, but non-continuous <a>CMAF Track</a>s or Presentations that can be sequenced by a <a>Manifest</a>. A <a>Manifest</a> can sequence Tracks on a presentation timeline to remove a time gap, or maintain a presentation gap between two Tracks so they remain in sync with other Tracks. <a>Player</a> handling of delivery errors that result in invalid <a>CMAF Fragment</a> sequences is out of scope of CMAF, but the Track Fragment Decode Time Box (‘tfdt’) in each Fragment enables synchronization to <a>Manifest</a> presentation time following a gap in media delivery, trick play, etc.</p>
<p>Tracks begin with a <a>CMAF Header</a>, and samples are stored in <a>CMAF Fragment</a>s that each contain a single Track Fragment that references a complete sample sequence stored in a Media Data Box (‘mdat’) that immediately follows each Movie Fragment box in delivery/storage order.</p>
<p>Each Track contains a Track Box (‘trak’) in accordance with [<a href="#ISOMREF"><em>ISOM</em></a>], with the following constraints:</p>
<ul>
<li><p>Track Boxes (‘trak’) SHALL NOT reference media samples.</p></li>
<li><p>Only audio Track Boxes MAY contain an Edit Box (‘edts’) that SHALL contain one Edit List Box (‘elst’).</p></li>
<li><p>If an Edit List Box (`elst’) is included in a CMAF audio Track, the value of entry_count SHALL be 1, and all fields shall be set to the values specified in Section [‎7.5.14].</p>
</li>
</ul>
</section>
<section>
<h3 id="cmaf-fragments"><a>CMAF Fragment</a>s</h3>
<p>Each <a>CMAF Fragment</a> is an ISO Base Media segment [<a href="#ISOMREF"><em>ISOM</em></a><em>, section 8.16</em>] that contains one Movie Fragment Box (‘moof') followed by one or more Media Data Boxes ('mdat'). These SHALL be packaged and encoded conformant to the following constraints:</p>
<ol type="1">
<li><p>A <a>CMAF Fragment</a> SHALL contain a single Movie Fragment Box (‘moof’).</p></li>
<li><p>A <a>CMAF Fragment</a> SHALL contain one or more Media Data Box ('mdat').</p></li>
<li><p>The Movie Fragment Box (‘moof’) SHALL contain a single Movie Fragment Header Box (‘mfhd’). See Section ‎0 for more detail.</p></li>
<li><p>The Movie Fragment Box (‘moof’) SHALL contain a single Track Fragment Box (‘traf’) and media type (e.g. audio, video or subtitle).<br />
<br />
Note that video with caption data embedded in the elementary stream (e.g. CEA 608 in SEI NALs) is identified as a single <a>CMAF Track</a> of video media type, but the presence of SEI caption data is indicated by an additional sample description with the sample entry ‘csei’.</p></li>
<li><p>The Track Fragment Box (‘traf’) SHALL contain one Track Fragment Decode Time Box (‘tfdt’) that indicates both the earliest sample presentation time in the Fragment and the earliest sample decode time (stored in the baseMediaDecodeTime field).</p></li>
<li><p>The Track Fragment Box (‘traf’) SHALL contain one Track Run Box (‘trun’) that relies on default values stored within the <a>CMAF Fragment</a>, or that are constant for all <a>CMAF Fragment</a>s in the same <a>CMAF Switching Set</a> (e.g. default_sample_duration or dependency flags in Track Extends Box (‘trex’) in the <a>CMAF Header</a>s).</p></li>
<li><p>A <a>CMAF Fragment</a> SHALL contain all media samples necessary to render the duration of the track fragment box, and no others.</p></li>
<li><p>All media samples in a <a>CMAF Fragment</a> SHALL be addressed by byte offsets in the Track Run Box (‘trun’) that are relative to the first byte of the Movie Fragment Box (‘moof’). (see [<a href="#ISOMREF">ISOM</a>] Section 8.8.4).</p></li>
<li><p>All samples in a <a>CMAF Fragment</a> SHALL be decodable without reference to samples outside the <a>CMAF Fragment</a>, with the exception of initial audio samples that may be necessary to prime a predictive audio codec.</p></li>
<li><p>All video <a>CMAF Fragment</a>s SHALL contain only complete Coded Video Sequences delimited by SAP type 1 or 2.</p></li>
<li><p>All video <a>CMAF Fragment</a>s SHALL contain a v1 Track Run Box (‘trun’) with composition offsets (negative composition offsets where necessary) to adjust the earliest sample presentation time to equal the earliest sample decode time stored in the baseMediaDecodeTime field of the Track Fragment Decode Time Box (‘tfdt’).</p></li>
<li><p><a>CMAF Fragment</a>s containing encrypted samples SHALL conform to the constraints in Section ‎8.</p></li>
<li><p>Each <a>CMAF Fragment</a>, in association with its associated <a>CMAF Header</a>, SHALL contain sufficient metadata to be decoded, decrypted, and displayed when it is independently accessed.</p>
<ol type="a">
<li><p>Note: For instance, if sample groups and sample group descriptions are used to signal optional features, such as encryption key changes, then a Sample Group Description Box (‘sgpd’), and Sample to Group Box (‘sbgp’) that reference that description has to be present in each in each Track Fragment Box (‘traf’).</p></li>
</ol></li>
<li><p>The <a>CMAF Fragment</a> MAY prepend one or more Event Message Boxes (‘emsg’). See Section ‎7.4.3.</p></li>
</ol>
<p>Note: Each Event Message Box (‘emsg’) contains a schemeIdUri that functions as a URN message scheme identifier, and defines the payload of the message. Some schemes such as urn:scte:scte35 are standardized by SDOs and consortia for interoperability, in this case, ad and program segmentation splicing and signaling. But, any application provider can define its own scheme using a URL they control, and may locate a specification at that URL if they choose. Possible uses include delivering sports scores, interactive components, presentation chaining, server redirection, sparse content description metadata, etc. Delivering a simple URL allows a server to decide what to download (if anything) based on the player, device, location, time of the request, etc. If a player has a handler for the scheme, that is the only component that needs to understand the payload and protocol. Message parsing and routing is generic.</p>
<p>Figure 3 illustrates the box sequence and containment of a <a>CMAF Fragment</a>.</p>
<p><img src="media/cmaf-fragment-box-sequence-and-containment.png" width="699" height="370" alt="<a>CMAF Fragment</a> Box Sequence and Containment"/></p>
<p>Figure 3 – (Informational) <a>CMAF Fragment</a> box sequence and containment</p>
<blockquote>
<p>NOTE Bottom row indicate containment in the ‘traf’ box above. The sequence is only recommended. The presence of the Protection Specific Header Box in the Movie Fragment is optional, and typically only used for the delivery of chained licenses or “key rotation”. The Producer Reference Time Box (‘prft’), Segment Type Box (‘styp’), and Event Message Box (‘emsg’) are optional.</p>
</blockquote>
</section>
<section>
<h3 id="cmaf-segments-1"><a>CMAF Segment</a>s</h3>
<p>Each <a>CMAF Segment</a> SHALL include one or more complete <a>CMAF Fragment</a>s.</p>
<p>Each <a>CMAF Segment</a> SHALL have a single unique URI by which it can be addressed by servers, CDNs, and <a>Manifest</a>s.</p>
<p>Note: use of the URI is strongly recommended so that the content is shared in caches and content distribution systems even when different manifests or delivery protocols are used.</p>
<p>If a <a>CMAF Track</a> is stored as a <a>CMAF Track File</a>, <a>CMAF Segment</a> URIs MAY be a file URL with a byte range appended to each <a>CMAF Segment</a> request.</p>
<p>Note: A URL response containing one or more <a>CMAF Fragment</a>s is defined as a <a>CMAF Segment</a> regardless of the addressing method (i.e. not called a subsegment File byte range URLs can request an arbitrary range of <a>CMAF Fragment</a>s, so byte range Segments are not typically cached at CDNs, rather each byte range request is extracted from a <a>CMAF Track File</a> that is cached near the edge servers. With CMAF <a>Player</a> buffers multiple minutes in duration and stable network conditions, long duration Segments, e.g. 1 minute, can be progressively delivered with high efficiency. However, Track Switching is inefficient when long duration requests have to be cancelled before completion.</p>
<p><a>CMAF Segment</a>s MAY be combined for delivery efficiency, error correction, or other reasons, but SHALL be made accessible to CMAF <a>Player</a>s that request the <a>CMAF Segment</a> URI so the Segments can be late bound and synchronized as described in the CMAF <a>Manifest</a>.</p>
<p>A <a>CMAF Segment</a> SHALL be made available to a CMAF <a>Player</a> independent of the delivery system when a <a>CMAF Segment</a> is requested by URI. For example, <a>CMAF Segment</a>s can be delivered over broadcast or multicast, while the same or different <a>CMAF Segment</a>s can be delivered over unicast, but the CMAF <a>Player</a> can identify any <a>CMAF Segment</a> by URI and schedule it for playback regardless of which network path delivered it.</p>
</section>
<section>
<h3 id="cmaf-low-latency-delivery-chunks">CMAF Low Latency Delivery Chunks</h3>
<p>A server may offer Low Latency Delivery Chunks earlier than the equivalent Segment can be encoded, packaged, and delivered. When CMAF Low Latency Delivery Chunks are offered, complete <a>CMAF Segment</a>s SHALL also be offered at their normal availability time.</p>
<p>A Low Latency Delivery Chunk is a segment related to a <a>CMAF Segment</a> by the following constraints:</p>
<p>A Low Latency Delivery Chunk -</p>
<ol type="1">
<li><p>SHALL contain only one <a>CMAF Fragment</a> with one Media Data Box (‘mdat’).</p></li>
<li><p>SHALL contain a sequential subset of the media samples of a related <a>CMAF Fragment</a> in decode order.</p></li>
</ol>
<blockquote>
<p>Note: Each Package will be a subset of the samples of a CVS.</p>
</blockquote>
<ol type="1">
<li><p>SHALL indicate the BaseMediaDecodeTime of the first stored sample and composition offsets equal to the related <a>CMAF Fragment</a>.</p></li>
<li><p>SHALL increment sequence_number of each Movie Fragment Box (‘moof’) by +1, starting with the sequence_number of the <a>CMAF Fragment</a> containing the same media samples.</p></li>
</ol>
<p>Note: Low Latency Delivery Chunk sequence_number values overlap those of segments in the same Track and therefore may not be stored as a valid ISO Media track.</p>
<p>A complete sequence of Low Latency Delivery Chunks contains all of the Samples in the equivalent <a>CMAF Segment</a> in decode order, but each CMAF Low Latency Delivery Chunk contains a short time range, e.g. a half-second. Seamless Track Switching is only possible on the first Low Latency Delivery Chunk containing the first samples of the equivalent <a>CMAF Segment</a>.</p>
</section>
<section>
<h3 id="cmaf-switching-sets"><a>CMAF Switching Set</a>s</h3>
<p>A <a>CMAF Switching Set</a> SHALL contain one or more <a>CMAF Track</a>s, each of which is an encoding of the same source content.</p>
<p>Each <a>CMAF Switching Set</a> SHALL contain one media type, i.e. audio or video or subtitles.</p>
<p>Switching Sets MAY contain multiple <a>CMAF Track</a>s, and SHALL be constrained by CMAF to allow players to switch between tracks at segment boundaries and decode the resulting sequence of <a>CMAF Fragment</a>s through a single decoder without playback disruption. <a>Player</a>s are expected to present each video sample at the same time and quality following a Track switch as it would without any Track switch, and this is referred to as “seamless switching”. Perceptually seamless video switching depends on the amount of bitrate, resolution, and quality change between Segments, viewing conditions, and the quality of the display.</p>
<p>Tracks in the same <a>CMAF Switching Set</a> MAY vary by one or more parameters including bit rate, frame rate, and resolution. Between Tracks in a Switching Set, any two <a>CMAF Segment</a>s with the same timestamp SHALL be encodings of the same source content.</p>
<p>Each Track in a Switching Set SHALL have the same <a>CMAF Track Duration</a>.</p>
<p>Each Track in a Switching Set SHALL have the same number of Segments.</p>
<p><a>CMAF Segment</a>s encoded from the same media samples in a Switching Set SHALL start at the same presentation time, as specified by the BaseMediaDecodeTime in the Track Fragment Decode Time Box (‘tfdt’).</p>
<p>All <a>CMAF Track</a>s in a Switching Set SHALL have <a>CMAF Header</a>s with matching boxes and field values, except for the following fields in the Movie Header Box, Track Header Box, or visual sample entry:</p>
<ul>
<li><p>The fields width, height, creation_time, and modification_time MAY differ between <a>CMAF Header</a>s in a Switching Set.</p></li>
<li><p>Visual sample entries SHALL indicate the same codingname by its four-character code.</p></li>
<li><p>Visual sample entries MAY indicate different codec profile, level, and constraints; and different encoded width, height, sample aspect ratio, and cropping dimensions.</p></li>
</ul>
<p>Tracks MAY have different frame rates, but the number of samples per Segment and their duration SHALL differ inversely so that alternative Segments have equal duration.</p>
<p>Each Video Track in a Switching Set SHALL have a <a>CMAF Header</a> containing a Track Header Box (‘tkhd’) with normalized display width and height values, and one sample entry that describes every Sample in the Track. See Section ‎9 for more information on calculating normalized display width and height.</p>
<p>All video Segments within a Switching Set are intended to be displayed with the same height, width and position; and SHALL be encoded with the same framing, transfer function, bit depth, color subsampling, and color volume, so that switching between <a>CMAF Track</a>s in a Switching Set will result in continuous appearance when the <a>CMAF Segment</a>s are scaled to the same display aperture.</p>
<p>Switching Sets are defined to be “bitstream switchable” if they need to process a <a>CMAF Header</a> only once before the first <a>CMAF Fragment</a> is decoded, and can switch between <a>CMAF Track</a>s in the same <a>CMAF Switching Set</a> without processing a <a>CMAF Header</a>, or “re-initializing” parsing, decoding, decryption, or display systems.</p>
<p>The following <a>CMAF Track</a> types encoded to the constraints of this document are bitstream switchable:</p>
<ol type="1">
<li><p>Audio Tracks</p></li>
<li><p>Video Tracks with ‘avc3’ or ‘hev1’ sample entries</p></li>
<li><p>Subtitle Tracks</p></li>
</ol>
<p>Audio and subtitle Fragments are sync samples, and ‘avc3’ and ‘hev1’ Coded Video Sequences, as specified in CMAF, contain the necessary Sequence Parameter Set and Picture Parameter Set NAL Units to signal decoding parameters allowed to change between CMF Tracks in the same Switching Set.</p>
<p>The following CMF Track types are not to bitstream switchable unless explicitly signaled so (e.g. in the manifest):</p>
<ol type="1">
<li><p>Video with ‘avc1’ sample entry</p></li>
<li><p>Video with ‘hvc1’ sample entry</p></li>
</ol>
<p>Switching Sets that are not bitstream switchable require re-initialization before decoding a sequence of <a>CMAF Fragment</a>s from a Track by processing the CMF Header of that Track. A <a>CMAF Header</a> from each Track in the Switching Set need only be downloaded once (it is assumed they do not change during encoding), but must be processed every time that Track is switched to, in order to set the correct decoder configuration in the sample entry, apply the correct cropping and scaling, codec profile and level, etc. <a>Player</a>s that process CMF Headers on each Track switch can evaluate parameter changes to minimize the amount of reconfiguration required and minimize presentation disruption.</p>
<p><a>Manifest</a>s can identify bitstream switchable Switching Sets explicitly, but if they do not, the above assumptions can be used by <a>Player</a>s.</p>
<p>See also Section ‎9.2 and Section A.3.</p>
</section>
<section>
<h3 id="cmaf-selection-sets"><a>CMAF Selection Set</a>s</h3>
<p>All Switching Sets within a Selection Set SHALL be of the same media type, i.e. audio, video, or subtitles.</p>
<p>All Switching Sets within a Selection Set SHALL be of approximately the same duration, and the difference less than the maximum duration of a Coded Video Sequence.</p>
<p>A Selection Set may contain only one Switching Set if no alternative content is available.</p>
<p>Different Switching Sets that encode the same content with different codecs or video formats may be contained within a Selection Set to enable a player to preselect the most compatible codec or video format for that content, and automatically adaptively switch within the selected Switching Set</p>
<p>One <a>CMAF Track</a> SHOULD be presented from each Selection Set in a Presentation, e.g. one audio and one video Selection Set.</p>
<p>Note: A Subtitle Track can be selected, but not displayed by user control, but “forced” titles may be displayed even through regular subtitles are not displayed.</p>
</section>
<section>
<h3 id="cmaf-presentations"><a>CMAF Presentation</a>s</h3>
<p>A <a>CMAF Presentation</a> SHALL contain one or more synchronized Selection Sets, each Selection Set potentially synchronizing a different media type (audio, video, or subtitles).</p>
<p><a>CMAF Track</a>s of different media types in a Presentation SHALL be encoded such that synchronized timestamps in the sources produce synchronized timestamps in the corresponding encoded Segments.</p>
<p>Each <a>CMAF Track</a> in a Presentation SHALL be synchronized to the same presentation start time, and have approximately the same Track duration, within a tolerance of the longest <a>CMAF Segment Duration</a> of any Track in a Selection Set.</p>
<p>An offset edit list SHOULD be recorded in a <a>CMAF Header</a> when encoding an audio track that contains a <a>CMAF Fragment</a> that overlaps the presentation time of the first video sample, in order to skip audio that precedes the first video sample during playback. See Section‎7.5.14.</p>
<p>The duration of a Presentation SHALL default to the duration of its longest Switching Set, but <a>Manifest</a> MAY indicate earlier termination. A Presentation MAY have a fixed duration, or a duration that grows over time as <a>CMAF Segment</a>s are encoded or otherwise added to Tracks. This is normally the case for live Presentations.</p>
</section>
</section>
<section>
<h2 id="extensions-to-iso-base-media-file-format">Extensions to ISO Base Media File Format</h2>
<section>
<h3 id="sample-encryption-box-senc">Sample Encryption Box (‘senc’)</h3>
<section>
<h4 id="sample-encryption-overview">Sample encryption Overview</h4>
<p>A Sample Encryption Box (‘senc’) specified in [<a href="#CENCREF"><em>CENC</em></a>], or equivalent, SHALL be present in each <a>CMAF Segment</a> that stores Sample Auxiliary Information for Common Encryption (e.g. subsample information for NAL structured video, or per-sample initialization vectors).</p>
<p>NOTE Common Encryption allows storage of Sample Auxiliary Information in any location, but content conformance testing and player parsing for CMAF can be optimized by using a defined location in each <a>CMAF Segment</a> that is easily accessible to the file parser. For instance, storage in media data or outside the <a>CMAF Segment</a> would result in different parsing requirements that would complicate player implementation. However, parsers must use ‘saio’ and ‘saiz’ byte offsets to locate Sample Auxiliary Information even when it is stored in ‘senc’ in order to conform to [<a href="#CENCREF"><em>CENC</em></a>].</p>
</section>
</section>
<section>
<h3 id="track-encryption-box-tenc">Track Encryption Box (‘tenc’)</h3>
<p>As specified in [<a href="#CENCREF"><em>CENC</em></a>], a Track Encryption Box indicates that media samples in the track might be encrypted, it identifies the encryption scheme used, and contains default encryption parameters for the ISO Media track. The third edition of MPEG Common Encryption (ISO/IEC 23001-7:2016) defines version 1 ‘tenc’ with support for additional encryption schemes, such as ‘cbcs’ pattern encryption, which uses a constant IV value in ‘tenc’ that is applied to the start of every cipher block chain in the track.</p>
</section>
<section>
<h3 id="event-message-box-emsg">Event Message Box (‘emsg’)</h3>
<p>The Event Message Box (‘emsg’) is specified in section 5.10.3.3 of [DASH]</p>
<p>One or more Event Message Boxes MAY precede the Movie Fragment Box in a <a>CMAF Fragment</a>.</p>
<p>Event Messages are used to associate sparse metadata to presentation times in the <a>CMAF Track</a>, such as program segments, ratings, user interface data, advertisement identification, or availability splice points where video advertisements can be inserted. Event Message Boxes do not need to be repeated, but can be repeated, e.g. at ten seconds and five seconds before the event, in order to allow players tuning into a live stream to receive at least one copy of the Event Message. Event Messages with duplicated IDs can be ignored.</p>
<p>An Event Message scheme can define a URL in the message_data[] section of the box intended to trigger a <a>Player</a> request. That allows a server to determine a response that can be different based on clock time, the <a>Player</a>, the device, its location, etc. To reduce <a>CMAF Track</a> bitrate, it is advisable to deliver a URL when the response is large, or not relevant to a significant fraction of <a>Player</a>s. Delivering data in the Event Message Box has the advantage of low latency and avoiding additional download requests, especially for live streaming.</p>
<p>Because Event Messages are attached to <a>CMAF Segment</a>s that are already being requested, e.g. for audio playback, no change is required in a <a>Player</a>’s normal adaptive Segment downloading behavior. Event Messages can also be duplicated in a <a>Manifest</a> to provide random access and Event Message history for VOD playback, or live random access within a time shift buffer. <a>Manifest</a> signaling also allows <a>Player</a>s to detect Event Messages by frequently requesting updated <a>Manifest</a>s.</p>
<p>Event Message Boxes can be appended during encoding or delivery without requiring reformatting of the <a>CMAF Fragment</a> Movie Fragment Box or Media Data Box. Event Messages can provide notification any time in advance of the event’s presentation time so a player can complete actions, such as downloading signaled information or media, e.g. a video ad. It is advisable to insert Event Message boxes on all Tracks within a Selection Set (e.g. audio) so the message will be read regardless of the Track selected.</p>
<p>A <a>Manifest</a> can notify a <a>Player</a> of the Event Message schemes that will be sent in a Presentation so that <a>Player</a> can register a handler for each scheme_id_uri that can parse and process that Event Message scheme. Schemes can be specified for private or public use, as long as the scheme_id_uri is unique for that scope, and specified and managed accordingly.</p>
</section>
</section>
<section>
<h2 id="constraints-on-iso-base-media-file-format-boxes">Constraints on ISO Base Media File Format Boxes </h2>
<section><h3 id="file-type-box-ftyp">File Type Box (‘ftyp’)</h3>
<p><a>CMAF Track</a>s and Files SHALL include at least the compatible_brands of ‘cmfc’ and ‘iso9’.</p>
</section>
<section>
<h3 id="movie-header-box-mvhd">Movie Header Box (‘mvhd’) </h3>
<p>The value of the duration field SHALL be set to zero to indicate that the Movie Box (‘moov’) contains no media samples and therefore has no duration.</p>
<blockquote>
<p>NOTE The duration field in the Media Header Box (‘mdhd’) applies to the Track Box (‘trak’), which contains no media samples in CMAF. The duration of an entire fragmented movie can optionally be stored in the fragment_duration field of the Movie Extends Header Box (‘mehd’), which is equal to the sum of all track Fragment durations in the longest track in the movie. If the duration is unknown, this box is omitted.</p>
</blockquote>
<p>The fields rate, volume, and matrix SHALL be set to their default values.</p>
</section>
<section>
<h3 id="handler-reference-box-hdlr-for-file-metadata">Handler Reference Box (‘hdlr’) for File Metadata </h3>
<p>The <a>CMAF Header</a> SHOULD contain a Copyright notice stored as defined in ISO/IEC 14496-12.</p>
<p>Tracks that are language-specific SHOULD carry a language tag in their media header [<a href="#ISOMREF"><em>ISOM</em></a>], augmented as necessary by an Extended Language Tag [<a href="#ISOMREF"><em>ISOM</em></a>].</p>
<p>Other metadata, carried in either user data or metadata boxes MAY be present. When present they MUST NOT occur at file level, i.e. they must be contained in another permitted box, as permitted by ISO/IEC 14496-12.</p>
</section>
<section>
<h3 id="xml-metadata">XML Metadata</h3>
<p>An XML document MAY be stored as the primary item of a Metadata Box (‘meta’), and reference other objects, such as thumbnail and jacket images, stored in an Item Data Box (‘idat’) in the Metadata Box (‘meta’) using their item names in the ‘iloc’ box. The use of the XML Box (‘ xml’) is deprecated.</p>
</section>
<section>
<h3 id="kind-box-kind">Kind Box (‘kind’)</h3>
<p>The Kind Box (‘kind’) MAY be used to store the role of a <a>CMAF Track</a>. The Kind Box (‘kind’) box is stored in the User Data Box (‘udta’) of the Track Box (‘trak’), as documented in the ISO Base Media File Format [ISOM].</p>
<p>Any track can be labeled with role information describing the intended purpose of the track. This information can be captured at the time of encoding, and later copied to a <a>Manifest</a> describing the <a>CMAF Track</a>s in a Selection Set so that a user or an automatic algorithm can make an appropriate selection.</p>
<p>The Kind Box (‘kind’) can contain one or more tags from a variety of places, including:</p>
<ul>
<li><p>the DASH specification [DASH]section 5.8.5.5, as identified by the schemeURI &quot;urn:mpeg:dash:role:2011&quot; (without the quotation marks);</p></li>
<li><p>The W3C HTML5 specification of track 'kind', as identified by the schemeURI [[TBD? https://www.w3.org/TR/html5/embedded-content-0.html#the-track-element]]</p></li>
</ul>
<p>Where multiple schemes define the same concepts, the DASH scheme SHOULD be used. In particular, where captions or descriptions need to be identified, or that the text be marked as easy to read, the following values from DASH SHOULD be used:</p>
<ul>
<li><p>&quot;caption&quot;</p></li>
<li><p>&quot;description&quot;</p></li>
<li><p>[[ed: &quot;public.easy-to-read&quot; – no matching DASH value?]]</p></li>
</ul>
<p>[[ed: The easy-to-read kind is an additional annotation, indicating that the text of the captions etc. is easy-to-read, as mandated by the FCC.]]</p>
</section>
<section>
<h3 id="track-header-box-tkhd">Track Header Box (‘tkhd’)</h3>
<p><a>CMAF Track</a> Header Boxes shall conform to [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.3.1 with the following additional constraints:</p>
<ul>
<li><blockquote>
<p>The field duration SHALL be set to a value of zero (‘0’), indicating no media samples are present in the Track Box (‘trak’).</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>The field matrix SHALL be set to their default values as defined in [<a href="#ISOMREF"><em>ISOM</em></a>], except to indicate video orientation (i.e. portrait or landscape orientation relative to the captured scene).</p>
</blockquote></li>
<li><blockquote>
<p>The following fields SHALL be set to default values as defined in [<a href="#ISOMREF"><em>ISOM</em></a>], unless specified otherwise in this specification:</p>
</blockquote></li>
</ul>
<p>The layer field SHALL equal -1 for subtitle tracks (i.e. in front of video).</p>
<ul>
<li><blockquote>
<p>The width and height fields for a non-visual track (i.e. audio) SHALL be 0.</p>
</blockquote></li>
<li><blockquote>
<p>The width and height fields for a CMAF video track shall specify the track’s normalized presentation size as fixed-point 16.16 values expressed in square pixels after decoder cropping, and in the case of video encoded with a non-square spatial sample shape, after horizontal scaling has been applied. See Section ‎9.2.2 for normalized width and height calculation.</p>
</blockquote></li>
</ul>
<p>Note: Normalized width and height are primarily useful to determine the picture aspect ratio, and for device selection of Tracks that approximate a player’s display aperture size, when bandwidth and decoding capacity allow. Adaptively switched Segments can be scaled to a device determined display aperture by applying scaling ratios equal to the display aperture’s width and height in square pixels, divided by the Segment’s decoded and cropped horizontal and vertical spatial sample counts. The spatial sample counts can be derived from the Track’s visual sample entry for ‘avc1’ or ‘hvc1’ video samples (see Section ‎9.2.3), or from a Sequence Parameter Set NAL in each Segment and Coded Video Sequence for ‘avc3’ or ‘hev1’ video samples. See Section ‎9.2.4 for the storage and semantics of video Sequence Parameter Sets.</p>
<ul>
<li><blockquote>
<p>Subtitle Tracks MAY set width and height to an intended layout size, in which case the text layout engine or graphics engine can scale the width and height to match the video display aperture (player implementation dependent).</p>
</blockquote></li>
<li><blockquote>
<p>As defined in ISO/IEC 14496-30 [ISOTXT], Subtitle Tracks encoded as text MAY use relative position coordinates and font sizes so that the text layout engine can adjust glyph and layout size to match the final video display aperture without relying on image scaling. For such tracks, the value of zero width and height SHOULD be used to indicate that the data can be rendered at any size, and the layout size may be determined by matching the size of the video display aperture.</p>
</blockquote></li>
<li><blockquote>
<p>For scalable text and subtitle tracks, the flag track_size_is_aspect_ratio may also be used.</p>
</blockquote></li>
<li><blockquote>
<p>The track_size_is_aspect_ratio flag indicates that the width and height fields are not expressed in pixel units, but indicate the intended aspect ratio. If the aspect ratios of this track and related video tracks are not identical, then the respective positioning of the tracks is undefined, possibly defined by external context. This flag value is 0x000008.</p>
</blockquote></li>
<li><blockquote>
<p>For non-visual tracks (e.g. audio), width and height SHALL be set to zero.</p>
</blockquote>
</li>
</ul>
</section>
<section>
<h3 id="media-header-box-mdhd">Media Header Box (‘mdhd’)</h3>
<p>The CMAF Media Header Boxes SHALL conform to [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.4.2 with the following additional constraints:</p>
<ul>
<li><blockquote>
<p>The value of the duration field SHALL be set to a value of zero (‘0’);</p>
</blockquote></li>
</ul>
<p>NOTE The duration field in the Media Header Box (‘mdhd’) applies to the Track Box (‘trak’), which contains no media samples in CMAF. The duration of an entire fragmented Track can optionally be stored in the fragment_duration field of the Movie Extends Header Box (‘mehd’), which is equal to the sum of all track Fragment durations.</p>
<ul>
<li><blockquote>
<p>Where possible, the value of the timescale field SHOULD be chosen such that when the frame rate is constant, the value of the sample duration may also be constant.</p>
</blockquote></li>
</ul>
<ul>
<li><p>When there are multiple tracks in a Selection Set that differ by language, the language of each track SHALL be identified to at least the precision needed to differentiate the tracks, using the language field and optionally the Extended Language Box (‘elng’). All tracks that are language-specific SHOULD similarly identify the language. The precision of all tagging SHOULD be as precise as possible (e.g. a text track whose language can be written in different scripts should identify which script is used.). When the language is not relevant or not known, the ‘und’ (undetermined) language tag SHOULD be used.</p></li>
<li><blockquote>
<p>The Extended Language box [<a href="#ISOMREF"><em>ISOM</em></a>] 8.4.6 MAY be present.</p>
</blockquote>
</li>
</ul>
</section>
<section>
<h3 id="video-media-header-vmhd">Video Media Header (‘vmhd’)</h3>
<p>Video Media Header Boxes in a CMAF SHALL conform to [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.4.5 with the following additional constraints:</p>
<ul>
<li><blockquote>
<p>The following fields SHALL be set to their default values as defined in [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.4.5:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>version=0</p>
</blockquote></li>
<li><blockquote>
<p>graphicsmode=0</p>
</blockquote></li>
<li><blockquote>
<p>opcolor={0, 0, 0}</p>
</blockquote>
</li>
</ul>
</section>
<section>
<h3 id="sound-media-header-smhd">Sound Media Header (‘smhd’) </h3>
<p>The balance value in the sound media header SHOULD be zero (centered).</p>
</section>
<section>
<h3 id="data-reference-box-dref">Data Reference Box (‘dref’) </h3>
<p>Data Reference Boxes in a <a>CMAF Track</a> shall conform to [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.7.2 with the following additional constraints:</p>
<ul>
<li><p>The Data Reference Box (‘dref’) SHALL contain a single entry with the entry_flags field set to 0x000001 (which means that the media data is in the same file as the Movie Box containing this data reference).</p>
</li>
</ul>
</section>
<section>
<h3 id="sample-description-box-stsd">Sample Description Box (‘stsd’)</h3>
<p>Sample Description Boxes in a <a>CMAF Track</a> shall conform to version 0 as defined in [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.5.2 with the following additional constraints:</p>
<ul>
<li><p>Sample entries for encrypted tracks (those containing any encrypted sample data) SHALL encapsulate the existing sample entry with a Protection Scheme Information Box (‘sinf’) that conforms to [<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.12.a-jcs.docx#ISOMREF"><em>ISOM</em></a>] section 8.12.1.</p></li>
<li><p>For video tracks, a visual sample entry SHALL be used. Design rules are specified in Section ‎9.2.3.</p></li>
<li><p>For audio tracks, an audio Sample entry SHALL be used. Design rules are specified in Section ‎10.3.6.</p></li>
<li><p>For subtitle tracks a subtitle sample entry SHALL be used. Design rules are specified in [ISOTXT].</p></li>
</ul>
</section>
<section>
<h3 id="protection-scheme-information-box-sinf">Protection Scheme Information Box (‘sinf’)</h3>
<p>CMAF shall use Common Encryption for Tracks containing one or more encrypted <a>CMAF Segment</a>s as defined in [<a href="#CENCREF"><em>CENC</em></a>], and use Scheme Signaling as defined in [<a href="#CENCREF"><em>CENC</em></a>] Section 4. An encrypted <a>CMAF Track</a> SHALL include at least one Protection Scheme Information Box ('sinf') identifying a scheme specified in [<a href="#CENCREF"><em>CENC</em></a>] Section 10.</p>
</section>
<section>
<h3 id="track-sample-boxes">Track Sample Boxes</h3>
<p>The following boxes SHALL have an entry_count of zero because CMAF does not store media samples in the Track Box (‘trak’).</p>
<ul>
<li><p>Decoding Time to Sample Box (‘stts’)</p></li>
<li><p>Sample to Chunk Box (‘stsc’)</p></li>
<li><p>Chunk Offset Box (‘stco’)</p></li>
<li><p>Sample Size Boxes (‘stsz’ or ‘stz2’)</p></li>
</ul>
<p>Both the sample_size and sample_count fields of the ‘stsz’ box shall be set to zero (‘0’). The sample_count field of the ‘stz2’ box shall be set to zero (‘0’). Sample size and duration information can be found in the Track Fragment Run Box (‘trun’) in each <a>CMAF Segment</a>.</p>
<p>The mandatory boxes of ISO/IEC 14496-12 are mandatory, even though they document no samples.</p>
</section>
<section>
<h3 id="track-edit-list-box-elst">Track Edit List Box (‘elst’)</h3>
<p>A single Edit List Box with the following constraints SHOULD be recorded in the CMF Header to document the earliest presentation time of an audio <a>CMAF Track</a> when the composition time of the first audio sample does not match the earliest video sample composition time of other CMF Tracks in a Presentation. In [ISOM] section 8.6.6, this is referred to as a “non-empty edit” that “provides the offset from media composition time to movie presentation time”.</p>
<p>Audio Tracks in multimedia presentations SHALL start with the first audio Segment that overlaps or starts at the earliest presentation time of other synchronized <a>CMAF Track</a>s. A “start offset” edit list MAY be used in a <a>CMAF Header</a> to indicate the presentation time of the audio Track that is synchronized with the Track Fragment Decode Time (‘tfdt’) of the first Segment in the video Track. A start offset edit list skips presentation of the leading audio during playback, but allows decoding from the start of an access unit in order to “prime” the decoder so it can output audio at the intended presentation start time.</p>
<p>Audio/video synchronization and start time can be modified by timestamps and offsets in a <a>Manifest</a>. In that case, the presentation of each audio sample is synchronized to the Presentation Timeline, i.e. the presentation time offset between audio ‘tfdt’ baseMediaDecodeTime and the Presentation Timeline includes the start offset of the edit list in the <a>CMAF Header</a>, so a CMAF <a>Player</a> can ignore the recorded edit list and apply the manifest ‘tfdt’ to presentation time offset..</p>
<p>A start offset edit list SHALL be defined as a single Edit List Box (‘elst’) in an Edit Box (‘edts’) in an audio Track Box (‘trak’) with the following values:</p>
<ul>
<li><blockquote>
<p>Segment-duration = 0</p>
</blockquote></li>
<li><blockquote>
<p>Media-Time = offset from the start of the audio Segment measured in the audio Track timescale</p>
</blockquote></li>
<li><blockquote>
<p>Media-Rate = 1</p>
</blockquote></li>
</ul>
<p>An audio track compressed with AAC MAY have a preroll sample group (‘roll’), and a start offset edit list to prevent presentation of priming audio data and other audio data prior to the intended presentation start time.</p>
</section>
<section>
<h3 id="track-extends-box-trex">Track Extends Box (‘trex’)</h3>
<p>Track Extends Boxes (‘trex’) SHALL be present in a <a>CMAF Track</a> since it is a fragmented file as defined in [<a href="#ISOMREF"><em>ISOM</em></a>] Section </p>
</section>
<section>
<h3 id="movie-fragment-header-box-mfhd">Movie Fragment Header Box (‘mfhd’)</h3>
<p>Movie Fragment Header Boxes (‘mfhd’) in a <a>CMAF Track</a> SHALL conform to [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.8.5 with the following additional constraints:</p>
<ul>
<li><p>The sequence_number integer field in each Movie Fragment Header Box (‘mfhd’) in a <a>CMAF Fragment</a> MAY be ignored. The integer values in a <a>CMAF Track</a> need not increase over time or be consecutive, although that is typical practice. Even if each <a>CMAF Track</a> in a Switching Set has consecutively numbered <a>CMAF Fragment</a>s, the adaptively delivered <a>CMAF Fragment</a>s might not be consecutive because they aren’t constrained to have the same sequence_number for each Fragment with the same decode time.</p>
</li>
</ul>
</section>
<section>
<h3 id="track-fragment-header-box-tfhd">Track Fragment Header Box (‘tfhd’)</h3>
<p>Track Fragment Header Boxes (‘tfhd’) in a <a>CMAF Track</a> SHALL conform to [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.8.7 with the following additional constraints:</p>
<ul>
<li><p>the base-data-offset-present flag (in the tf_flags field) SHALL be set to zero in order to indicate that media samples are addressed using byte offsets relative to the the Movie Fragment Box (‘moof’); and</p></li>
<li><p>the default-base-is-moof flag (in the tf_flags field) SHALL be set to one in order to indicate that the data_offset field in the Track Fragment Run Box (‘trun’) is always calculated relative to the first byte of the enclosing Movie Fragment Box (‘moof’).</p></li>
<li><p>The Track Fragment Box (‘traf’) SHALL contain a Track Fragment Decode Time Box (‘tfdt’), as defined in [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.8.12, to provide the first Sample decode time in the Fragment.</p></li>
<li><p>In <a>CMAF Segment</a>s, the field baseMediaDecodeTime SHALL also equal the first Sample composition time in the Fragment.</p></li>
</ul>
<p>The baseMediaDecodeTime of the first available <a>CMAF Segment</a> in a <a>CMAF Track</a> MAY be non-zero.</p>
<p>Note: A <a>CMAF Track</a> may be thought of as a portion of a hypothetical ISO Media track. In the event that the baseMediaDecodeTime of each <a>CMAF Segment</a> is set to its NTP encode time, for example, that would imply it was a portion of an ISO Media track that began January 1, 1900. For CMAF, ‘tfdt’ baseMediaDecodeTime can be considered an arbitrary timeline for <a>CMAF Track</a>s, which follows ISO Media decode time rules within the available Segments, i.e. decode time is the sum of prior sample durations in the track, and ‘tfdt’ contains the decode time of the first sample in each Segment.</p>
</section>
<section>
<h3 id="track-fragment-run-box-trun">Track Fragment Run Box (‘trun’)</h3>
<p>Track Fragment Run Boxes (‘trun’) in a <a>CMAF Track</a> SHALL conform to [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.8.8 with the following additional constraints:</p>
<ul>
<li><p>the version field SHALL be set to ‘1’; and</p>
<ul>
<li><p>the data-offset-present flag (in the tf_flags field) SHALL be set to true in order to indicate that the data_offset field is present and contains the byte offset from the start of this Fragment’s Movie Fragment Box (‘moof’) to the first sample of media data in the following Media Data Box (‘mdat’). Note, this is called movie-fragment relative addressing in [<a href="#ISOMREF"><em>ISOM</em></a>].</p></li>
<li><p>The sample_composition_time_offset is a signed 32-bit integer measured by the timescale of the track, which reorders video Samples from decode order to presentation order. The first presented Sample in a <a>CMAF Segment</a> SHALL be offset to coincide with the first Sample decode time (BaseMediaDecodeTime in ‘tfdt’), and subsequent Samples follow continuously in presentation order. Note that the use of only positive composition offsets would result in a video synchronization delay of multiple frames relative to audio, subtitles, and other tracks.</p></li>
</ul></li>
<li><p>Within a video <a>CMAF Track</a>, any Track Run Box (‘trun’) that describes any non-sync pictures SHALL identify pictures using a combination of the sample_flags and first_sample_flags fields:</p>
<ul>
<li><p>sample_is_non_sync_sample SHALL be 0 for SAP type 1 or 2, and 1 if not;</p></li>
<li><p>sample_depends_on SHOULD be 2 for I pictures;</p></li>
<li><p>sample_is_depended_on SHOULD be 2 for disposable pictures.</p></li>
</ul>
</li>
</ul>
</section>
<section>
<h3 id="sample-group-description-box-sgpd">Sample Group Description Box (‘sgpd’)</h3>
<p>When sample group information can change within a <a>CMAF Track</a>, a Sample Group Description Box SHALL be stored in each <a>CMAF Fragment</a> that references that sample group description. If sample group information is the same for all Fragments in a Switching Set, it MAY be stored in a Sample Group Description Box in the <a>CMAF Header</a> Sample Table Box (‘stbl’).</p>
<p>For example: when Common Encryption is used and KID values can change per <a>CMAF Fragment</a>, a Sample to Group Box (‘sbgp’) stored in each Track Fragment Box (‘traf’) will reference a Sample Group Description Box containing the KID, which is also stored in the Track Fragment Box in order to support random access.</p>
</section>
<section>
<h3 id="media-data-box-mdat.">Media Data Box (‘mdat’).</h3>
<p>Each <a>CMAF Fragment</a> SHALL contains one or more Media Data Box (‘mdat’) containing media Samples, unless the Track Run Box (‘trun’) references no media data (i.e. a <a>CMAF Fragment</a> that has duration, but no media). The Media Data Box conforms to the definition in [<a href="#ISOMREF"><em>ISOM</em></a>] Section 8.1.1 with the following additional constraints:</p>
<ul>
<li><p>The only media Samples in each instance of this box SHALL be those referenced by the single Track Fragment Box that precedes it (i.e. only audio, video, or subtitles from the track fragment time interval of one track). In other words, all samples within an instance of this box belong to the same <a>CMAF Track</a> and Fragment.</p></li>
</ul>
</section>
</section>
</section>
<section>
<h2 id="common-encryption-of-tracks">Common Encryption of Tracks</h2>
<section>
<h3 id="multiple-drm-support-informative">Multiple DRM Support (Informative)</h3>
<p>Multiple DRM systems can provide a license for an encrypted Track using Common Encryption [<a href="#CENCREF"><em>CENC</em></a>]. The default_KID identifies the key and license required, and a registered SystemID identifies a Common Encryption capable DRM system. License acquisition information can be provided to identify which DRM systems can provide licenses. License acquisition information usually includes the URL of an authorization and license server, DRM SystemID, DRM client identification, type of license requested, media key identifier, etc., and may be stored in a ‘pssh’ box, a <a>Manifest</a>, or an application in order to assist players in requesting a license to decrypt a Track.</p>
<p>A single key and license may be sufficient to access all tracks in a presentation, or HD and other high value content may be required to use different keys for audio and video tracks, since the audio path may be less secure. A content provider may also require different keys and licenses for different qualities, such as SD, HD, and UHD.</p>
<p>CMAF requires license acquisition information to be signaled only in a <a>Manifest</a> or application when streaming, because it allows a CMAF <a>Player</a> application to parse all license acquisition information in advance of playback, and download the required license(s) only once. If license acquisition information is stored in a Protection System Specific Header Box (‘pssh’ version 0) in the <a>CMAF Header</a>, a license may be requested each time a <a>CMAF Header</a> is processed, e.g. for bitrate switching. If ‘pssh’ version 0 were allowed, CMAF <a>Player</a> application would then have to analyze each proprietary header to determine if the request was a duplicate.</p>
<p><a>Manifest</a> signaling makes it easier to add or change license information without editing media files. That makes it easier to offer different types of licenses, e.g. subscription, rental, ownership, SD, HD, etc., without multiple media copies; and support different distribution channels and license servers with the same media. For a live streaming presentation, it is advantageous for players to request a license before the live media becomes available, authorize or purchase playback rights, and download a license in advance, rather than experience playback delay when thousands of players receive the first live Segment, which would be the case with license acquisition information stored in ‘pssh’ in the <a>CMAF Header</a>.</p>
</section>
<section>
<h2 id="track-encryption">Track Encryption</h2>
<section><h3 id="encryption-overview">Encryption Overview</h3>
<p>Encrypted track sample data in a CMAF SHALL use an encryption scheme defined in [<a href="#CENCREF"><em>CENC</em></a>] Section 4.2.Encrypted NAL Structured Video tracks SHALL follow a Subsample encryption scheme outlined in [<a href="#CENCREF"><em>CENC</em></a>] Section 9.5, which defines a NAL unit partial encryption scheme to allow access to NALs and unencrypted video NAL headers in an encrypted NAL Structured Video elementary stream.</p>
<p>As documented in the Common Encryption and ISO BMFF specifications, the Track Fragment Box (‘traf’) SHOULD contain a Sample Auxiliary Information Offsets Box (‘saio’) with an explicit or implied aux_info_type value of &quot;cenc&quot; and a Sample Auxiliary Information Sizes Box (‘saiz’) with an explicit or implied aux_info_type value of &quot;cenc&quot;, as specified in as defined in [ISOM] Section 8.7.12; the aux_info_type_parameter takes the value defined by Common Encryption (implied or explicit value of 0).</p>
<p>Initialization vectors, subsample byte ranges and other Sample Auxiliary Information for Common Encryption SHALL be stored in the Sample Encryption Box (‘senc’) or equivalent box in the ‘moof’.</p>
<p>All encrypted non-video tracks SHALL follow the schemes outlined in [<a href="#CENCREF"><em>CENC</em></a>] Section 9.4 or 9.7, which defines full sample encryption schemes.</p>
</section>
<section>
<h3 id="the-following-additional-constraints-shall-be-applied-to-all-encrypted-tracks">The following additional constraints SHALL be applied to all encrypted tracks:</h3>
<p>All key identifier values SHALL be a UUID generated according to <a href="#RFC4122REF">[X667]</a> and stored in the KID field as 16 octets in big endian order, as specified in section 6.2 of <a href="#RFC4122REF">[X667]</a><em>,</em> or represented as a hyphenated hexadecimal string in <a>Manifest</a>s, as specified in section 6.4 of <a href="#RFC4122REF">[X667]</a>.</p>
<ul>
<li><p>A KID value SHALL only index one key value used in any <a>CMAF Track</a>, i.e. be a globally unique identifier for one CMAF key.</p>
</li>
</ul>
</section>
<section>
<h3 id="track-constraints">Track Constraints</h3>
<section>
<h4 id="sample-encryption-box-senc-and-sample-auxiliary-information">Sample Encryption Box (‘senc’) and Sample Auxiliary Information</h4>
<p>For encrypted track Fragments that contain Sample Auxiliary Information, the Track Fragment Box (‘traf’) SHALL contain a Sample Auxiliary Information Offsets Box (‘saio’) with an aux_info_type value of &quot;cenc&quot; as defined in [<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.11.f-jcs.docx#CENCREF"><em>CENC</em></a>] Section 7 to provide sample-specific encryption data. This Sample Auxiliary Information Offsets Box (‘saio’) is constrained as follows:</p>
<ul>
<li><p>The offset field SHALL point to the first byte of the first initialization vector in the Sample Encryption Box ('senc'); and</p></li>
<li><p>The entry_count field SHALL be 1 as the data in the Sample Encryption Box (‘senc’) is contiguous for all of the samples in the movie Fragment (the CencSampleAuxiliaryDataFormat structure has the same format as the data in the Sample Encryption Box ('senc'), by design); and</p></li>
<li><p>the offset field of the entry SHALL be calculated as the difference between the first byte of the containing Movie Fragment Box (‘moof’) and the first byte of the first InitializationVector in the Sample Encryption Box (using movie Fragment relative addressing where no base data offset is provided in the track Fragment header).</p></li>
</ul>
<p>The size of this sample auxiliary data SHALL be specified in a Sample Auxiliary Information Sizes Box (‘saiz’) with an aux_info_type value of &quot;cenc&quot;, as defined in [<a href="https://microsoft-my.sharepoint.com/personal/johnsim_microsoft_com/Documents/CMF%20Spec/Common%20Media%20Format%20v2015.04.11.f-jcs.docx#CENCREF"><em>CENC</em></a>] Section 7, including the following exceptions:</p>
<p>If Subsample encryption is not used (the size of the sample auxiliary information equals default_Per_Sample_IV_Size in the ‘tenc’ box), and the entire sample is protected (see [CENC] 9.4 for further details). In this case, all auxiliary information will have the same size and hence the default_sample_info_size of the Sample Auxiliary Information Sizes box (‘saiz’) will be equal to the default_Per_Sample_IV_Size of the Initialization Vectors, and ‘saiz’ box MAY be omitted.</p>
<p>If Per_Sample_IV_Size is also zero (because constant IVs are in use) then the sample auxiliary information would then be empty and SHOULD be omitted, as well as the ‘saio’ box.</p>
<p>Even if Subsample encryption is used, the size of the sample auxiliary information may be the same for all of the samples (if all of the samples have the same number of Subsamples) and the default_sample_info_size may be used.</p>
<p>The Sample Auxiliary Information Sizes Box (‘saiz’) is constrained as follows:</p>
<ul>
<li><p>the sample_count field SHALL match the sample_count in the Sample Encryption Box ('senc'); and</p></li>
<li><p>the default_sample_info_size SHALL be zero (‘0’) if the size of the per-sample information is not the same for all of the samples in the Sample Encryption Box ('senc').</p></li>
</ul>
<p>Note: Sample encryption information, is located by Fragment byte offsets stored in the Sample Auxiliary Information Offsets Box (‘saio’), and in some cases by size information stored in the Sample Auxiliary Information Size Box (‘saiz’). Sample Auxiliary Information, such as per-sample initialization vectors and subsample byte ranges is not intended to be read directly from the Sample Encryption Box (‘senc’). - This specification defines storage in a Sample Encryption Box (‘senc’) in each movie Fragment for consistency, parsing efficiency, and conformance testing, but the Sample Auxiliary Information Offsets Box (‘saio’) can be used to locate auxiliary information that may have been refragmented or stored in other boxes in the Track Fragment Box (‘traf’). If Sample Auxiliary Information were stored in media data, it might not be accessible to the file parser.</p>
</section>
<section>
<h4 id="track-encryption-box-tenc-1">Track Encryption Box (‘tenc’)</h4>
<p>As specified in [<a href="#CENCREF"><em>CENC</em></a>], a Track Encryption Box indicates that media samples in the track might be encrypted, it identifies the encryption scheme used, and contains default encryption parameters for the ISO Media track. The third edition of MPEG Common Encryption (ISO/IEC 23001-7:2016) defines version 1 ‘tenc’ with support for additional encryption schemes, such as ‘cbcs’ pattern encryption, which uses a constant IV value in ‘tenc’ that is applied to the start of every cipher block chain in the track.</p>
</section>
<section>
<h4 id="protection-system-specific-header-box-pssh">Protection System Specific Header Box (‘pssh’)</h4>
<p>Common Encryption specifies version zero and version one Protection System Specific Header Boxes (‘pssh’). Protection System Specific Header Boxes can be used to store licenses in downloaded files, signal that license downloads are required in CMF Headers, and deliver licenses, keys, and usage information in CMF Fragments. Protection System Specific Header Boxes contain a registered SystemID that uniquely identifies the protection system intended to use the information. Information contained in the data[] array is considered opaque to <a>Player</a>s, file parsers, and other DRM systems, and might be encrypted by the protection system.</p>
<p>The Common Encryption standard [<a href="#CENCREF"><em>CENC</em></a>] also specifies XML elements to contain license acquisition information for use in <a>Manifest</a>s. CMAF strongly recommends signaling license acquisition information only in the <a>Manifest</a>, not in <a>CMAF Header</a>s, to avoid triggering event handling each time a <a>CMAF Header</a> is processed when adaptive switching. A <a>Player</a> can download all licenses that will be needed for playback as soon as it parses the <a>Manifest</a> and before it downloads <a>CMAF Header</a>s. It is particularly useful to acquire licenses in advance of a large live streaming event that would otherwise result in a large number of synchronized license requests if triggered by the media stream.</p>
<p>CMAF specifies the following constraints:</p>
<ul>
<li><p>‘pssh’ boxes SHOULD NOT be present in <a>CMAF Header</a>s, except as specified below, and MAY be ignored if present. In a generic CMAF <a>Player</a>, it is assumed that all ‘pssh’ boxes in <a>CMAF Header</a>s or <a>CMAF Segment</a>s will be passed directly to the DRM content decryption module without <a>Player</a> processing.</p></li>
<li><p>A Common ‘pssh’ box and additional ‘pssh’ boxes in CMF Header MAY be used with Presentation-specific playback applications that can read the KID from the Common ‘pssh’ and implement application-specific license management. A Common PSSH is defined by W3C Encrypted Media Extension specification as a version one ‘pssh’ box with a W3C designated SystemID, and the track’s default_KID listed in the version one ‘pssh’ box KID array, but it contains no data in the data[] array. A presentation-specific playback application that has information on license servers, the format of license requests, etc. can use the default_KID in a Common ‘pssh’ box or the <a>Manifest</a> to request a license for each unique default_KID.</p></li>
<li><p>‘pssh’ version one boxes MAY be present in <a>CMAF Fragment</a>s for the purpose of providing protection system information, such as encrypted keys in licenses, for use by the DRM system with a SystemID matching the ‘pssh’ SystemID. Multiple ‘pssh’ boxes with different SystemIDs may be present to enable different protection systems on different devices.<br />
<br />
For example, version one ‘pssh’ boxes in <a>CMAF Fragment</a>s can be used to deliver the same encrypted licenses to all <a>Player</a>s by a channel or subscription service, but only users who have purchased and downloaded an entitlement license bound to their particular device or account can decrypt the licenses in the <a>CMAF Fragment</a>s needed to decrypt the Fragment. Since one license decrypts the other, they are said to be “chained”, and chained licenses in combination with periodic key changes can verify that each viewer is authorized by a valid account-bound entitlement license (this process is often called “key rotation”).</p>
</li>
</ul>
</section>
</section>
<section>
<h3 id="encryption-constraints">Encryption Constraints</h3>
<ul>
<li><blockquote>
<p>For a given KID, Initialization Vectors and counter values SHALL be globally unique and SHALL follow the guidelines outlined in [<a href="#CENCREF"><em>CENC</em></a>] Section 9.2 and 9.3.</p>
</blockquote></li>
<li><blockquote>
<p>Initialization Vectors for used with the ‘cenc’ scheme SHALL be limited to 8-bytes as defined in [<a href="#CENCREF"><em>CENC</em></a>] section 9.2 to avoid block counter value overlap.</p>
</blockquote></li>
<li><blockquote>
<p>Each KID and default_KID SHALL never reference more than one key value for all <a>CMAF Track</a>s. Therefore each KID SHALL be generated by the UUID algorithm specified in UUID as specified in [X667]. Note that it is possible for two different KIDs to reference the same key value.</p>
</blockquote></li>
<li><blockquote>
<p>Default_KID and key values SHALL be applied to <a>CMAF Switching Set</a>s such that the default_KID identifies a license or key sufficient to enable an authorized DRM system to decrypt the <a>CMAF Switching Set</a>. Any additional keys described by sample groups MAY be delivered in version 1 Protection System Specific Header Boxes (‘pssh’) in <a>CMAF Segment</a>s, identifying the contained KID(s), and protected by DRM specific methods.</p>
</blockquote></li>
<li><blockquote>
<p>Textual representation of KID and SystemID in <a>Manifest</a>s SHOULD use the hexadecimal string representation specified in [X667] section 6.4, derived from the 16 octet binary representation specified in section 6.2 and equivalent byte arrays specified in [<a href="#CENCREF"><em>CENC</em></a>] boxes.</p>
</blockquote></li>
</ul>
<p>Subtitle tracks shall not be encrypted.</p>
<p>The following additional constraints SHALL be applied to the encryption of NAL Structured Video tracks:</p>
<ul>
<li><blockquote>
<p>Slice headers, NAL type headers, NAL size headers, and all Non-video NALs SHALL be unencrypted.</p>
</blockquote></li>
<li><blockquote>
<p>VCL data SHALL be protected, either by full encryption or pattern encryption of the VCL slice data.</p>
</blockquote></li>
<li><blockquote>
<p>‘cenc’ scheme bytesOfProtectedData SHALL be a multiple of 16 bytes.</p>
</blockquote></li>
<li><blockquote>
<p>‘cbcs’ scheme bytesOfProtectedData SHALL start on the first complete byte of video data following the slice header, and BytesOfProtectedData = size of video slice data starting from the first complete byte of video data following the slice header</p>
</blockquote></li>
</ul>
<section>
<h4 id="clear-samples-within-an-encrypted-track">Clear Samples within an Encrypted Track</h4>
<p>In an encrypted track, the isProtected flag in the Track Encryption Box (‘tenc’) SHALL be set to 1, indicating that all samples are protected by default. Sample Groups may indicate unprotected Samples, as specified in [<a href="#CENCREF"><em>CENC</em></a>].</p>
<p>Each <a>CMAF Fragment</a> SHALL be constrained to Samples that are all protected or all unprotected, not a mix.</p>
</section>
</section>
</section>
</section>
<section>
<h2 id="video-tracks">Video Tracks</h2>
<section>
<h3 id="introduction-4">Introduction</h3>
<p>This section specifies CMAF video Tracks<span id="OLE_LINK53" class="anchor"><span id="OLE_LINK54" class="anchor"></span></span>, samples, codecs, elementary streams, and access units.</p>
<p>CMAF video Tracks conform to ISO Media files containing a single ISO Media video track with all samples stored in movie fragments formatted as Segments, as specified in [<a href="#ISOMREF"><em>ISOM</em></a>] and [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>], with additional constraints specified in this section. Elementary stream encoding constraints are specified for two widely used MPEG video codecs, AVC and HEVC, and two access unit formats and sample descriptions, one optimized for file storage, and the other for live bitstream encoding and switching similar to transport streams.</p>
<p>Constraints on Switching Sets of multiple CMAF video Tracks that enable seamless adaptive switching are specified in Section ‎6.1.6.Video Profiles are specified in ‎Annex A. to signal widely used operating points, such as SD, HD, and UHD, which further constrain codec profiles, levels, resolutions, framerates, bit depth, electro-optical transfer function, color subsampling, etc. For additional information see ‎Annex A.<br />
<a>CMAF Presentation</a> and Media Profiles. CMAF video Tracks SHALL be encoded as frames (i.e. “progressive scan”).</p>
</section>
<section>
<h2 id="video-track-container">Video Track Container</h2>
<section>
<h3 id="introduction-5">Introduction</h3>
<p>CMAF video Tracks SHALL comply with [<a href="#ISOMREF"><em>ISOM</em></a>] and [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>]. In this section, the CMAF constraints on the boxes and samples in video Tracks are specified.</p>
</section>
<section>
<h3 id="track-header-box-tkhd-1">Track Header Box (‘tkhd’)</h3>
<p>For video Tracks, the fields of the Track Header Box (‘tkhd’) shall be set to the values constrained below and specified in [<a href="#ISOMREF"><em>ISOM</em></a>].</p>
<ul>
<li><blockquote>
<p>flags = 0x000007, except for the case where the track belongs to an alternate group</p>
</blockquote></li>
<li><blockquote>
<p>The values of width and height SHALL indicate the active picture area of the video content without overscan and measured on a uniformly sampled square grid as specified in [<a href="#ISOMREF"><em>ISOM</em></a>].</p>
</blockquote></li>
<li><blockquote>
<p>The values of width and height in the Track Header Box SHALL be normalized to width and height of the encoded video, as defined below:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>The video elementary stream SHALL contain only spatial samples intended for presentation after SPS cropping parameters are applied in the decoder. The Clean Aperture box SHOULD NOT be present.</p>
</blockquote></li>
<li><blockquote>
<p>The normalized Presentation height SHALL be the number of vertical samples after SPS cropping parameters are subtracted from the encoded frame height indicated by the SPS. The height field of the visual sample entry SHALL be set to number of encoded vertical samples after cropping.</p>
</blockquote></li>
<li><blockquote>
<p>The Normalized Presentation width SHALL be the number of horizontal samples after SPS cropping parameters are subtracted from the encoded frame width calculated from SPS parameters, then multiplied by the sample aspect ratio. The sample aspect ratio is defined by the PixelAspectRatioBox if present in the sample entry, or otherwise by the aspect_ratio_idc (and if applicable the sar_width and sar_height) in SPS VUI parameters. The width field in the visual sample entry SHALL be set to the number of encoded horizontal samples after cropping, not the value of the Track Header width field, which is normalized to square presentation pixel dimensions to indicate the presented picture aspect ratio.</p>
</blockquote></li>
</ul>
<blockquote>
<p>NOTE A <a>Player</a> is expected to apply scaling and display adaptation, such as cropping or padding, to match the decoded and cropped luma sample counts and the Track Header width /height picture aspect ratio to the number of square pixels in the <a>Player</a>-determined video aperture. Segments adaptively selected from a Switching Set may have different cropped sample counts and spatial sample aspect ratios, so a <a>Player</a> must determine the correct scaling ratios to exactly equal the display aperture for each Segment to avoid scaling or displacement errors.</p>
</blockquote>
<ul>
<li><p>The value of the matrix field SHALL reflect the video orientation. Non-identity matrices SHALL be rotations in multiples of 90 degrees.</p></li>
</ul>
<ul>
<li><blockquote>
<p>When video is not rotated, matrix SHALL be {0x00010000, 0, 0, 0, 0x00010000, 0, 0, 0, 0x40000000}.</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>When video should be rotated 90 degrees clockwise for display, matrix SHOULD be {0, 0x00010000, 0, 0xFFFF0000, 0, 0, height&lt;&lt;16, 0, 0x40000000}.</p>
</blockquote></li>
</ul>
<ul>
<li><p>When video should be rotated 180 degrees for display, matrix SHOULD be {0xFFFF0000, 0, 0, 0, 0xFFFF0000, 0, width&lt;&lt;16, height&lt;&lt;16, 0x40000000}.</p></li>
<li><p>When video should be rotated 90 degrees counter-clockwise for display, matrix SHOULD be {0, 0xFFFF0000, 0, 0x00010000, 0, 0, 0, width&lt;&lt;16, 0x40000000}.</p>
</li>
</ul>
</section>
<section>
<h3 id="sample-description-box-stsd-1">Sample Description Box (‘stsd’)</h3>
<p>The Sample Description Box (‘stsd’) in a video track SHALL contain a single Sample Entry which SHALL include:</p>
<ul>
<li><blockquote>
<p>width and height field values equal to the largest cropped horizontal and vertical sample counts in any Sequence Parameter Set in the track (only one in the case of ‘avc1’ or ‘hvc1’); and</p>
</blockquote></li>
<li><blockquote>
<p>a Decoder Configuration Record:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>SHALL signal the highest Profile and Level that must be supported to decode the track, and other parameters for the video track as specified in [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>] Section 8.3.3.1 (HEVC) or [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>] Section 5.3.3.1 (AVC);</p>
</blockquote></li>
<li><blockquote>
<p>SHALL contain a single parameter set for decoder and display initialization, for a Visual Sample Entry with codingname ‘avc3’ or ‘hev1’, (SPS and PPS NALs for AVC Video, or VPS, SPS, and PPS NALs for HEVC Video). Each video sample in the <a>CMAF Track</a> SHALL reference SPS and PPS NALs stored in its CMAF video Segment and Coded Video Sequence;</p>
</blockquote></li>
<li><blockquote>
<p>SHALL contain a single decoding parameter set, for a Visual Sample Entry with codingname ‘avc1’ or ‘hvc1’, (SPS and PPS NALs for AVC Video; VPS, SPS, and PPS NALs for HEVC Video). Each video sample in the <a>CMAF Track</a> SHALL reference this parameter set in the sample entry;</p>
</blockquote></li>
<li><blockquote>
<p>MAY contain additional SEI NAL units to signal color encoding and rendering, such as mastering_display_colour_volume, SEI payloadType =137 [<a href="#H265REF">HEVC</a>] Section D.2.27;</p>
</blockquote></li>
<li><blockquote>
<p>SHOULD set LengthSizeMinusOne field to the value “3” (to indicate 4 bytes) to simplify conversion of elementary streams between MPEG-2 TS bytestreams with startcodes and [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>] with NAL length headers.</p>
</blockquote></li>
</ul>
<blockquote>
<p>Note: The size of the NAL header length field defined in video tracks [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>] is stored in the field LengthSizeMinusOne in the corresponding decoder configuration record. For AVC video AVCDecoderConfigurationRecord and for HEVC video HEVCDecoderConfigurationRecord.</p>
</blockquote>
</section>
<section>
<h3 id="picture-access-units">Picture Access Units</h3>
<p>Picture Access Units SHALL conform to the requirements of a sample for the indicated format (‘avc1’, ‘avc3’, ‘hvc1’or ‘hev1’) as specified in [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>]. Picture Access Units MAY be delimited by Access Unit Delimiter NALs. Each Access Unit is a sample stored in a Media Data Box (‘mdat’), as specified in [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>].</p>
<p><a>CMAF Segment</a>s containing ‘avc3’ or ‘hev1’ Picture Access Units SHALL contain all SPS and PPS NALs referenced by a Coded Video Sequence in the first Access Unit of that sequence, immediately following its first Access Unit Delimiter NAL (if any).</p>
<p>Access Units of type ‘avc3’and ‘hev1’ MAY retain bitstream padding and SEI messages that would change hypothetical reference decoder bitstream conformance if such conformance is necessary, such as the case where bitstreams are to be repackaged and conformance tested in MPEG-2 Transport Streams.</p>
<p>As specified in [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>], timing information provided within a video elementary stream SHALL be ignored. Instead, sample timing in the Track Run Box (‘trun’) SHALL determine picture presentation order and timing.</p>
</section>
<section>
<h3 id="sync-samples">Sync Samples</h3>
<p>A stream access point (SAP) type 1, 2, or 3 as defined by [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>] SHOULD occur approximately every 2 seconds or less within a Video Track for consistent random access.</p>
</section>
</section>
<section>
<h2 id="avc">AVC</h2>
<section>
<h3 id="storage-of-avc-elementary-streams">Storage of AVC Elementary Streams</h3>
<section>
<h4>Conformance</h4>
<p>AVC video tracks SHALL comply with Section 5 of [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>].</p>
</section>
<section>
<h4 id="visual-sample-entry">Visual Sample Entry</h4>
<p>The syntax and values for visual sample entry shall conform to AVCSampleEntry (‘avc1’) or AVCSampleEntry (‘avc3’) as defined in [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>], and the general video sample entry requirements of Section ‎9.2.3.</p>
</section>
</section>
<section>
<h3 id="constraints-on-avc-elementary-streams">Constraints on AVC Elementary Streams</h3>
<section>
<h4 id="picture-type">Picture type</h4>
<p>All pictures SHALL be encoded as coded frames, and shall not be encoded as coded fields.</p>
</section>
<section>
<h4 id="sequence-parameter-sets-sps">Sequence Parameter Sets (SPS)</h4>
<section>
<h5 id="sps-field-constraints">SPS Field Constraints</h5>
<p>Sequence Parameter Set NAL Units that occur in an AVC video <a>CMAF Track</a> shall conform to [<a href="#H264REF"><em>AVC</em></a>] with the following additional constraints:</p>
<ul>
<li><p>The following fields have pre-determined values as follows:</p>
<ul>
<li><p>frame_mbs_only_flag SHALL be set to 1</p></li>
<li><p>mb_adaptive_frame_field_flag SHALL be set to 0 if present</p></li>
<li><p>vui_parameters_present_flag SHALL be set to 1</p></li>
<li><p>gaps_in_frame_num_value_allowed_flag SHOULD be set to 0</p></li>
</ul></li>
<li><p>The values of the following fields SHALL NOT change throughout a <a>CMAF Track</a>:</p></li>
</ul>
<ul>
<li><p>chroma_format_idc</p></li>
<li><p>bit_depth_luma_minus8</p></li>
<li><p>bit_depth_chroma_minus8</p></li>
</ul>
<ul>
<li><blockquote>
<p>The values of the following fields SHALL NOT change throughout an ‘avc1’ <a>CMAF Track</a>:</p>
</blockquote></li>
</ul>
<ul>
<li><p>profile_idc</p></li>
<li><p>level_idc</p></li>
<li><p>pic_width_in_mbs_minus1</p></li>
<li><p>pic_height_in_map_units_minus1</p></li>
<li><p>frame_crop_left_offset</p></li>
<li><p>frame_crop_right_offset</p></li>
<li><p>frame_crop_top_offset</p></li>
<li><p>frame_crop_bottom_offset</p></li>
<li><p>max_num_ref_frames</p></li>
</ul>
<ul>
<li><blockquote>
<p>The values of the following fields SHOULD NOT change throughout a <a>CMAF Track</a>:</p>
</blockquote></li>
</ul>
<ul>
<li><p>seq_parameter_set_id</p>
</li>
</ul>
</section>
<section>
<h5 id="visual-usability-information-vui-parameters">Visual Usability Information (VUI) Parameters</h5>
<p>VUI parameters that occur within a CMAF AVC video Track SHALL conform to [<a href="#H264REF"><em>AVC</em></a>] with the following additional constraints:</p>
<ul>
<li><blockquote>
<p>The following fields SHALL have pre-determined values as follows:</p>
</blockquote></li>
</ul>
<ul>
<li><p>If video_signal_type_present_flag is set to 0, then video_full_range_flag SHALL be inferred to be 0.</p></li>
</ul>
<blockquote>
<p>Note: This indicates normal black “setup”, i.e. 16 for 8-bit video.</p>
</blockquote>
<ul>
<li><blockquote>
<p>aspect_ratio_info_present_flag SHALL be set to 1. aspect_ratio_idc SHALL NOT be set to 0. If sample aspect ratio is 1:1 (square), aspect_ratio_idc SHALL be set to 1.</p>
</blockquote></li>
</ul>
<blockquote>
<p>Note: This indicates Sample aspect ratio is present, not picture aspect ratio.</p>
</blockquote>
<ul>
<li><blockquote>
<p>chroma_loc_info_present_flag SHALL be set to 0</p>
</blockquote></li>
</ul>
<blockquote>
<p>Note: Indicates standard progressive 4:2:0 color subsampling.</p>
</blockquote>
<ul>
<li><blockquote>
<p>overscan_info_present_flag, if present, SHALL be set to 0</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>The following fields SHOULD have pre-determined values as follows:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>colour_description_present_flag SHOULD be set to 1. (Note that the actual values of the color description are defined by the profiles in ‎Annex A. )</p>
</blockquote></li>
<li><blockquote>
<p>If colour_description_present_flag is set to 0, this SHALL indicate the following default video coding and mastering:</p>
</blockquote></li>
<li><p>SHALL be encoded using the video parameters defined by [<a href="#R709REF"><em>R709</em></a>]; and</p></li>
<li><p>Video SHOULD be graded in a viewing environment that complies with [R2035] for presentation on a display which uses the electro-optic transfer function specified in [<a href="#R1886REF">R1886</a>] with a peak luminance of 100 cd/m2.</p></li>
</ul>
<blockquote>
<p>NOTE Per [<a href="#H264REF"><em>AVC</em></a>], if the colour_description_present_flag is set to 1, the colour_primaries, transfer_characteristics and matrix_coefficients fields SHALL be present.</p>
</blockquote>
<ul>
<li><blockquote>
<p>The values of the following fields SHALL NOT change in a <a>CMAF Track</a>:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>low_delay_hrd_flag</p>
</blockquote></li>
<li><blockquote>
<p>colour_primaries, when present</p>
</blockquote></li>
<li><blockquote>
<p>transfer_characteristics, when present</p>
</blockquote></li>
<li><blockquote>
<p>matrix_coefficients, when present</p>
</blockquote>
</li>
</ul>
</section>
</section>
<section>
<h4 id="picture-parameter-sets-pps">Picture Parameter Sets (PPS)</h4>
<p>Picture Parameter Set NAL Units that occur within a CMAF shall conform to [AVC] with the following additional constraints:</p>
<p>The value of the entropy_coding_mode_flag SHALL NOT change throughout a <a>CMAF Track</a> using an ‘avc1’ sample entry.</p>
</section>
<section>
<h4 id="measurement-of-maximum-bitrate">Measurement of Maximum Bitrate</h4>
<p>The maximum bitrate of [<a href="#H264REF"><em>AVC</em></a>] elementary streams SHALL be calculated by implementation of the buffer and timing model defined in [<a href="#H264REF"><em>AVC</em></a>] Annex C.</p>
</section>
</section>
</section>
<section>
<h2 id="hevc">HEVC</h2>
<section>
<h3 id="storage-of-hevc-elementary-streams">Storage of HEVC Elementary Streams</h3>
<section>
<h4 id="conformance-1">Conformance</h4>
<p>HEVC video tracks SHALL comply with Section 8 of [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>].</p>
</section>
<section>
<h4 id="visual-sample-entry-1">Visual Sample Entry</h4>
<p>The syntax and values for a visual sample entry shall conform to HEVCSampleEntry (‘hvc1’) or HEVCSampleEntry (‘hev1’) sample entries as defined in [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>].</p>
</section>
<section>
<h4 id="hevcdecoderconfigurationrecord">HEVCDecoderConfigurationRecord</h4>
<ul>
<li><p>For video that is captured or color graded with characteristics other than BT.709 defaults, one or more SEI NALs with additional transfer characteristics or color volume information SHOULD be stored in the HEVCDecoderConfigurationRecord to enable color and dynamic range calibration during decoder and display initialization. This includes the following SEI messages specified in Annex D of [HEVC]:</p></li>
<li><p>SEI payloadType, 23, tone_mapping_info</p></li>
<li><p>SEI payloadType 137, mastering_display_colour_volume</p></li>
<li><p>SEI payloadType 141, knee_function_info</p></li>
<li><p>SEI payloadType 142, colour_remapping_info</p></li>
<li><p>SEI payloadType 144, content_light_level_info</p></li>
<li><p>SEI payloadType 182, alternative_transfer_characteristics</p></li>
<li><p>SEI payloadType 183, ambient_viewing_environment</p></li>
</ul>
<ul>
<li><p>CMAF <a>Player</a> display processors can use SEI color grading, color volume, and dynamic range information in the HEVCDecoderConfigurationRecord to calibrate conversion of decoded HEVC numeric values to color values that are appropriate for their display characteristics and viewing conditions. Track Switching Set encoding SHALL be constrained to allow a single initialization, i.e. color lookup table selection, for the entire Track Switching Set.</p></li>
<li><p>A CMAF player can pass ST-2086 and other SEI message data to a display over HDMI, as specified in CEA 861.3 to enable color and transfer function calibration within a capable UHD/HDR display.</p>
</li>
</ul>
</section>
</section>
<section>
<h3 id="constraints-on-hevc-elementary-streams">Constraints on HEVC Elementary Streams</h3>
<section>
<h4 id="introduction-6">Introduction</h4>
<p>The following general constraints apply to all CMAF HEVC elementary streams. See ‎Annex A. for Video Profile constraints on Tier, Profile, Level, and frame rates.</p>
</section>
<section>
<h4 id="picture-type-1">Picture type</h4>
<p>All pictures SHALL be encoded as coded frames, and shall not be encoded as coded fields.</p>
</section>
<section>
<h4 id="video-parameter-sets-vps">Video Parameter Sets (VPS)</h4>
<p>Each HEVC video sample in the <a>CMAF Track</a> SHALL reference the VPS in the <a>CMAF Header</a> sample entry. VPS does not change within <a>CMAF Track</a>s or between <a>CMAF Track</a>s in a Switching Set. A CMAF HEVC track shall conform to [<a href="#H265REF"><em>HEVC</em></a>] with the following additional constraints:</p>
<ul>
<li><blockquote>
<p>The following fields SHALL have pre-determined values as follows:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>general_progressive_source_flag SHALL be set to 1</p>
</blockquote></li>
<li><blockquote>
<p>general_frame_only_constraint_flag SHALL be set to 1</p>
</blockquote></li>
<li><blockquote>
<p>general_interlaced_source_flag SHALL be set to 0</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>The condition of the following fields SHALL NOT change throughout an HEVC elementary stream:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>general_profile_space</p>
</blockquote></li>
<li><blockquote>
<p>general_profile_idc</p>
</blockquote></li>
<li><blockquote>
<p>general_tier_flag</p>
</blockquote></li>
<li><blockquote>
<p>general_level_idc</p>
</blockquote>
</li>
</ul>
</section>
<section>
<h4 id="sequence-parameter-sets-sps-1">Sequence Parameter Sets (SPS)</h4>
<section>
<h5 id="sps-fields">SPS Fields</h5>
<p>Sequence Parameter Set NAL Units that occur within a CMAF HEVC track shall conform to [<a href="#H265REF"><em>HEVC</em></a>] with the following additional constraints:</p>
<ul>
<li><blockquote>
<p>The following fields SHALL have pre-determined values as follows:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>vui_parameters_present_flag SHALL be set to 1</p>
</blockquote>
</li>
</ul>
</section>
<section>
<h5 id="visual-usability-information-vui-parameters-1">Visual Usability Information (VUI) Parameters</h5>
<p>VUI parameters that occur within a CMAF HEVC track SHALL conform to [<a href="#H265REF"><em>HEVC</em></a>] with the following additional constraints:</p>
<ul>
<li><blockquote>
<p>The following fields SHALL have pre-determined values as defined:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>aspect_ratio_info_present_flag SHALL be set to 1</p>
</blockquote></li>
<li><blockquote>
<p>chroma_loc_info_present_flag SHALL be set to 0</p>
</blockquote></li>
<li><blockquote>
<p>video_full_range_flag SHALL be set to 0</p>
</blockquote></li>
</ul>
<p>- The following fields have the following values:</p>
<ul>
<li><p>colour_description_present_flag SHOULD be set to 1.</p></li>
<li><p>If colour_description_present_flag is set to 0, the following default video coding and mastering SHALL be assumed:</p>
<ul>
<li><p>Video is encoded using the video parameters defined by [<a href="#R709REF"><em>R709</em></a>]; and</p></li>
<li><p>Video is graded in a viewing environment that complies with [<a href="#R2035REF"><em>R2035</em></a>] for presentation on a display which uses the electro-optic transfer function specified in [<a href="#R1886REF"><em>R1886</em></a>] with a peak luminance of 100 cd/m2.</p></li>
</ul></li>
</ul>
<blockquote>
<p>NOTE Per [<a href="#H265REF"><em>HEVC</em></a>], if the colour_description_present_flag is set to 1, the colour_primaries, transfer_characteristics and matrix_coefficients fields are present in the VUI.</p>
</blockquote>
<ul>
<li><blockquote>
<p>overscan_info_present_flag shall be set to 0</p>
</blockquote></li>
<li><blockquote>
<p>overscan_appropriate shall NOT be present</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>The values of the following fields SHALL NOT change throughout a <a>CMAF Track</a> and Switching Set:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>low_delay_hrd_flag</p>
</blockquote></li>
<li><blockquote>
<p>colour_description_present_flag</p>
</blockquote></li>
<li><blockquote>
<p>colour_primaries, when present</p>
</blockquote></li>
<li><blockquote>
<p>transfer_characteristics, when present</p>
</blockquote></li>
<li><blockquote>
<p>matrix_coeffs, when present</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>The values of the following fields SHOULD NOT change throughout a <a>CMAF Track</a>:</p>
</blockquote></li>
</ul>
<ul>
<li><blockquote>
<p>vui_time_scale</p>
</blockquote></li>
<li><blockquote>
<p>vui_num_units_in_tick</p>
</blockquote>
</li>
</ul>
</section>
</section>
<section>
<h4 id="maximum-bitrate">Maximum Bitrate</h4>
<p>The maximum bitrate of HEVC elementary streams SHALL be calculated by implementation of the buffer and timing model defined in [<a href="#H265REF"><em>HEVC</em></a>] Annex C.</p>
</section>
<section>
<h4 id="frame-rate-in-the-elementary-stream">Frame rate in the Elementary Stream</h4>
<p>Sample durations stored in the ISO Media Track Run Box SHALL determine the frame rate of a Track.</p>
</section>
</section>
</section>
<section>
<h2 id="video-codec-parameters">Video codec parameters</h2>
<section>
<h3 id="avc-signaling-of-codecs-parameter-informational">AVC signaling of “codecs” parameter (Informational)</h3>
<p>Presentation Applications SHOULD signal the video codec profile and level of each AVC Track and Switching Set using parameters conforming to [<a href="#RFC6381REF"><em>RFC6381</em></a>] and [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>] Annex E.</p>
</section>
<section>
<h3 id="hevc-signaling-of-codecs-parameters-informational">HEVC signaling of “codecs” parameters (Informational)</h3>
<p>Presentation Applications SHOULD signal video codec profile and levels of each HEVC Track and Switching Set using parameters conforming to [<a href="#RFC6381REF"><em>RFC6381</em></a>] and [<a href="#ISOVIDEOREF"><em>ISOVIDEO</em></a>] Annex E.</p>
</section>
<section>
<h3 id="encoding-overview">Encoding Overview</h3>
<p>Video Tracks SHALL only encode spatial samples intended for presentation on all displays. Padding such as letterbox and pillarbox bars SHOULD NOT be encoded.</p>
<p>The active image SHOULD be upper left justified, and only one row or one column of partially filled macroblocks encoded if the image height or width is not a multiple of 16 samples. Extra samples SHALL be cropped by setting SPS cropping parameters frame_crop_bottom_offset or frame_crop_right_offset for AVC; or conf_win_bottom_offset or conf_win_right_offset for HEVC.</p>
<p>The VUI parameter, aspect_ratio_idc, SHALL be present if square samples are not encoded, and SHOULD always be present to avoid incorrectly assuming the default value of 1.</p>
<p>Each device and display system is expected to frame the decoded and cropped video to its video display size and shape using methods such as scaling, stretching, cropping, padding with letterbox or pillarbox bars, or framing in a window. Each visual Segment may be encoded with different sample width and height, so devices must scale each Segment to fit the same display aperture and maintain the correct picture aspect ratio to avoid scaling and placement errors during bitrate switching.</p>
</section>
<section>
<h3 id="video-color-and-dynamic-range-mastering">Video color and dynamic range mastering</h3>
<p>Video streams conforming to CMAF SHALL be encoded using the transfer characteristics, color parameters, and grading specified in each video Media Profile, and the Media Profile, indicated by that Media Profile’s compatibility brand in the <a>CMAF Header</a>. See Video Media Profiles and Track Brands Annex [‎A.2].</p>
<p>For all Media Profiles, unless signaled otherwise in Sequence Parameter Sets or SEI messages, default transfer characteristics and grading SHALL be assumed. Default grading is defined as a viewing environment that complies with [<a href="#R2035REF"><em>R2035</em></a>] for presentation on a display which uses the electro-optic transfer function specified in [R1886] with a peak luminance of 100 cd/m2.</p>
<p>Video MAY be graded for presentation on a display which uses an electro-optic transfer function not specified in [R1886] with a peak luminance greater than 100 cd/m2, in which case, the grading profile SHOULD be signaled by VUI and/or [ST2086] metadata in SEI messages contained in the sample entry ‘avcC’ or ‘hvcC’ box, and content descriptors in CMAF compliant <a>Manifest</a>s.</p>
</section>
</section>
<section>
<h2 id="video-elementary-stream-embedded-captions">Video Elementary Stream Embedded Captions</h2>
<section>
<h3 id="carriage-of-cea-608708-in-sei-messages">Carriage of CEA-608/708 in SEI messages</h3>
<p>CEA 608/708 caption data [CEA608], [CEA708] MAY be stored in SEI messages described as user data registered by Rec. ITU-T T.35, with SEI payloadType = 4 and the registered identifier in the field user_data_registered_itu_t_t35. See [<a href="#H265REF"><em>HEVC</em></a>] Section D.2.6. or [AVC] Section D.2.5.</p>
</section>
<section>
<h3 id="signaling-the-presence-of-cea-608708-in-sei-messages">Signaling the presence of CEA-608/708 in SEI messages</h3>
<p>The presence of CEA-608/708 data in SEI messages in a video track SHOULD be signaled by the presence of one or more Track boxes with Media Type ‘sbtl’ with a Sample Entry codingname of ‘csei’ and a track reference of type ‘csei’ to the video track. This track SHALL NOT reference any media samples, and it SHALL NOT have any ‘traf’ boxes in Segments. The languages contained in the caption data MAY be identified using an Extended Language Box (‘elng’) in the Media Data Information Box (‘mdia’) in a Track Box (‘trak’) for each language present.</p>
<p>The ‘csei’ sample entry is derived from the PlainTextSampleEntry of [ISOM], Section 12.5.3.2, with codingname equal ‘csei’.</p>
<p>class PlainTextSampleEntry(codingname) extends SampleEntry (codingname) {<br />
}</p>
</section>
<section>
<h3 id="cea-608708-in-sei-messages">CEA-608/708 in SEI messages</h3>
<p>ANSI/SCTE 128 2013-a [<a href="#SCTE128"><em>SCTE128</em></a>] defines in section 8.1 Encoding and transport of caption, active format description (AFD) and bar data. Based on this, a video track MAY carry SEI messages that carry CEA-608/708 closed caption data. The SEI message payloadType=4 is used to indicates that Rec. ITU-T T.35 based SEI messages are contained in an SEI message.</p>
<p>In summary the following is included in [<a href="#SCTE128"><em>SCTE128</em></a>] to signal CEA-608/708 in SEI messages:</p>
<ul>
<li><p>SEI payloadType is set to 4</p></li>
<li><p>itu_t_t35_country_code – A fixed 8-bit field, the value of which shall be 0xB5.</p></li>
<li><p>itu_t_t35_provider_code – A fixed 16-bit field registered by the ATSC. The value shall be 0x0031.</p></li>
<li><p>user_identifier – This is a 32-bit code that indicates the contents of the user_structure() and is 0x47413934 (“GA94”).</p></li>
<li><p>user_structure() – This is a variable length data structure ATSC1_data() defined in section 8.2 of ANSI/SCTE 128 2013-a.</p></li>
<li><p>user_data_type_code is set to 0x03 for indicating captioning data in the user_data_type_structure()</p></li>
<li><p>user_data_type_structure() is defined in section 8.2.2 of [<a href="#SCTE128"><em>SCTE128</em></a>] for Closed Captioning and defines the details on how to encapsulate the captioning data.</p></li>
</ul>
<p>A <a>Manifest</a> can signal the presence of SEI-stored closed captions. <a>Player</a>s may automatically select Tracks signaled to contain captions if the user or <a>Player</a> indicates a preference for audio accessibility.</p>
</section>
</section>
</section>
<section>
<h2 id="audio-tracks">Audio Tracks</h2>
<section>
<h2 id="overview-1">Overview</h2>
<p>This section describes audio Tracks, their general container and Track constraints, and requirements for audio Media Profiles that specify codecs, elementary streams and sample formats.</p>
<p>In addition, a specific Track format and Media Profile binding is specified for a “core” set of widely interoperable AAC stereo codecs. The system layer specified in [<a href="#MP4SYS">MP4SYS</a>] is used to embed the AAC audio elementary streams in Tracks.</p>
</section>
<section>
<h2 id="general-requirements-for-cmaf-compatible-audio-media-profiles">General Requirements for CMAF Compatible Audio Media Profiles</h2>
<p>All audio Media Profiles SHALL define a compatibility brand for the ‘ftyp’ box in the <a>CMAF Header</a>.</p>
<p>All audio Media Profiles SHALL define sample entries and decoder configuration information required in the <a>CMAF Header</a>.</p>
<p>All audio Media Profiles SHALL define Internet Media Type “codecs” parameters that can be used to identify the <a>CMAF Track</a> in a <a>Manifest</a>.</p>
<p>All audio Media Profiles SHALL define <a>CMAF Fragment</a> and sample encoding constraints and signaling necessary to random access Segments and samples, and initiate decoded output (e.g. “priming” predicted samples).</p>
<p>Audio Track Switching Sets SHALL be bitstream switchable unless a Media Profile specifies that it is never bitstream switchable (in which case, it always requires processing a <a>CMAF Header</a> prior to every sequence of Segments from a different <a>CMAF Track</a>).</p>
<p>CMAF Compatible audio Media Profiles MAY define Switching Set constraints to enable seamless bitrate switching between time aligned <a>CMAF Fragment</a>s in alternative <a>CMAF Track</a>s.</p>
<p>All audio Tracks SHOULD contain loudness and dynamic range information in the bitstream conforming to DRC Presentation Mode in ISO/IEC 14496-3:2009 and Amendment 4 [AAC].</p>
<p>See [‎A.3] for details of audio media profiles and track brands.</p>
</section>
<section>
<h2 id="audio-track-container-constraints">Audio Track Container Constraints</h2>
<section>
<h3 id="general">General</h3>
<p>The common ISO Media track structure for storing audio in a <a>CMAF Track</a> is described below. All audio formats SHALL comply with these constraints.</p>
</section>
<section>
<h3 id="track-header-box-tkhd-2">Track Header Box (‘tkhd’)</h3>
<p>For audio tracks, the fields of the Track Header Box shall be set to the values specified below. Other fields may be set per [<a href="#ISOMREF">ISOM</a>] Section 8.3.2.</p>
<ul>
<li><p>flags = 0x000007, except for the case where the track belongs to an alternate group</p></li>
<li><p>layer = 0</p></li>
<li><p>volume = 0x0100</p></li>
<li><p>matrix = {0x00010000, 0, 0, 0, 0x00010000, 0, 0, 0, 0x40000000} // unity matrix</p></li>
<li><p>width = 0</p></li>
<li><p>height = 0</p></li>
<li><p>duration = 0 (duration of the ‘trak’ box, which contains no samples)</p></li>
</ul>
</section>
<section>
<h3 id="sync-sample-box-stss">Sync Sample Box (‘stss’)</h3>
<p>The Sync Sample Box (‘stss’) SHALL NOT be used.</p>
<blockquote>
<p>NOTE “sync sample” in movie Fragments cannot be signaled by the absence of the Sync Sample box (‘stss’) or by the presence of the Sync Sample box (‘stss’), since this box is not designed to list sync samples in movie Fragments.</p>
</blockquote>
<ul>
<li><p>For audio formats in which every audio access unit is a random access point (sync sample), signaling can be achieved by other means such as setting the 'sample_is_non_sync_sample' flag to &quot;0&quot; in the 'default_sample_flags' field in the Track Extends box (‘trex’).</p>
</li>
</ul>
</section>
<section>
<h3 id="handler-reference-box-hdlr">Handler Reference Box (‘hdlr’)</h3>
<p>The syntax and values for the Handler Reference Box (‘hdlr’) for audio tracks shall conform to [ISOM] with the following additional constraints:</p>
<ul>
<li><p>The handler_type field shall be set to “soun”</p>
</li>
</ul>
</section>
<section>
<h3 id="sound-media-header-box-smhd">Sound Media Header Box (‘smhd’)</h3>
<p>The syntax and values for the Sound Media Header Box shall conform to [ISOM] with the following additional constraints:</p>
<ul>
<li><p>The following fields shall be set as defined:</p></li>
</ul>
<ul>
<li><p>balance = 0</p>
</li>
</ul>
</section>
<section>
<h3 id="sample-description-box-stsd-2">Sample Description Box (‘stsd’)</h3>
<p>As specified in [<a href="#ISOMREF">ISOM</a>], the Sample Description Box (‘stsd’) contains the AudioSampleEntry Box or AudioSampleEntryV1 Box.</p>
<p>See the guidelines in section 12.2.3.1 of the fifth edition of [ISOM] ISOMFor each of the audio formats supported by the CMAF, a specific audio sample entry box is derived from one of the AudioSampleEntry Boxes defined in [ISOM]. Each codec-specific SampleEntry Box is identified by a unique codingname value, and specifies the audio format used to encode the audio track, and describes the configuration of the audio elementary stream.</p>
<p>Table 3 lists audio formats used by Media Profiles that are defined in the CMAF specification ‎A.3, and the corresponding SampleEntry that is present in the Sample Description Box for each format.</p>
<p>Table 3 – AAC Core audio formats</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">codingname</th>
<th style="text-align: left;">Audio Format</th>
<th style="text-align: left;">SampleEntry Type</th>
<th style="text-align: left;">Section Reference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">mp4a</td>
<td style="text-align: left;">MPEG-4 AAC LC</td>
<td style="text-align: left;">MP4AudioSampleEntry</td>
<td style="text-align: left;">Section ‎10.4.3</td>
</tr>
<tr class="even">
<td style="text-align: left;">mp4a</td>
<td style="text-align: left;">MPEG-4 HE AAC v1 or v2</td>
<td style="text-align: left;">MP4AudioSampleEntry</td>
<td style="text-align: left;">Section ‎10.4.5</td>
</tr>
</tbody>
</table>
</section>
<section>
<h3 id="shared-elements-of-audiosampleentry">Shared elements of AudioSampleEntry</h3>
<p>For all audio formats supported by CMAF, the following elements of the AudioSampleEntry box defined in [ISOM] are shared:</p>
<pre><code>class AudioSampleEntry(codingname) 
	extends SampleEntry(codingname)
{
	const unsigned int(32)     reserved[2] = 0;
	template unsigned int(16)  channelcount;
	template unsigned int(16)  samplesize = 16;
	unsigned int(16)           pre_defined = 0;
	const unsigned int(16)     reserved = 0;
	template unsigned int(32)  sampleRate; 
	(codingnamespecific)Box
}</code></pre>
<p>For all audio Media Profiles in CMAF, the value of the samplesize parameter shall be set to 16.</p>
<p>Each of the audio formats supported by the CMAF extends the AudioSampleEntry box through the addition of a box (shown above as “(codingnamespecific)Box”) containing codec-specific information that is placed within the AudioSampleEntry. This information is described in the following codec-specific sections.</p>
</section>
</section>
<section>
<h2 id="cmaf-requirements-for-aac-audio">CMAF Requirements for AAC Audio</h2>
<section>
<h3 id="signaling">Signaling</h3>
<p>The signaling of the codecs MIME parameter is according to [<a href="#RFC6381REF"><em>RFC6381</em></a>] as shown in</p>
<p>Table 4.<span id="_Ref416538860" class="anchor"><span id="_Toc438473884" class="anchor"></span></span></p>
<p>Table 4 - AAC Codecs MIME parameter according to RFC 6381</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Codec</td>
<td style="text-align: left;">MIME type</td>
<td style="text-align: left;">codecs parameter</td>
<td style="text-align: left;">ISO BMFF Encapsulation</td>
</tr>
<tr class="even">
<td style="text-align: left;">MPEG-4 AAC-LC</td>
<td style="text-align: left;">audio/mp4</td>
<td style="text-align: left;">mp4a.40.2</td>
<td style="text-align: left;">ISO/IEC 14496-14</td>
</tr>
<tr class="odd">
<td style="text-align: left;">MPEG-4 HE-AAC v1</td>
<td style="text-align: left;">audio/mp4</td>
<td style="text-align: left;">mp4a.40.5</td>
<td style="text-align: left;">ISO/IEC 14496-14</td>
</tr>
<tr class="even">
<td style="text-align: left;">MPEG-4 HE-AAC v2</td>
<td style="text-align: left;">audio/mp4</td>
<td style="text-align: left;">mp4a.40.29</td>
<td style="text-align: left;">ISO/IEC 14496-14</td>
</tr>
</tbody>
</table>
<p>Note: HE-AACv1 is a superset of AAC-LC, and HE-AACv2 is a superset of HE-AAC v1. It is assumed that a decoder capable of fully decoding HE-AACv2 is also capable of decoding HE-AACv1 or AAC-LC.</p>
</section>
<section>
<h3 id="general-considerations-for-aac-audio-encoding">General Considerations for AAC Audio Encoding</h3>
<p>The AAC codec uses frames of a fixed length, and a transform which applies over two frames. To obtain the correct audio from a frame, both frames in the transform are needed, and hence both the prior encoded frame and the current encoded frame need to be decoded to output the first frame. This is sometimes called “priming”.</p>
<p>In order to obtain correctly synchronized audio at the start of a Track, encoders typically add some silent audio before the start of the audio signal so the first audio frame will decode in sync with the first video sample. All encoders necessarily encode an additional frame to output the last frame of audio content. All frames at the end of a recording that contain content added to flush the encoder SHOULD NOT be included in a Track.</p>
<p>Files SHALL indicate that initial added audio be removed, by using an edit list, as specified in Section‎7.5.14.</p>
<p>The pre-roll sample group SHOULD be used to indicate that to get the correct audio out of any frame one must pass the previous frame to the decoder and discard the resulting output.</p>
<p>Figure 4 illustrates an AAC bit-stream, both encoded and framed in Access Units in a track.</p>
<p><img src="media/example-aac-access-units.png" width="578" height="242" alt="Example of AAC Access Units"/></p>
<p><span id="_Ref416538911" class="anchor"><span id="_Toc447628028" class="anchor"></span></span>Figure 4 - Example of AAC Access Units</p>
<p>In Figure 5, the enclosed numbers indicate which input blocks are used for prediction and encoding in an encoded frame; for example, [1,2] indicates that block 2 is predicted from frame 1. The source block labelled “Dummy” is audio or silence encoded to output block 5, but is not included in the coded stream in the Track. The letter N indicates encoded silence in the last frame. The last audio frame MAY contain silence if the audio source ends prior to the frame boundary.</p>
<p>The audio stream SHOULD contain DRC and loudness metadata according to [AAC]. The audio encoder SHOULD set the Program Reference Level to the loudness level of the audio stream. The audio decoder SHALL use the Program Reference Level, if available, to achieve a desired target loudness, if applicable. The audio encoder SHOULD generate DRC metadata for light compression encoded in the dyn_rng_ctl and dyn_rng_sgn fields of dynamic_range_info() in the FIL element and DRC metadata for heavy compression in the compression_value field of MPEG4_ancillary_data() in the DSE (data stream element). The audio decoder SHALL apply the DRC metadata, if present, according to [AAC] Amendment 4 including the DRC Presentation Mode value of the drc_presentation_mode field.</p>
</section>
<section>
<h3 id="mpeg-4-aac-lc">MPEG-4 AAC LC</h3>
<section>
<h4 id="storage-of-mpeg-4-aac-lc-media-samples">Storage of MPEG-4 AAC LC Media Samples</h4>
<p>Storage of MPEG-4 AAC LC elementary stream samples within a <a>CMAF Track</a> shall be according to [MP4]. The following additional constraints also apply:</p>
<ul>
<li><p>An audio sample shall consist of a single AAC audio access unit.</p></li>
<li><p>The parameter values of AudioSampleEntry, DecoderConfigDescriptor, and DecoderSpecificInfo shall be consistent with the configuration of the AAC audio stream.</p>
</li>
</ul>
</section>
<section>
<h4 id="audio-sample-entry-box-for-mpeg-4-aac-lc">Audio Sample Entry Box for MPEG-4 AAC LC</h4>
<section>
<h5 id="field-values">Field Values</h5>
<p>The syntax and values of the AudioSampleEntry shall conform to MP4AudioSampleEntry (‘mp4a’) as defined in [MP4], and the following fields shall be set as defined:</p>
<ul>
<li><p>channelcount = 1 (for mono) or 2 (for stereo)</p></li>
</ul>
<p>For MPEG-4 AAC, the (codingnamespecific)Box that extends the MP4AudioSampleEntry is the ESDBox defined in [MP4], which contains an ES_Descriptor.</p>
</section>
<section>
<h5 id="esdbox">ESDBox</h5>
<p>The syntax and values for ES_Descriptor shall conform to [MPEG4S], and the fields of the ES_Descriptor shall be set to the following specified values. Descriptors other than those specified below shall not be used.</p>
<ul>
<li><p>ES_ID = 0</p></li>
<li><p>streamDependenceFlag = 0</p></li>
<li><p>URL_Flag = 0;</p></li>
<li><p>OCRstreamFlag = 0</p></li>
<li><p>streamPriority = 0</p></li>
<li><p>decConfigDescr = DecoderConfigDescriptor</p></li>
<li><p>slConfigDescr = SLConfigDescriptor, predefined type 2</p></li>
</ul>
</section>
<section>
<h5 id="decoderconfigdescriptor">DecoderConfigDescriptor</h5>
<p>The syntax and values for DecoderConfigDescriptor shall conform to [MPEG4S], and the fields of this descriptor shall be set to the following specified values. In this descriptor, decoderSpecificInfo shall be used, and ProfileLevelIndicationIndexDescriptor shall not be used.</p>
<ul>
<li><p>objectTypeIndication = 0x40 (Audio)</p></li>
<li><p>streamType = 0x05 (Audio Stream)</p></li>
<li><p>upStream = 0</p></li>
<li><p>decSpecificInfo = AudioSpecificConfig</p></li>
</ul>
</section>
<section>
<h5 id="audiospecificconfig">AudioSpecificConfig</h5>
<p>The syntax and values for AudioSpecificConfig shall conform to [AAC], and the fields of AudioSpecificConfig shall be set to the following specified values:</p>
<ul>
<li><p>audioObjectType = 2 (AAC LC)</p></li>
<li><p>channelConfiguration = 1 (for single mono) or 2 (for stereo)</p></li>
<li><p>GASpecificConfig</p></li>
</ul>
<p>Channel assignment shall not be changed within the audio stream within a Track.</p>
</section>
<section>
<h5 id="gaspecificconfig">GASpecificConfig</h5>
<p>The syntax and values for GASpecificConfig shall conform to [AAC], and the fields of GASpecificConfig shall be set to the following specified values:</p>
<ul>
<li><p>frameLengthFlag = 0 (1024 lines IMDCT)</p></li>
<li><p>dependsOnCoreCoder = 0</p></li>
<li><p>extensionFlag = 0</p></li>
</ul>
</section>
</section>
</section>
<section>
<h3 id="mpeg-4-aac-lc-elementary-stream-constraints">MPEG-4 AAC LC Elementary Stream Constraints</h3>
<section>
<h4 id="general-encoding-constraints">General Encoding Constraints</h4>
<p>MPEG-4 AAC elementary streams shall conform to the requirements of the MPEG-4 AAC profile at Level 2 as specified in [AAC] with the following restrictions:</p>
<ul>
<li><p>Only the MPEG-4 AAC LC object type shall be used.</p></li>
<li><p>The elementary stream shall be a Raw Data stream. ADTS and ADIF shall not be used.</p></li>
<li><p>The transform length of the IMDCT for AAC shall be 1024 samples for long and 128 for short blocks.</p></li>
<li><p>The following parameters shall not change within the elementary stream</p></li>
</ul>
<ul>
<li><p>Audio Object Type</p></li>
<li><p>Sampling Frequency</p></li>
<li><p>Channel Configuration</p></li>
</ul>
</section>
<section>
<h4 id="syntactic-elements">Syntactic Elements</h4>
<section>
<h5 id="the-syntax-and-values-for-syntactic-elements-shall-conform-to-aac.-arrangement-of-syntactic-elements">The syntax and values for syntactic elements shall conform to [AAC]. Arrangement of Syntactic Elements</h5>
<ul>
<li><p>Syntactic elements shall be arranged in the following order for the channel configurations below.</p></li>
</ul>
<ul>
<li><p>&lt;SCE&gt;, &lt;optional additional elements&gt;, &lt;TERM&gt;… for mono</p></li>
<li><p>&lt;CPE&gt;, &lt;optional additional elements&gt;, &lt;TERM&gt;... for stereo</p></li>
</ul>
<blockquote>
<p>Note: Angled brackets (&lt;&gt;) are delimiters for syntactic elements.</p>
</blockquote>
</section>
<section>
<h5 id="individual_channel_stream">individual_channel_stream</h5>
<ul>
<li><p>The syntax and values for individual_channel_stream shall conform to [AAC]. The following fields shall be set as defined:</p></li>
</ul>
<ul>
<li><p>gain_control_data_present = 0</p>
</li>
</ul>
</section>
<section>
<h5 id="maximum-bitrate-1">Maximum Bitrate</h5>
<p>The maximum bitrate of MPEG-4 AAC LC [2-Channel] elementary streams SHALL be calculated in accordance with the AAC buffer requirements as defined in ISO/IEC 14496-3:2009, section 4.5.3. Only the raw data stream SHALL be considered in determining the maximum bitrate (system-layer descriptors are excluded).</p>
</section>
</section>
</section>
<section>
<h3 id="mpeg-4-he-aac-v1-and-he-aac-v2">MPEG-4 HE AAC v1 and HE AAC v2</h3>
<section>
<h4 id="storage-of-mpeg-4-he-aac-v1-and-he-aac-v2-media-samples">Storage of MPEG-4 HE AAC v1 and HE AAC v2 Media Samples</h4>
<p>Storage of MPEG-4 HE AAC v1 or HE AAC v2 elementary streams within a <a>CMAF Track</a> shall be according to [MP4]. The following constraints also apply.</p>
<ul>
<li><p>An audio sample shall consist of a single HE AAC v1 or HE AAC v2 audio access unit.</p></li>
<li><p>The parameter values of AudioSampleEntry, DecoderConfigDescriptor, and DecoderSpecificInfo shall be consistent with the configuration of the MPEG-4 HE AAC v1 or HE AAC v2 audio stream.</p>
</li>
</ul>
</section>
<section>
<h4 id="audio-sample-entry-box-for-mpeg-4-he-aac-v1-and-he-aac-v2">Audio Sample Entry Box for MPEG-4 HE AAC v1 and HE AAC v2</h4>
<section>
<h5 id="field-values-1">Field Values</h5>
<p>The syntax and values of the AudioSampleEntry box shall conform to MP4AudioSampleEntry (‘mp4a’) defined in [MP4], and the following fields shall be set as defined:</p>
<ul>
<li><p>channelcount = 1 (for HE AAC v2 and mono HE AAC v1) or 2 (for stereo HE AAC v1)</p></li>
</ul>
<p>For the core MPEG-4 AAC, the (codingnamespecific)Box that extends the MP4AudioSampleEntry is the ESDBox defined in ISO 14496-14 [14], which contains an ES_Descriptor.</p>
</section>
<section>
<h5 id="esdbox-1">ESDBox</h5>
<p>The ESDBox contains an ES_Descriptor.</p>
<ul>
<li><p>The syntax and values for ES_Descriptor shall conform to [MPEG4S], and the fields of the ES_Descriptor shall be set to the following specified values. Descriptors other than those specified below shall not be used.</p></li>
</ul>
<ul>
<li><p>ES_ID = 0</p></li>
<li><p>streamDependenceFlag = 0</p></li>
<li><p>URL_Flag = 0</p></li>
<li><p>OCRstreamFlag = 0 (false)</p></li>
<li><p>streamPriority = 0</p></li>
<li><p>decConfigDescr = DecoderConfigDescriptor</p></li>
<li><p>slConfigDescr = SLConfigDescriptor, predefined type 2</p></li>
</ul>
</section>
<section>
<h5 id="decoderconfigdescriptor-1">DecoderConfigDescriptor</h5>
<ul>
<li><p>The syntax and values for DecoderConfigDescriptor shall conform to [MPEG4S], and the fields of this descriptor shall be set to the following specified values. In this descriptor, DecoderSpecificInfo shall be used, and ProfileLevelIndicationIndexDescriptor shall not be used.</p></li>
</ul>
<ul>
<li><p>objectTypeIndication = 0x40 (Audio)</p></li>
<li><p>streamType = 0x05 (Audio Stream)</p></li>
<li><p>upStream = 0</p></li>
<li><p>decSpecificInfo = AudioSpecificConfig</p></li>
</ul>
</section>
<section>
<h5 id="audiospecificconfig-1">AudioSpecificConfig</h5>
<ul>
<li><p>The syntax and values for AudioSpecificConfig shall conform to [AAC] and the fields of AudioSpecificConfig shall be set to the following specified values:</p></li>
</ul>
<ul>
<li><p>audioObjectType = 2 (AAC LC)</p></li>
<li><p>channelConfiguration = 1 (for HE AAC v2 or mono HE AAC v1) or 2 (for stereo HE AAC v1)</p></li>
<li><p>GASpecificConfig</p></li>
<li><p>extensionAudioObjectType = 5 (SBR) or 29 (PS)</p></li>
</ul>
<p>This configuration uses explicit hierarchical signaling to indicate the use of the SBR coding tool, and the PS coding tool.</p>
</section>
<section>
<h5 id="gaspecificconfig-1">GASpecificConfig</h5>
<ul>
<li><p>The syntax and values for GASpecificConfig shall conform to [AAC], and the fields of GASpecificConfig shall be set to the following specified values.</p></li>
</ul>
<ul>
<li><p>frameLengthFlag = 0 (1024 IMDCT lines)</p></li>
<li><p>dependsOnCoreCoder = 0</p></li>
<li><p>extensionFlag = 0</p></li>
</ul>
</section>
</section>
</section>
<section>
<h3 id="mpeg-4-he-aac-v1-and-he-aac-v2-elementary-stream-constraints">MPEG-4 HE AAC v1 and HE AAC v2 Elementary Stream Constraints</h3>
<section>
<h4 id="general-encoding-constraints-1">General Encoding Constraints</h4>
<blockquote>
<p>Note: MPEG-4 HE AAC v2 is a superset of MPEG-4 AAC LC and MPEG-4 HE AAC v1.</p>
</blockquote>
<p>The MPEG-4 HE AAC v1 and HE AAC v2 elementary stream as defined in [AAC] shall conform to the requirements of MPEG-4 HE AAC v1 at Level 2 and MPEG-4 HE AAC v2 at Level 2, respectively, except as follows:</p>
<ul>
<li><p>The elementary stream may be encoded according to the MPEG-4 AAC LC, HE AAC v1 or HE AAC v2. Use of the MPEG-4 HE AAC v2 is recommended for 32 kbps or lower.</p></li>
<li><p>When using HE-AACv1 and HE-AACv2 bitstreams, explicit backwards compatible signaling SHALL be used to indicate the use of the SBR and PS coding tools. <a>CMAF Segment</a>s containing HE-AAC SHALL start with a type 1 SAP, notably, the SBR configuration information SHALL be in the first packet.</p></li>
<li><p>The audio shall be encoded in mono, parametric stereo or 2-channel stereo. (Mono only if the source content is recorded in mono.)</p></li>
<li><p>The IMDCT size for AAC shall be 1024 lines for long and 128 lines for short blocks.</p></li>
<li><p>The elementary stream shall be a Raw Data stream. ADTS and ADIF shall not be used.</p></li>
<li><p>The following parameters shall not change within the elementary stream:</p></li>
</ul>
<ul>
<li><p>Audio Object Type</p></li>
<li><p>Sampling Frequency</p></li>
<li><p>Channel Configuration</p></li>
</ul>
</section>
<section>
<h4 id="syntactic-elements-1">Syntactic Elements</h4>
<section>
<h5 id="syntax-and-values-of-syntactic-elements">Syntax and Values of Syntactic Elements</h5>
<p>The syntax and values for syntactic elements shall conform to [AAC]. The following elements shall not be present in an MPEG-4 HE AAC v1 or HE AAC v2 elementary stream:</p>
<ul>
<li><p>coupling_channel_element (CCE)</p></li>
<li><p>program_config_element (PCE).</p></li>
</ul>
</section>
<section>
<h5 id="arrangement-of-syntactic-elements">Arrangement of Syntactic Elements</h5>
<ul>
<li><p>Syntactic elements shall be arranged in the following order for the channel configurations below.</p></li>
</ul>
<ul>
<li><p>&lt;SCE&gt;&lt;optional additional elements&gt;&lt;TERM&gt;… for HE AAC v2 and mono HE AAC v1</p></li>
<li><p>&lt;CPE&gt;&lt;optional additional elements&gt;&lt;TERM&gt;... for stereo HE AAC v1</p></li>
</ul>
</section>
</section>
<section>
<h4 id="maximum-bitrate-2"> Maximum Bitrate</h4>
<p>The maximum bitrate of MPEG-4 HE AAC v1 or HE AAC v2 elementary streams in a CMAF SHALL be calculated in accordance with the AAC buffer requirements as defined in [AAC] section 4.5.3. Only the raw data stream SHALL be considered in determining the maximum bitrate (system-layer descriptors are excluded).</p>
</section></section>
</section>
</section>
<section>
<h2 id="subtitles-and-captions">Subtitles and Captions</h2>
<section>
<h2 id="introduction-7">Introduction</h2>
<p>CMAF supports the following formats for carrying subtitles and captions:</p>
<ul>
<li><p>WebVTT</p></li>
<li><p>TTML</p></li>
<li><p>CEA-608</p></li>
<li><p>CEA-708</p></li>
</ul>
<p>The term “subtitles” in this document is used to mean a visual presentation of text that is synchronized with video and audio tracks, inclusive of “closed captions”. Subtitles are presented for various purposes such as dialog language translation, localized titles, content description, and descriptive captions for hearing impaired viewers or presentation situations where audio is unavailable or inappropriate.</p>
<p>Closed captions used in broadcast video signals are also supported. In North America, closed captions, containing subtitles intended primarily for the hearing impaired viewers, are commonly delivered in one of two formats: CEA-608 and CEA-708. <a href="#_Video_Elementary_Stream"><em>See Embedded Captions</em></a>.</p>
</section>
<section>
<h2 id="webvtt">WebVTT</h2>
<p>WebVTT is a subtitle format that is commonly used to render subtitles in web browsers [<a href="#VTT"><em>VTT</em></a>]. It can also be used to render subtitles in other types of media presentation applications.</p>
<p>In CMAF, WebVTT documents are encapsulated in CMAF Media Segments contained in a <a>CMAF Track</a>. WebVTT Segments may be sequentially downloaded, synchronized, and presented the same as audio and video <a>CMAF Segment</a>s. A WebVTT document can be contained in a single Segment that spans the entire duration of a prerecorded Presentation, or span Segments with durations similar to audio and video, which is necessary in the case of low latency live streaming. The encapsulation of WebVTT documents in ISO Base Media movie fragments and tracks is defined in MPEG-4 Part 30 [ISOTXT].</p>
<p>WebVTT subtitle tracks are defined using a track handler_type of ‘text’ with a codingname of ‘wvtt’. WebVTT subtitle tracks store samples corresponding to zero or more simultaneously presented WebVTT cues in movie fragments and <a>CMAF Segment</a>s that span variable durations on the Track timeline. WebVTT subtitle tracks synchronize with other tracks selected for presentation using regular CMAF track synchronization methods based on ISO Base Media File Format and a Presentation Description <a>Manifest</a>. Any WebVTT cue that crosses a <a>CMAF Segment</a> boundary (i.e. which starts before the Segment starts and/or ends after the Segment ends) SHALL be present in that Segment, and SHALL indicate the entire time range of the cue, even when it lies outside of the Segment boundary.</p>
<p>Note: Forced titles are supported in TTML/IMSC1, but not VTT. A workaround is to create two VTT Tracks, one with only the forced titles, and the other with both forced and regular subtitles. A player must play the forced-only track by default, and switch to the forced + subtitles track when subtitles are selected.</p>
</section>
<section>
<h2 id="ttml">TTML</h2>
<p>TTML is a subtitle format that is used to author and deliver subtitles for television, movies, etc. The Timed Text Markup Language was specified by W3C, then adapted to the authoring and presentation of video synchronized subtitles in multiple production and delivery specifications. W3C has specified an Internet Media Subtitle and Caption profile version 1 [IMSC]that is compatible with these delivery specifications. IMSC1 can store subtitles as text with style and layout information, or as images. <a>CMAF Track</a>s conforming to ISO/IEC 14496-30 [ISOTXT] and W3C Internet Media Subtitles and Caption profile [IMSC] MAY be used in addition to WebVTT.</p>
<p>TTML subtitle tracks as specified in ISO/IEC 14496-30, use a track handler_type of ‘subt’, a Subtitle Media Header Box (‘sthd’), and the XMLSubtitleSampleEntry format.</p>
<p>The XMLSubtitleSampleEntry namespace field is set to at least one unique namespace. It SHOULD indicate the primary IMSC1 namespace of the document, and SHOULD list all namespaces in use in the document (e.g. IMSC1 + SMPTE-TT).</p>
<p>The schema_location field should be set to schema pathnames that uniquely identify the profile or constraint set of the namespaces included in the namespace field, e.g. <a href="https://www.w3.org/TR/2016/CR-ttml-imsc1-20160128/xml-schemas/imsc1.xsd"><em>https://www.w3.org/TR/2016/CR-ttml-imsc1-20160128/xml-schemas/imsc1.xsd</em></a></p>
<p>When image sub-samples are present, then the auxiliary_mime_types field SHALL be set to the mime types used in the sub-samples – e.g. “image/png”.</p>
</section>
<section>
<h2 id="cea-608-and-cea-708">CEA-608 and CEA-708</h2>
<p>CEA-608 and CEA-708 are formats developed for delivering closed captions for accessibility purposes for broadcast television in North America. These formats can also be used to deliver captions in other scenarios. Closed captions can be embedded in the video elementary stream’s SEI messages. Please refer to section ‎9.6 for the format of CEA-608/708 in SEI Messages.</p>
</section>
<section>
<h2 id="metadata-for-subtitles">Metadata for Subtitles</h2>
<p>Text tracks SHOULD normally be labeled with their Role. See section [‎7.5.5]</p>
</section>
<section>
<h2 id="translating-subtitles-from-other-formats">Translating Subtitles from Other Formats</h2>
<p>Subtitles can be authored in a variety of formats, including many that are not supported by CMAF. To be CMAF compliant it will be necessary to convert subtitles into one of the formats supported by CMAF.</p>
<p>The mandatory subtitle format is VTT in the profiles defined in ‎Annex A. ; other formats, including TTML and SEI messages, may also be offered. The Timed Text Working Group of the W3C has provided a Note on how to map subtitles between the TTML and WebVTT formats. The note can be found here: <a href="https://dvcs.w3.org/hg/ttml/raw-file/tip/ttml-webvtt-mapping/mappingbetweenTTMLandWebVTTW3C.html"><em>https://dvcs.w3.org/hg/ttml/raw-file/tip/ttml-webvtt-mapping/mappingbetweenTTMLandWebVTTW3C.html</em></a> .</p>
</section>
</section>
<section class="appendix">
<h2><a>CMAF Presentation</a> and Media Profiles</h2>
<section>
<h3><a>CMAF Presentation</a> Profiles</h3>
<p><a>CMAF Presentation</a> Profile ID CMFHD</p>
<ul>
<li><p>If containing video, SHALL include at least one Switching Set constrained to the ‘cfhd’ Media Profile in ‎A.2</p></li>
<li><p>If containing audio, SHALL include at least one audio Switching Set constrained to the ‘caac’ Media Profile in ‎A.3Table 3 – AAC Core audio formats.</p></li>
<li><p>If containing subtitles, SHALL include a Switching Set for each language and role provided in subtitles constrained to the ‘cwvt’ Media Profile in ‎A.4.</p></li>
</ul>
<p>It is recommended that each Track Switching Set include Tracks conforming to one Track Profile so that a <a>Player</a> compatible with that profile can automatically switch between all Tracks once a Switching Set is selected by a <a>Player</a>. A Track Switching Set that combines multiple Media Profiles requires additional logic to determine if it can switch up to a higher Media Profile during adaptive streaming, while switching down is usually possible. Switching Sets of different Profiles often also differ regarding the need for different encryption keys, DRM licenses, output permissions, and authorization, e.g. different purchase or subscription rights associated with each Video Profile.</p>
<p>Switching Set Media Profiles, encoding parameters, encryption, and licensing SHALL be constrained so that a single license acquisition and decoder/display system initialization is sufficient to present all the Tracks in the Switching Set. For instance, SD content may be available over analog display connections, HD may require HDMI, and UHD may require HDCP 2.2 over HDMI to reach an external display. These output controls are expressed in DRM licenses and enforced by DRM systems probably not exposed to the playback application, so they SHALL be constrained by content authoring to result in automatic seamless switching behavior.</p>
<p>It is strongly recommended, that encryption keys not be shared between audio and video Switching Sets. Audio decoding and decryption systems may have lower key security than video decoding systems so should not expose a key also used for video. Premium UHD/HDR content may require hardware security, watermarking, etc. only available on some devices and DRMs.</p>
</section>
<section>
<h3>Video Media Profiles and Track Brands</h3>
<p>The following Video Profiles are interoperability points between encoders and decoders that use the video Track format and tools specified above. Profiles SHOULD be indicated by the presence of the indicated brand in the compatible brands table of the File Type box.</p>
<p>Tracks indicating a Profile SHALL not exceed the limits specified in Table 5 - Video Media Profiles. <a>Player</a>s SHOULD equal or exceed the limits of a Profile in order to reliably decode it.</p>
<p>Track Profiles SHOULD be indicated in a <a>Manifest</a> so that <a>Player</a>s can identify the maximum decoding requirements of each Track and select a compatible Track with appropriate encoding quality for the <a>Player</a>’s available bandwidth, display capabilities, etc. Switching Sets in <a>Manifest</a>s SHOULD indicate the highest Profile of the included Tracks. A <a>Player</a> MAY also initialize and play a subset of Tracks in a Switching Set using per Track Profiles and parameters, and ignore other Tracks in the Switching Set that exceed its decoding capabilities.</p>
<p>The following table lists the maximum encoding parameters and minimum decoding parameters necessary for interoperability. Profiles are generally inclusive of lower codec profiles and levels, and can encode video less than the maximum height and width, and SHALL the size of other picture aspect ratios to the constraining dimension. For example, movies that are typically produced in aspect rations ranging from 1.85 to 2.4 will be width limited and will therefore have to encode fewer lines if encoding with square sample aspect ratio, e.g. 1920x800 in HD frame limits. Note that a smaller frame size allows a higher frame rate, determined by the fill rate of the level.</p>
<p>For example, the HD video Media Profile allows 1280x720 size at 60Hz, even though it is limited to 30Hz at 1920x1080 size, and the SD Profile allows 854x480 at 60Hz. See ‎Annex D. for detailed examples.</p>
<p>Table 5 - Video Media Profiles</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Media Profile</strong></th>
<th style="text-align: left;"><strong>Codec</strong></th>
<th style="text-align: left;"><strong>Profile</strong></th>
<th style="text-align: left;"><strong>Level </strong></th>
<th style="text-align: left;"><p><strong>Bitrate</strong></p>
<p><strong>Mbps</strong></p></th>
<th style="text-align: left;"><strong>Frame Sz Samples</strong></th>
<th style="text-align: left;"><strong>Fillrate Samples/s</strong></th>
<th style="text-align: left;"><strong>Color Coding</strong></th>
<th style="text-align: left;"><strong>EOTF</strong></th>
<th style="text-align: left;"><strong>Max Height Samples</strong></th>
<th style="text-align: left;"><strong>Max Width Samples</strong></th>
<th style="text-align: left;"><p><strong>Max Fr Rate</strong></p>
<p><strong>@maxSize</strong></p></th>
<th style="text-align: left;"><strong>File Brand</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>SD</strong></td>
<td style="text-align: left;">AVC</td>
<td style="text-align: left;">High</td>
<td style="text-align: left;">3.1</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">921 600</td>
<td style="text-align: left;">27 648 000</td>
<td style="text-align: left;">BT-709 or 601</td>
<td style="text-align: left;">BT-1886</td>
<td style="text-align: left;">576</td>
<td style="text-align: left;">854</td>
<td style="text-align: left;">56.2</td>
<td style="text-align: left;">‘cfsd’</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>HD</strong></td>
<td style="text-align: left;">AVC</td>
<td style="text-align: left;">High</td>
<td style="text-align: left;">4.0</td>
<td style="text-align: left;">25</td>
<td style="text-align: left;">2 097 152</td>
<td style="text-align: left;">62 914 560</td>
<td style="text-align: left;">BT-709</td>
<td style="text-align: left;">BT-1886</td>
<td style="text-align: left;">1080</td>
<td style="text-align: left;">1920</td>
<td style="text-align: left;">30.1</td>
<td style="text-align: left;">‘cfhd’</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>HDHF</strong></td>
<td style="text-align: left;">AVC</td>
<td style="text-align: left;">High</td>
<td style="text-align: left;">4.2</td>
<td style="text-align: left;">62</td>
<td style="text-align: left;">2 228 224</td>
<td style="text-align: left;">133 693 440</td>
<td style="text-align: left;">BT 709</td>
<td style="text-align: left;">BT 1886</td>
<td style="text-align: left;">1080</td>
<td style="text-align: left;">1920</td>
<td style="text-align: left;">64</td>
<td style="text-align: left;">‘chdf’</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>HHD8</strong></td>
<td style="text-align: left;">HEVC</td>
<td style="text-align: left;">Main</td>
<td style="text-align: left;">4.1</td>
<td style="text-align: left;">20</td>
<td style="text-align: left;">2 228 224</td>
<td style="text-align: left;">133 693 440</td>
<td style="text-align: left;">BT-709</td>
<td style="text-align: left;">BT-1886</td>
<td style="text-align: left;">1080</td>
<td style="text-align: left;">1920</td>
<td style="text-align: left;">64.0</td>
<td style="text-align: left;">‘chhd’</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>HHD10</strong></td>
<td style="text-align: left;">HEVC</td>
<td style="text-align: left;">Main10</td>
<td style="text-align: left;">4.1</td>
<td style="text-align: left;">20</td>
<td style="text-align: left;">2 228 224</td>
<td style="text-align: left;">133 693 440</td>
<td style="text-align: left;">BT-709</td>
<td style="text-align: left;">BT-1886</td>
<td style="text-align: left;">1080</td>
<td style="text-align: left;">1920</td>
<td style="text-align: left;">64.0</td>
<td style="text-align: left;">‘chh1’</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>UHD8</strong></td>
<td style="text-align: left;">HEVC</td>
<td style="text-align: left;">Main8 MainTier</td>
<td style="text-align: left;">5.0</td>
<td style="text-align: left;">25</td>
<td style="text-align: left;">8 912 896</td>
<td style="text-align: left;">267 386 880</td>
<td style="text-align: left;">BT-709</td>
<td style="text-align: left;">BT-1886</td>
<td style="text-align: left;">2160</td>
<td style="text-align: left;">3840</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">‘cud8’</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>UHD10</strong></td>
<td style="text-align: left;">HEVC</td>
<td style="text-align: left;">Main10 MainTier 10-bit</td>
<td style="text-align: left;">5.1</td>
<td style="text-align: left;">40</td>
<td style="text-align: left;">8 912 896</td>
<td style="text-align: left;">534 773 760</td>
<td style="text-align: left;">BT-709, 2020</td>
<td style="text-align: left;">BT-1886</td>
<td style="text-align: left;">2160</td>
<td style="text-align: left;">3840</td>
<td style="text-align: left;">64</td>
<td style="text-align: left;">‘cud1’</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>HDR10</strong></td>
<td style="text-align: left;">HEVC</td>
<td style="text-align: left;">Main10 MainTier 10-bit</td>
<td style="text-align: left;">5.1</td>
<td style="text-align: left;">40</td>
<td style="text-align: left;">8 912 896</td>
<td style="text-align: left;">534 773 760</td>
<td style="text-align: left;">BT-2020</td>
<td style="text-align: left;">ST-2084</td>
<td style="text-align: left;">2160</td>
<td style="text-align: left;">3840</td>
<td style="text-align: left;">64</td>
<td style="text-align: left;">‘chr1’</td>
</tr>
</tbody>
</table>
</section>
<section>
<h3>Audio Media Profiles and Track Brands</h3>
<p>CMAF specifies a Required audio profile, AAC Core, to provide a minimum level of interoperability between <a>CMAF Presentation</a>s and <a>Player</a>s. Every audio <a>CMAF Selection Set</a> SHALL include at least one AAC Core audio <a>CMAF Track</a>. As detailed in Table 6, this audio track SHALL be stereo or mono. Audio Tracks containing other codecs and channel configurations MAY be included in Selection Sets.</p>
<p><span id="_Ref447628425" class="anchor"></span>Table 6 - Audio Track Profiles</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Media Profile</strong></th>
<th style="text-align: left;"><strong>Codec and Profile</strong></th>
<th style="text-align: left;"><strong>Number of channels</strong></th>
<th style="text-align: left;"><strong>Max Sampling Rate</strong></th>
<th style="text-align: left;"><strong>File Brand</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>AAC Core</strong></td>
<td style="text-align: left;">AAC-LC, HE-AAC v1 or HE-AAC v2</td>
<td style="text-align: left;">Mono or Stereo</td>
<td style="text-align: left;">48 kHz</td>
<td style="text-align: left;">‘caac’</td>
</tr>
</tbody>
</table>
<p>See Section ‎10 for more restrictions on audio tracks.</p>
</section>
<section>
<h3>Subtitle Media Profiles and Track Brands</h3>
<p>CMAF specifies a required subtitle profile, WebVTT Core, to provide a minimum level of interoperability between <a>CMAF Presentation</a>s and <a>Player</a>s.</p>
<p>Table 7 - Subtitle Track Profiles</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Media Profile</strong></th>
<th style="text-align: left;"><strong>Format</strong></th>
<th style="text-align: left;"><strong>Notes</strong></th>
<th style="text-align: left;"><strong>File Brand</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>WebVTT Core</strong></td>
<td style="text-align: left;">WebVTT, Version 1.0</td>
<td style="text-align: left;">—</td>
<td style="text-align: left;">‘cwvt’</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>TTML IMSC1</strong></td>
<td style="text-align: left;">TTML W3C IMSC Version 1</td>
<td style="text-align: left;">—</td>
<td style="text-align: left;">‘ctti’</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>CEA</strong></td>
<td style="text-align: left;">CEA-608 and CEA-708</td>
<td style="text-align: left;">Caption data is embedded in SEI messages in video track; multiple closed caption streams may be present</td>
<td style="text-align: left;">‘ccea’</td>
</tr>
</tbody>
</table>
<p>See also Section ‎11 for more details of these subtitle formats.</p>
</section>
</section>
<section>
<h2>CMAF Compatible Tracks and Media Profiles</h2>
<section>
<h3>Conformance</h3>
</section>
<section>
<h3>Registration and Specification</h3>
<p><a>CMAF Presentation</a> Profiles require each Presentation to include required audio, video, and subtitle Tracks conforming to CMAF specified Media Profiles (when the content type is present), but do not prohibit additional Tracks. Additional codecs and sample descriptions can be contained in the CMAF container format using standard ISOBMFF extension mechanisms.</p>
<p>Each sample description registered for use in ISOBMFF is listed by the four-character code of its sample entry at <a href="http://mp4ra.org"><em>http://mp4ra.org</em></a>, and links to a specification defining the sample and track format. CMAF Compatible Media Profiles and Track bindings MAY be specified and registered in the form of a brand in the MP4RA registry that links to a CMAF Compatible Media Profile specification.</p>
<p>CMAF constraints on audio and video Tracks SHALL apply to CMAF Compatible Track Media Profiles and Track bidings, including sample containment and timing in Fragments, sequencing of Fragments within Tracks, time alignment of Fragments between tracks in the same Switching Sets, synchronization with other Tracks in a Presentation, application of Common Encryption to samples, value of the “codecs” media type parameter, etc. The track specification linked to each Media Profile brand SHOULD specify what parameter changes are allowed between Fragments in a Track, and alternative Fragments in a Switching Set in order to enable seamless switching and decoding.</p>
<p>Tracks not compatible with a CMAF Media Profile (e.g. using an alternative codec) SHALL NOT carry a CMAF Media Profile brand, but MAY carry the 'cmfc' container format brand if they comply with the restrictions of that brand as documented in Section ‎7.2.</p>
</section>
</section>
<section>
<h2>Subsampling of Tracks in Track Switching Sets</h2>
<section>
<h3>Spatial and Temporal Subsampling and Scaling</h3>
<p>Spatial and temporal subsampling are encoding methods commonly used to adaptively reduce bitrate during adaptive streaming while optimizing video quality.</p>
<ul>
<li><p>Spatial subsampling encodes a fraction of the samples in the source video, e.g. 50% of the source’s cropped vertical and horizontal sample count. See Section ‎C.2.</p></li>
<li><p>Temporal subsampling encodes a fraction of the frames in the source video, e.g. 50% of 24Hz to result in a 12Hz Track with half the samples, each of twice the duration, but the same <a>CMAF Segment</a> durations and start times. A Switching Set can include Tracks at different framerates, e.g. 15Hz and 30Hz (and perhaps 60Hz and 120Hz for UHD), but only if they are all exact submultiples of the lowest framerate.</p></li>
</ul>
<p>In order for Track Switching Sets to be presented to viewers with minimal visible disturbance during adaptive bitrate switching, encoding and playback of all the alternative Tracks should adhere to the following best practices:</p>
<ul>
<li><p>Tracks in a Switching Set SHALL be alternative encodings of the same source content (same active video area, color encoding, source spatial sampling, etc.).</p></li>
<li><p>All subsamples are exact sub-multiples of the number of spatial samples in the active area of the source video, i.e. no fractional or rounded subsamples after subsampling and possibly decoder cropping of partially empty macroblocks.</p></li>
<li><p>The <a>Player</a> SHALL determine the display aperture i.e. the number of vertical and horizontal pixels rendered. A player may select a display aperture based on the picture aspect ratio of the Tracks in a Switching Set (‘tkhd’ width/height), available display shapes and sizes, or output signal formats (such as HDMI EDIDs), as well as application and user preferences in framing the source aspect ratio within the application determined display area (full screen, windowed, letterboxed, portrait or landscape device orientation, etc.). Precise subsampling and rescaling is specified in this Annex to avoid visible changes in image size, position, or shape between alternative Tracks and Segments in a Switching Set. Also, different Switching Sets within a Selection Set SHOULD maintain exactly the same aspect ratio to prevent visible distortion when selecting e.g. different camera angles.</p></li>
<li><p><a>Player</a>s SHALL scale the decoded and cropped samples in all Tracks in a Switching Set to the same display aperture.</p></li>
<li><p><a>Player</a>s SHALL display all Tracks in a Switching Set at the same refresh rate. The <a>Player</a> SHALL determine a display refresh rate for the Switching Set and maintain that by refreshing each decoded image multiple times if necessary. Note: Framerate changes are impractical for many video interfaces to smoothly handle, and they may lack operating points for low framerates.</p>
</li>
</ul>
</section>
<section>
<h3>Spatial Sub-sampling</h3>
<p>Spatial sub-sampling can be a helpful tool for improving coding efficiency of a video elementary stream. It is achieved by reducing the resolution of the coded picture relative to the source picture, while adjusting the sample aspect ratio if necessary to compensate for any change in the width to height sample ratio. For example, by reducing the horizontal resolution of the coded picture by 50% while increasing the sample aspect ratio from 1:1 to 2:1, the coded picture size is reduced by half. While this does not necessarily correspond to a 50% decrease in the amount of coded picture data, the decrease can nonetheless be significant.</p>
<p>The width and height in active image spatial samples in a Coded Video Sequence is specified by the combination of the following sequence parameter set fields in the video elementary stream or sample entry:</p>
<ul>
<li><p>[<a href="#H264REF"><em>AVC</em></a>]:</p></li>
</ul>
<ul>
<li><p>pic_width_in_mbs_minus1 which defines the number of horizontal samples</p></li>
<li><p>pic_height_in_map_units_minus1, which defines the number of vertical samples</p></li>
<li><p>aspect_ratio_idc, which defines the aspect ratio of each sample</p></li>
<li><p>frame_crop_left_offset, cropping parameter in SPS</p></li>
<li><p>frame_crop_right_offset, cropping parameter in SPS</p></li>
<li><p>frame_crop_top_offset, cropping parameter in SPS</p></li>
<li><p>frame_crop_bottom_offset, cropping parameter in SPS</p></li>
</ul>
<ul>
<li><p>[<a href="#H265REF"><em>HEVC</em></a>]:</p></li>
</ul>
<ul>
<li><p>pic_width_in_luma_samples which defines the number of horizontal samples</p></li>
<li><p>pic_height_in_luma_samples which defines the number of vertical samples</p></li>
<li><p>aspect_ratio_idc, which defines the aspect ratio of each sample</p></li>
<li><p>conf_win_left_offset, cropping parameter in SPS</p></li>
<li><p>conf_win_right_offset, cropping parameter in SPS</p></li>
<li><p>conf_win_top_offset, cropping parameter in SPS</p></li>
<li><p>conf_win_bottom_offset cropping parameter in SPS</p></li>
</ul>
<p>The presentation size in the video track header box (‘tkhd’) is defined in terms of square pixels (i.e. 1:1 sample aspect ratio) in the width and height fields of the Track Header Box (‘tkhd’) of the video track. These values are used to determine the appropriate aspect ratio when displaying a Track. The width and height in the sample entry is the cropped sample count, which can be converted to square pixels by multiplying by the ratio indexed by aspect_ratio_idc.</p>
<p>All Tracks in a Track Switching Set SHALL have the same picture aspect ratio, equal to that of the active image area of the source. A <a>Player</a> may ignore the presentation size indicated in each Track, and scale all Segments to the <a>Player</a>-determined presentation aperture for that Switching Set.</p>
</section>
<section>
<h3>Sub-sample Factor and Sample Aspect Ratio (SAR)</h3>
<p>The original picture aspect ratio is conveyed in NAL-structured video by the sample aspect ratio of the source video as well as the cropped horizontal and vertical sample counts (SAR is the enumerated sample width to height ratio indexed by the SPS VUI parameter, aspect_ratio_idc). The picture aspect ratio is the cropped width divided by the cropped height times the SAR ratio.</p>
<p>Subsampling may change the encoded video sample aspect ratio when it changes the encoded sample counts, and must be accurately encoded in the VUI information in Sequence Parameter Sets in each Fragment of every Track. MPEG decoder models include an undefined display processor that uses SPS NAL and VUI information to convert decoded 4:2:0 numerical values to a scaled image with the SAR, transfer function and color space indicated in VUI. This Annex further defines how multiple Tracks in a Track Set are scaled to a common display aperture with a fixed picture aspect ratio. The SAR and cropped sample counts SHALL produce the same picture aspect ratio as the source video.</p>
<p>The extent of sub-sampling applied to a Track can be characterized by a <em>sub-sample factor</em> in each of the horizontal and vertical dimensions, defined as follows:</p>
<ul>
<li><p>The <em>horizontal sub-sample factor</em> is defined as the ratio of the number of columns of the <em>luma</em> sample array in the source frame after sample cropping has been applied, divided by the number of columns of the <em>luma</em> sample array after sample cropping has been applied in subsampled Track. For example, a 1920 wide source image subsampled to 960 horizontal samples in a subsampled Track would have a horizontal sub-sample factor of 0.5</p></li>
<li><p>The <em>vertical sub-sample factor</em> is defined as the ratio of the number of rows of the <em>luma</em> sample array in the source frame after sample cropping has been applied, divided by the number of rows of the <em>luma</em> sample array after sample cropping has been applied in a subsampled Track. For example, 1088 vertical samples cropped to 1080 in the source, subsampled to 544 samples cropped to 540 in a subsampled Track would have a vertical sub-sample factor of 0.5.</p>
</li>
</ul>
</section>
<section>
<h3>Examples of Single Dimension Sub-sampling</h3>
<p>If a 1920 x 1080 square pixel (SAR 1:1) source picture is horizontally sub-sampled and encoded at a resolution of 1440 x 1080 (SAR 4:3), which corresponds to a 1920 x 1080 square pixel (SAR 1:1) picture, then the horizontal sub-sample factor is 1440 ÷ 1920 = 0.75, while the vertical sub-sample factor is 1.0 since there is no change in the vertical dimension.</p>
<p>Similarly, if a 1280 x 720 (SAR 1:1) source picture is vertically sub-sampled and encoded at a resolution of 1280 x 540 (SAR 3:4), which corresponds to a 1280 x 720 (SAR 1:1) picture size, then the horizontal sub-sample factor is 1.0 since the is no change in the horizontal dimension, and the vertical sub-sample factor is 540 ÷ 720 = 0.75.</p>
</section>
<section>
<h3>Example of Mixed Sub-sampling</h3>
<p>If a 1280 x 1080 (SAR 3:2) source picture is vertically sub-sampled and encoded at a resolution of 1280 x 540 (SAR 3:4), corresponding to a 1920 x 1080 square pixel (SAR 1:1) picture size, then the horizontal sub-sample factor is 1280 ÷ 1920 = <sup>2</sup>/<sub>3</sub>, and the vertical sub-sample factor is 540 ÷ 1080 = 0.5. To understand how this is an example of mixed sub-sampling, it is helpful to remember that the initial source picture resolution of 1280 x 1080 (SAR 3:2) can itself be thought of as having been horizontally sub-sampled from a higher resolution picture.</p>
</section>
<section>
<h3>Cropping to Active Picture Area</h3>
<p>CMAF players typically control adaptation of the source image to whatever display environment is currently in use. Source content like movies, old TV, and videos from cellphones, etc. have a variety of picture aspect ratios, as do video devices that include phones, tablets, computers, TVs, projectors, and wall displays. In some cases, display aspect ratios will change dynamically when a device like a tablet is rotated from vertical to horizontal orientation, or video is directed to a different display, and the video aperture may be switched from full screen to a window at any time. A <a>Player</a> conforming to the CMAF Application model SHALL adapt the source Active Image size and shape to its display environment by methods such as scaling, padding, cropping and stretching, and apply the same adaptation to every <a>CMAF Segment</a> in a Switching Set, adjusted for subsampling. Image padding added during production to adapt images to a particular TV aspect ratio like 4:3 or 16:9 (i.e. letter box bars or pillar box bars) SHOULD not be encoded.</p>
<p>Since the sub-sampled picture area might not always fall exactly on the sample coding unit boundary employed by the video elementary stream, additional cropping parameters are used to further define the dimensions of the coded picture. It is a normative requirement of AVC and HEVC that decoders perform cropping as signaled in Sequence Parameter Sets (SPS NALs).</p>
<ul>
<li><p>[H264]:</p></li>
</ul>
<ul>
<li><p>“Macroblocks” define the sample coding unit boundary (and are 16x16 blocks)</p></li>
</ul>
<ul>
<li><p>[H265]:</p></li>
</ul>
<ul>
<li><p>“Coding Tree Units” define the sample coding unit boundary (and are 64×64, 32×32, or 16×16 blocks). See section ‎C.2.</p>
</li>
</ul>
</section>
<section>
<h3>Relationship of Cropping and Sub-sampling</h3>
<p>When spatial sub-sampling is applied, additional cropping parameters are often needed to compensate for the mismatch between the coded picture size and the macroblock ([H264]) / coding tree unit ([H265]) boundaries. The specific relationship between theses mechanisms is defined as follows:</p>
<ul>
<li><p>Each picture is decoded using the coding parameters, including horizontal and vertical sample counts and cropping fields, defined in the sequence parameter set corresponding to that picture’s Coded Video Sequence.</p></li>
<li><p>The display aperture is determined by the CMAF <a>Player</a>, and each Segment scaled to fill that aperture using the same method to maintain registration, e.g. common sides, common top bottom, exact match, etc. For example, to output the video to an HDTV, the decoded image might need to be scaled to the display aperture width, then additional letterbox matting applied in order to match a valid HDMI television input format. A newer TV or projector might accept this picture aspect ratio directly without padding.</p>
</li>
</ul>
</section>
<section>
<h3>Example Encoding and Decoding Process</h3>
<p>The following example shows a typical movie picture aspect ratio that was padded and encoded with letterbox bars to fit a 16:9 TV display. The active image is extracted, subsampled, encoded, and partially filled macroblocks indicated by cropping parameters. AVC and HEVC parameters for the example are detailed in the figure that follows.</p>
<p><img src="media/letterboxed-content-encoding-process.png" alt="Letterboxed Content Encoding Process"></p>
<p>Figure 5 - Example of encoding process of letterboxed source content</p>
<p>Figure 5 shows an example of the encoding process that can be applied. Table 8 shows the parameter values that could be used.</p>
<p>Table 8 – Example sub-sample and cropping values for Figure 5</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Object</th>
<th style="text-align: left;">Field</th>
<th style="text-align: left;">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Picture Format</td>
<td style="text-align: left;">width</td>
<td style="text-align: left;">1920</td>
</tr>
<tr class="even">
<td style="text-align: left;">Frame Size</td>
<td style="text-align: left;">height</td>
<td style="text-align: left;">1080</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Sub-sample Factor</td>
<td style="text-align: left;">horizontal</td>
<td style="text-align: left;">0.75</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">vertical</td>
<td style="text-align: left;">1.0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Track Header Box</td>
<td style="text-align: left;">width</td>
<td style="text-align: left;">1920</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">height</td>
<td style="text-align: left;">818</td>
</tr>
<tr class="odd">
<td style="text-align: left;">[H264] Parameter Values</td>
<td style="text-align: left;">chroma_format_idc</td>
<td style="text-align: left;">1 (4:2:0)</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">aspect_ratio_idc</td>
<td style="text-align: left;">14 (4:3)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">pic_width_in_mbs_minus1</td>
<td style="text-align: left;">89</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">pic_height_in_map_units_minus1</td>
<td style="text-align: left;">51</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">frame_cropping_flag</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">frame_crop_left_offset</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">frame_crop_right_offset</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">frame_crop_top_offset</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">frame_crop_bottom_offset</td>
<td style="text-align: left;">7</td>
</tr>
<tr class="even">
<td style="text-align: left;">[H265] Parameter Values</td>
<td style="text-align: left;">chroma_format_idc</td>
<td style="text-align: left;">1 (4:2:0)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">MinCbSizeY</td>
<td style="text-align: left;">16</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">log2_min_luma_coding_block_size_minus3</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">aspect_ratio_idc</td>
<td style="text-align: left;">14 (4:3)</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">pic_width_in_luma_samples</td>
<td style="text-align: left;">1440</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">pic_height_in_luma_samples</td>
<td style="text-align: left;">832</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">conformance_window_flag</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">conf_win_left_offset</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">conf_win_right_offset</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">conf_win_top_offset</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">conf_win_bottom_offset</td>
<td style="text-align: left;">7</td>
</tr>
</tbody>
</table>
<p>Note 1: as chroma_format_idc is 1, SubWidthC and SubWidthC are set to 2 per [H264] and [H265]. This results in a doubling of frame crop parameters (so frame_crop_bottom_offset and conf_win_bottom_offset both equate to 14 pixels in the above example).</p>
<p>Note 2: As [H265] MinCbSizeY is 16 and log2_min_luma_coding_block_size_minus3 is 1, the Coding Tree Unit size is 16x16 (matching the [H264] macroblock size of 16x16).</p>
<p>The decoding and display process for this content is illustrated in Figure 6, below. In this example, the decoded picture dimensions are 1440 x 818, one line larger than the original active picture area. This is due to a limitation in the cropping parameters to crop only even pairs of lines. Note: 816 lines or 51 macroblocks might be more practical, but makes a less informative example.</p>
<p><img src="media/letterboxed-content-display-process.png" alt="Letterboxd content display process"></p>
<p>Figure 6 – Example of display process for letterboxed source content</p>
<p>Figure 7, below, illustrates what might happen when both sub-sampling and cropping are working in the same horizontal dimension. The original source picture content is first sub-sampled horizontally from a 1:1 sample aspect ratio at 1920 x 1080 to a sample aspect ratio of 4:3 at 1440 x 1080, then the 1080 x 1080-pixel active picture area of the sub-sampled image is encoded. However, the actual coded samples have a size of 1088 x 1088 samples due to the coding unit boundaries falling on even multiples of 16 pixels in this example - therefore, additional cropping parameters are provided in both horizontal and vertical dimensions.</p>
<p><img src="media/pillarboxed-content-encoding-process.png" alt="Pillarboxed content encoding process"></p>
<p>Figure 7 - Example of encoding process for pillarboxed source content</p>
<p>Table 9 lists the various parameters that might appear in the resulting file for this sample content.</p>
<p>Table 9 – Example sub-sample and cropping values for Figure 7</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Object</th>
<th style="text-align: left;">Field</th>
<th style="text-align: left;">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Picture Format</td>
<td style="text-align: left;">width</td>
<td style="text-align: left;">1920</td>
</tr>
<tr class="even">
<td style="text-align: left;">Frame Size</td>
<td style="text-align: left;">height</td>
<td style="text-align: left;">1080</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Sub-sample Factor</td>
<td style="text-align: left;">horizontal</td>
<td style="text-align: left;">0.75</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">vertical</td>
<td style="text-align: left;">1.0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Track Header Box</td>
<td style="text-align: left;">width</td>
<td style="text-align: left;">1440</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">height</td>
<td style="text-align: left;">1080</td>
</tr>
<tr class="odd">
<td style="text-align: left;">[H264] Parameter Values</td>
<td style="text-align: left;">chroma_format_idc</td>
<td style="text-align: left;">1 (4:2:0)</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">aspect_ratio_idc</td>
<td style="text-align: left;">14 (4:3)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">pic_width_in_mbs_minus1</td>
<td style="text-align: left;">67</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">pic_height_in_map_units_minus1</td>
<td style="text-align: left;">67</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">frame_cropping_flag</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">frame_crop_left_offset</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">frame_crop_right_offset</td>
<td style="text-align: left;">4</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">frame_crop_top_offset</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">frame_crop_bottom_offset</td>
<td style="text-align: left;">4</td>
</tr>
<tr class="even">
<td style="text-align: left;">[H265] Parameter Values</td>
<td style="text-align: left;">chroma_format_idc</td>
<td style="text-align: left;">1 (4:2:0)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">MinCbSizeY</td>
<td style="text-align: left;">16</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">log2_min_luma_coding_block_size_minus3</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">aspect_ratio_idc</td>
<td style="text-align: left;">14 (4:3)</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">pic_width_in_luma_samples</td>
<td style="text-align: left;">1088</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">pic_height_in_luma_samples</td>
<td style="text-align: left;">1088</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">conformance_window_flag</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">conf_win_left_offset</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">conf_win_right_offset</td>
<td style="text-align: left;">4</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">conf_win_top_offset</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">conf_win_bottom_offset</td>
<td style="text-align: left;">4</td>
</tr>
</tbody>
</table>
<p>Note 1: as chroma_format_idc is 1, SubWidthC and SubWidthC are set to 2 per [H264] and [H265]. This results in a doubling of frame crop parameters (so frame_crop_bottom_offset and conf_win_bottom_offset both equate to 14 pixels in the above example).</p>
<p>Note 2: As [H265] MinCbSizeY is 16 and log2_min_luma_coding_block_size_minus3 is 1, the Coding Tree Unit size is 16x16 (matching the [H264] macroblock size of 16x16).</p>
<p>The process for reconstructing the video for display is shown in Figure 8. As in the previous example, the decoded picture is required to be scaled back up to the original 1:1 sample aspect ratio.</p>
<p><img src="media/pillarboxed-content-display-process.png" alt="Pillarboxed content display process"></p>
<p>Figure 8 – example of display process for pillarboxed source content</p>
<p>If this content was to be displayed on a 4:3 television or other 4:3 display, no further processing of the image would be necessary. However, if this content was to be displayed on a 16:9 HDTV, it might be necessary for it to apply additional matting on the left and right sides to reconstruct the original pillarboxes in order to ensure the video image displays properly. Or, a user might elect to zoom the image to full width and crop the top and bottom. Standard procedure for most TV programs shot on 1.85 aspect ratio film is to “protect” the 1.78 aspect ratio area (16:9) so that the top and bottom can be cropped when displayed full width on HDTVs without loss of significant content.</p>
</section>
<section>
<h3>Example Track Switching Set</h3>
<p>Example encoding “ladders” for adaptive bitrate and resolution Track Switching Sets are included in ‎0.</p>
<p>The examples show worksheets that calculate a series of bitrates and sizes given a maximum desired bitrate and the percentage bitrate change between Tracks, referred to as “gradient”. The number of Tracks calculated is fixed at a large number, but only the necessary number of tracks need be encoded (starting from the top). Additional rows can be ignored.</p>
<p>Scaling and macroblock are calculated and compared to a codec level and profile to calculate frame rate, etc. Horizontal and vertical subsample ratios are checked for integer accuracy after cropping parameters are applied. A figure of merit (bits per picture element) is calculated to help manually adjust subsample ratios against the bitrate to maintain a consistent level of video quality at each bitrate (aside from resolution).</p>
<p>Note that max bitrate, gradient, the number of Tracks, and bit per PEL need to be adjusted to actual source material, deliver strategy, target networks, target devices, encoder efficiency, etc.</p>
<p>Some common source content aspect ratios and frame rates are selected for examples; including 16x9 HD, nearly 16x9 SD, a wide screen movie aspect ratio (2.4), 4x3, and frame sizes for 60Hz.</p>
</section>
</section>
<section>
<h2>Example Encoding Parameters for Conformant <a>CMAF Switching Set</a>s</h2>
<section>
<h3>16x9 Aspect Ratio HD and SD</h3>
<p><img src="media/16x9-aspect-ratio-hd-sd.png" width="623" height="556" alt="16x9 Aspect Ratio HD and SD" /></p>
</section>
<section>
<h3>2.4 Aspect Ratio HD and SD</h3>
<p><img src="media/2-4-aspect-ratio-hd-sd.png" width="624" height="532" alt="2.4 Aspect Ratio HD and SD"/></p>
</section>
<section>
<h3>4x3 Aspect Ratio 1080 Line Source</h3>
<p><img src="media/4x3-aspect-ratio-1080-line-source.png" width="624" height="526" alt="4x3 Aspect Ratio 1080 Line Source"/></p>
</section>
<section>
<h3>60Hz from 1280x720p60 Source</h3>
<p><img src="media/60hz-1280x720p60-source.png" width="623" height="470" alt="60Hz 1280x720p60 source" /></p>
</section>
</section>
</body>
</html>
